<!DOCTYPE html ><html><head><meta http-equiv="X-UA-Compatible" content="IE=edge"/><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" name="viewport"/><title>Spark 4.0.0-preview2 ScalaDoc  - org.apache.spark.sql.api.DataFrameReader</title><meta content="Spark 4.0.0 - preview2 ScalaDoc - org.apache.spark.sql.api.DataFrameReader" name="description"/><meta content="Spark 4.0.0 preview2 ScalaDoc org.apache.spark.sql.api.DataFrameReader" name="keywords"/><meta http-equiv="content-type" content="text/html; charset=UTF-8"/><link href="../../../../../lib/index.css" media="screen" type="text/css" rel="stylesheet"/><link href="../../../../../lib/template.css" media="screen" type="text/css" rel="stylesheet"/><link href="../../../../../lib/print.css" media="print" type="text/css" rel="stylesheet"/><link href="../../../../../lib/diagrams.css" media="screen" type="text/css" rel="stylesheet" id="diagrams-css"/><script type="text/javascript" src="../../../../../lib/jquery.min.js"></script><script type="text/javascript" src="../../../../../lib/index.js"></script><script type="text/javascript" src="../../../../../index.js"></script><script type="text/javascript" src="../../../../../lib/scheduler.js"></script><script type="text/javascript" src="../../../../../lib/template.js"></script><script type="text/javascript">/* this variable can be used by the JS to determine the path to the root document */
var toRoot = '../../../../../';</script></head><body><div id="search"><span id="doc-title">Spark 4.0.0-preview2 ScalaDoc<span id="doc-version"></span></span> <span class="close-results"><span class="left">&lt;</span> Back</span><div id="textfilter"><span class="input"><input autocapitalize="none" placeholder="Search" id="index-input" type="text" accesskey="/"/><i class="clear material-icons"></i><i id="search-icon" class="material-icons"></i></span></div></div><div id="search-results"><div id="search-progress"><div id="progress-fill"></div></div><div id="results-content"><div id="entity-results"></div><div id="member-results"></div></div></div><div id="content-scroll-container" style="-webkit-overflow-scrolling: touch;"><div id="content-container" style="-webkit-overflow-scrolling: touch;"><div id="subpackage-spacer"><div id="packages"><h1>Packages</h1><ul><li class="indented0 " name="_root_.root" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="_root_" class="anchorToMember"></a><a id="root:_root_" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../../../../index.html" title=""><span class="name">root</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../../../index.html" name="_root_" id="_root_" class="extype">root</a></dd></dl></div></li><li class="indented1 " name="_root_.org" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="org" class="anchorToMember"></a><a id="org:org" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../../../index.html" title=""><span class="name">org</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../../../index.html" name="_root_" id="_root_" class="extype">root</a></dd></dl></div></li><li class="indented2 " name="org.apache" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="apache" class="anchorToMember"></a><a id="apache:apache" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../../index.html" title=""><span class="name">apache</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../../index.html" name="org" id="org" class="extype">org</a></dd></dl></div></li><li class="indented3 " name="org.apache.spark" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="spark" class="anchorToMember"></a><a id="spark:spark" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../index.html" title="Core Spark functionality."><span class="name">spark</span></a></span><p class="shortcomment cmt">Core Spark functionality.</p><div class="fullcomment"><div class="comment cmt"><p>Core Spark functionality. <a href="../../SparkContext.html" name="org.apache.spark.SparkContext" id="org.apache.spark.SparkContext" class="extype">org.apache.spark.SparkContext</a> serves as the main entry point to
Spark, while <a href="../../rdd/RDD.html" name="org.apache.spark.rdd.RDD" id="org.apache.spark.rdd.RDD" class="extype">org.apache.spark.rdd.RDD</a> is the data type representing a distributed collection,
and provides most parallel operations.</p><p>In addition, <a href="../../rdd/PairRDDFunctions.html" name="org.apache.spark.rdd.PairRDDFunctions" id="org.apache.spark.rdd.PairRDDFunctions" class="extype">org.apache.spark.rdd.PairRDDFunctions</a> contains operations available only on RDDs
of key-value pairs, such as <code>groupByKey</code> and <code>join</code>; <a href="../../rdd/DoubleRDDFunctions.html" name="org.apache.spark.rdd.DoubleRDDFunctions" id="org.apache.spark.rdd.DoubleRDDFunctions" class="extype">org.apache.spark.rdd.DoubleRDDFunctions</a>
contains operations available only on RDDs of Doubles; and
<a href="../../rdd/SequenceFileRDDFunctions.html" name="org.apache.spark.rdd.SequenceFileRDDFunctions" id="org.apache.spark.rdd.SequenceFileRDDFunctions" class="extype">org.apache.spark.rdd.SequenceFileRDDFunctions</a> contains operations available on RDDs that can
be saved as SequenceFiles. These operations are automatically available on any RDD of the right
type (e.g. RDD[(Int, Int)] through implicit conversions.</p><p>Java programmers should reference the <a href="../../api/java/index.html" name="org.apache.spark.api.java" id="org.apache.spark.api.java" class="extype">org.apache.spark.api.java</a> package
for Spark programming APIs in Java.</p><p>Classes and methods marked with <span class="experimental badge" style="float: none;">
Experimental</span> are user-facing features which have not been officially adopted by the
Spark project. These are subject to change or removal in minor releases.</p><p>Classes and methods marked with <span class="developer badge" style="float: none;">
Developer API</span> are intended for advanced users want to extend Spark through lower
level interfaces. These are subject to changes or removal in minor releases.
</p></div><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../index.html" name="org.apache" id="org.apache" class="extype">apache</a></dd></dl></div></li><li class="indented4 " name="org.apache.spark.sql" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="sql" class="anchorToMember"></a><a id="sql:sql" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../index.html" title="Allows the execution of relational queries, including those expressed in SQL using Spark."><span class="name">sql</span></a></span><p class="shortcomment cmt">Allows the execution of relational queries, including those expressed in SQL using Spark.</p><div class="fullcomment"><div class="comment cmt"><p>Allows the execution of relational queries, including those expressed in SQL using Spark.
</p></div><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../index.html" name="org.apache.spark" id="org.apache.spark" class="extype">spark</a></dd></dl></div></li><li class="indented5 " name="org.apache.spark.sql.api" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="api" class="anchorToMember"></a><a id="api:api" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="index.html" title="Contains API classes that are specific to a single language (i.e."><span class="name">api</span></a></span><p class="shortcomment cmt">Contains API classes that are specific to a single language (i.e.</p><div class="fullcomment"><div class="comment cmt"><p>Contains API classes that are specific to a single language (i.e. Java).
</p></div><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../index.html" name="org.apache.spark.sql" id="org.apache.spark.sql" class="extype">sql</a></dd></dl></div></li><li class="indented6 " name="org.apache.spark.sql.api.java" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="java" class="anchorToMember"></a><a id="java:java" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/java/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="java/index.html" title=""><span class="name">java</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="index.html" name="org.apache.spark.sql.api" id="org.apache.spark.sql.api" class="extype">api</a></dd></dl></div></li><li class="current-entities indented5"><span class="separator"></span> <a href="Catalog.html" title="Catalog interface for Spark." class="class"></a><a href="Catalog.html" title="Catalog interface for Spark.">Catalog</a></li><li class="current-entities indented5"><span class="separator"></span> <a href="DataFrameNaFunctions.html" title="Functionality for working with missing data in DataFrames." class="class"></a><a href="DataFrameNaFunctions.html" title="Functionality for working with missing data in DataFrames.">DataFrameNaFunctions</a></li><li class="current-entities indented5"><span class="separator"></span> <a href="" title="Interface used to load a Dataset from external storage systems (e.g." class="class"></a><a href="" title="Interface used to load a Dataset from external storage systems (e.g.">DataFrameReader</a></li><li class="current-entities indented5"><span class="separator"></span> <a href="DataFrameStatFunctions.html" title="Statistic functions for DataFrames." class="class"></a><a href="DataFrameStatFunctions.html" title="Statistic functions for DataFrames.">DataFrameStatFunctions</a></li><li class="current-entities indented5"><span class="separator"></span> <a href="Dataset.html" title="A Dataset is a strongly typed collection of domain-specific objects that can be transformed in parallel using functional or relational operations." class="class"></a><a href="Dataset.html" title="A Dataset is a strongly typed collection of domain-specific objects that can be transformed in parallel using functional or relational operations.">Dataset</a></li><li class="current-entities indented5"><span class="separator"></span> <a href="KeyValueGroupedDataset.html" title="A Dataset has been logically grouped by a user specified grouping key." class="class"></a><a href="KeyValueGroupedDataset.html" title="A Dataset has been logically grouped by a user specified grouping key.">KeyValueGroupedDataset</a></li><li class="current-entities indented5"><span class="separator"></span> <a href="RelationalGroupedDataset.html" title="A set of methods for aggregations on a DataFrame, created by groupBy, cube or rollup (and also pivot)." class="class"></a><a href="RelationalGroupedDataset.html" title="A set of methods for aggregations on a DataFrame, created by groupBy, cube or rollup (and also pivot).">RelationalGroupedDataset</a></li><li class="current-entities indented5"><span class="separator"></span> <a href="SparkSession.html" title="The entry point to programming Spark with the Dataset and DataFrame API." class="class"></a><a href="SparkSession.html" title="The entry point to programming Spark with the Dataset and DataFrame API.">SparkSession</a></li><li class="current-entities indented5"><span class="separator"></span> <a href="StreamingQuery.html" title="A handle to a query that is executing continuously in the background as new data arrives." class="trait"></a><a href="StreamingQuery.html" title="A handle to a query that is executing continuously in the background as new data arrives.">StreamingQuery</a></li><li class="current-entities indented5"><span class="separator"></span> <a href="UDFRegistration.html" title="Functions for registering user-defined functions." class="class"></a><a href="UDFRegistration.html" title="Functions for registering user-defined functions.">UDFRegistration</a></li></ul></div></div><div id="content"><body class="class type"><div id="definition"><div class="big-circle class">c</div><p id="owner"><a href="../../../../index.html" name="org" id="org" class="extype">org</a>.<a href="../../../index.html" name="org.apache" id="org.apache" class="extype">apache</a>.<a href="../../index.html" name="org.apache.spark" id="org.apache.spark" class="extype">spark</a>.<a href="../index.html" name="org.apache.spark.sql" id="org.apache.spark.sql" class="extype">sql</a>.<a href="index.html" name="org.apache.spark.sql.api" id="org.apache.spark.sql.api" class="extype">api</a></p><h1>DataFrameReader<span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html" title="Permalink"><i class="material-icons"></i></a></span></h1><h3><span class="morelinks"></span></h3></div><h4 id="signature" class="signature"><span class="modifier_kind"><span class="modifier">abstract </span> <span class="kind">class</span></span> <span class="symbol"><span class="name">DataFrameReader</span><span class="tparams">[<span name="DS">DS<span class="tparams">[<span name="U">U</span>]</span> &lt;: <a href="Dataset.html" name="org.apache.spark.sql.api.Dataset" id="org.apache.spark.sql.api.Dataset" class="extype">Dataset</a>[<span name="org.apache.spark.sql.api.DataFrameReader.DS.U" class="extype">U</span>, <span name="org.apache.spark.sql.api.DataFrameReader.DS" class="extype">DS</span>]</span>]</span><span class="result"> extends <span name="scala.AnyRef" class="extype">AnyRef</span></span></span></h4><div id="comment" class="fullcommenttop"><div class="comment cmt"><p>Interface used to load a <a href="Dataset.html" name="org.apache.spark.sql.api.Dataset" id="org.apache.spark.sql.api.Dataset" class="extype">Dataset</a> from external storage systems (e.g. file systems,
key-value stores, etc). Use <code>SparkSession.read</code> to access this.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Stable</span><span class="args">()</span> </dd><dt>Source</dt><dd><a href="https://github.com/apache/spark/tree/v4.0.0-preview2/sql/api/src/main/scala/org/apache/spark/sql/api/DataFrameReader.scala" target="_blank">DataFrameReader.scala</a></dd><dt>Since</dt><dd><p>1.4.0</p></dd></dl><div class="toggleContainer"><div class="toggle block"><span>Linear Supertypes</span><div class="superTypes hiddenContent"><span name="scala.AnyRef" class="extype">AnyRef</span>, <span name="scala.Any" class="extype">Any</span></div></div></div><div class="toggleContainer"><div class="toggle block"><span>Known Subclasses</span><div class="subClasses hiddenContent"><a href="../DataFrameReader.html" name="org.apache.spark.sql.DataFrameReader" id="org.apache.spark.sql.DataFrameReader" class="extype">DataFrameReader</a></div></div></div></div><div id="mbrsel"><div class="toggle"></div><div id="memberfilter"><i class="material-icons arrow"></i><span class="input"><input placeholder="Filter all members" id="mbrsel-input" type="text" accesskey="/"/></span><i class="clear material-icons"></i></div><div id="filterby"><div id="order"><span class="filtertype">Ordering</span><ol><li class="alpha in"><span>Alphabetic</span></li><li class="inherit out"><span>By Inheritance</span></li></ol></div><div class="ancestors"><span class="filtertype">Inherited<br/></span><ol id="linearization"><li class="in" name="org.apache.spark.sql.api.DataFrameReader"><span>DataFrameReader</span></li><li class="in" name="scala.AnyRef"><span>AnyRef</span></li><li class="in" name="scala.Any"><span>Any</span></li></ol></div><div class="ancestors"><span class="filtertype"></span><ol><li class="hideall out"><span>Hide All</span></li><li class="showall in"><span>Show All</span></li></ol></div><div id="visbl"><span class="filtertype">Visibility</span><ol><li class="public in"><span>Public</span></li><li class="protected out"><span>Protected</span></li></ol></div></div></div><div id="template"><div id="allMembers"><div id="constructors" class="members"><h3>Instance Constructors</h3><ol><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#&lt;init&gt;" group="Ungrouped" fullComment="no" data-isabs="false" visbl="pub"><a id="&lt;init&gt;():org.apache.spark.sql.api.DataFrameReader[DS]" class="anchorToMember"></a><a id="&lt;init&gt;:DataFrameReader[DS]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#&lt;init&gt;():org.apache.spark.sql.api.DataFrameReader[DS]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">new</span></span> <span class="symbol"><span class="name">DataFrameReader</span><span class="params">()</span></span></li></ol></div><div class="values members"><h3>Abstract Value Members</h3><ol><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#csv" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="csv(csvDataset:DS[String]):DS[org.apache.spark.sql.Row]" class="anchorToMember"></a><a id="csv(DS[String]):DS[Row]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#csv(csvDataset:DS[String]):DS[org.apache.spark.sql.Row]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">abstract </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">csv</span><span class="params">(<span name="csvDataset">csvDataset: <span name="org.apache.spark.sql.api.DataFrameReader.DS" class="extype">DS</span>[<span name="scala.Predef.String" class="extype">String</span>]</span>)</span><span class="result">: <span name="org.apache.spark.sql.api.DataFrameReader.DS" class="extype">DS</span>[<a href="../Row.html" name="org.apache.spark.sql.Row" id="org.apache.spark.sql.Row" class="extype">Row</a>]</span></span><p class="shortcomment cmt">Loads an <code>Dataset[String]</code> storing CSV rows and returns the result as a <code>DataFrame</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Loads an <code>Dataset[String]</code> storing CSV rows and returns the result as a <code>DataFrame</code>.</p><p>If the schema is not specified using <code>schema</code> function and <code>inferSchema</code> option is enabled,
this function goes through the input once to determine the input schema.</p><p>If the schema is not specified using <code>schema</code> function and <code>inferSchema</code> option is disabled,
it determines the columns as string types and it reads only the first line to determine the
names and the number of fields.</p><p>If the enforceSchema is set to <code>false</code>, only the CSV header in the first line is checked to
conform specified or inferred schema.
</p></div><dl class="paramcmts block"><dt class="param">csvDataset</dt><dd class="cmt"><p>
  input Dataset with one CSV row per record</p></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>2.2.0</p></dd><dt>Note</dt><dd><span class="cmt"><p>
  if <code>header</code> option is set to <code>true</code> when calling this API, all lines same with the header
  will be removed if exists.</p></span></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#jdbc" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="jdbc(url:String,table:String,predicates:Array[String],connectionProperties:java.util.Properties):DS[org.apache.spark.sql.Row]" class="anchorToMember"></a><a id="jdbc(String,String,Array[String],Properties):DS[Row]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#jdbc(url:String,table:String,predicates:Array[String],connectionProperties:java.util.Properties):DS[org.apache.spark.sql.Row]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">abstract </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">jdbc</span><span class="params">(<span name="url">url: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="table">table: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="predicates">predicates: <span name="scala.Array" class="extype">Array</span>[<span name="scala.Predef.String" class="extype">String</span>]</span>, <span name="connectionProperties">connectionProperties: <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/Properties.html#java.util.Properties" name="java.util.Properties" id="java.util.Properties" class="extype">Properties</a></span>)</span><span class="result">: <span name="org.apache.spark.sql.api.DataFrameReader.DS" class="extype">DS</span>[<a href="../Row.html" name="org.apache.spark.sql.Row" id="org.apache.spark.sql.Row" class="extype">Row</a>]</span></span><p class="shortcomment cmt">Construct a <code>DataFrame</code> representing the database table accessible via JDBC URL url named
table using connection properties.</p><div class="fullcomment"><div class="comment cmt"><p>Construct a <code>DataFrame</code> representing the database table accessible via JDBC URL url named
table using connection properties. The <code>predicates</code> parameter gives a list expressions
suitable for inclusion in WHERE clauses; each one defines one partition of the <code>DataFrame</code>.</p><p>Don't create too many partitions in parallel on a large cluster; otherwise Spark might crash
your external database systems.</p><p>You can find the JDBC-specific option and parameter documentation for reading tables via JDBC
in &lt;a
href="https://spark.apache.org/docs/latest/sql-data-sources-jdbc.html#data-source-option"&gt;
Data Source Option</a> in the version you use.
</p></div><dl class="paramcmts block"><dt class="param">table</dt><dd class="cmt"><p>
  Name of the table in the external database.</p></dd><dt class="param">predicates</dt><dd class="cmt"><p>
  Condition in the where clause for each partition.</p></dd><dt class="param">connectionProperties</dt><dd class="cmt"><p>
  JDBC database connection arguments, a list of arbitrary string tag/value. Normally at least
  a "user" and "password" property should be included. "fetchsize" can be used to control the
  number of rows per fetch.</p></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#json" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="json(jsonDataset:DS[String]):DS[org.apache.spark.sql.Row]" class="anchorToMember"></a><a id="json(DS[String]):DS[Row]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#json(jsonDataset:DS[String]):DS[org.apache.spark.sql.Row]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">abstract </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">json</span><span class="params">(<span name="jsonDataset">jsonDataset: <span name="org.apache.spark.sql.api.DataFrameReader.DS" class="extype">DS</span>[<span name="scala.Predef.String" class="extype">String</span>]</span>)</span><span class="result">: <span name="org.apache.spark.sql.api.DataFrameReader.DS" class="extype">DS</span>[<a href="../Row.html" name="org.apache.spark.sql.Row" id="org.apache.spark.sql.Row" class="extype">Row</a>]</span></span><p class="shortcomment cmt">Loads a <code>Dataset[String]</code> storing JSON objects (<a href="http://jsonlines.org/">JSON Lines
text format or newline-delimited JSON</a>) and returns the result as a <code>DataFrame</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Loads a <code>Dataset[String]</code> storing JSON objects (<a href="http://jsonlines.org/">JSON Lines
text format or newline-delimited JSON</a>) and returns the result as a <code>DataFrame</code>.</p><p>Unless the schema is specified using <code>schema</code> function, this function goes through the input
once to determine the input schema.
</p></div><dl class="paramcmts block"><dt class="param">jsonDataset</dt><dd class="cmt"><p>
  input Dataset with one JSON object per record</p></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>2.2.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#load" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="load(paths:String*):DS[org.apache.spark.sql.Row]" class="anchorToMember"></a><a id="load(String*):DS[Row]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#load(paths:String*):DS[org.apache.spark.sql.Row]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">abstract </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">load</span><span class="params">(<span name="paths">paths: <span name="scala.Predef.String" class="extype">String</span>*</span>)</span><span class="result">: <span name="org.apache.spark.sql.api.DataFrameReader.DS" class="extype">DS</span>[<a href="../Row.html" name="org.apache.spark.sql.Row" id="org.apache.spark.sql.Row" class="extype">Row</a>]</span></span><p class="shortcomment cmt">Loads input in as a <code>DataFrame</code>, for data sources that support multiple paths.</p><div class="fullcomment"><div class="comment cmt"><p>Loads input in as a <code>DataFrame</code>, for data sources that support multiple paths. Only works if
the source is a HadoopFsRelationProvider.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@varargs</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>1.6.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#load" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="load(path:String):DS[org.apache.spark.sql.Row]" class="anchorToMember"></a><a id="load(String):DS[Row]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#load(path:String):DS[org.apache.spark.sql.Row]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">abstract </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">load</span><span class="params">(<span name="path">path: <span name="scala.Predef.String" class="extype">String</span></span>)</span><span class="result">: <span name="org.apache.spark.sql.api.DataFrameReader.DS" class="extype">DS</span>[<a href="../Row.html" name="org.apache.spark.sql.Row" id="org.apache.spark.sql.Row" class="extype">Row</a>]</span></span><p class="shortcomment cmt">Loads input in as a <code>DataFrame</code>, for data sources that require a path (e.g.</p><div class="fullcomment"><div class="comment cmt"><p>Loads input in as a <code>DataFrame</code>, for data sources that require a path (e.g. data backed by a
local or distributed file system).
</p></div><dl class="attributes block"><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#load" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="load():DS[org.apache.spark.sql.Row]" class="anchorToMember"></a><a id="load():DS[Row]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#load():DS[org.apache.spark.sql.Row]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">abstract </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">load</span><span class="params">()</span><span class="result">: <span name="org.apache.spark.sql.api.DataFrameReader.DS" class="extype">DS</span>[<a href="../Row.html" name="org.apache.spark.sql.Row" id="org.apache.spark.sql.Row" class="extype">Row</a>]</span></span><p class="shortcomment cmt">Loads input in as a <code>DataFrame</code>, for data sources that don't require a path (e.g.</p><div class="fullcomment"><div class="comment cmt"><p>Loads input in as a <code>DataFrame</code>, for data sources that don't require a path (e.g. external
key-value stores).
</p></div><dl class="attributes block"><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#table" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="table(tableName:String):DS[org.apache.spark.sql.Row]" class="anchorToMember"></a><a id="table(String):DS[Row]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#table(tableName:String):DS[org.apache.spark.sql.Row]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">abstract </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">table</span><span class="params">(<span name="tableName">tableName: <span name="scala.Predef.String" class="extype">String</span></span>)</span><span class="result">: <span name="org.apache.spark.sql.api.DataFrameReader.DS" class="extype">DS</span>[<a href="../Row.html" name="org.apache.spark.sql.Row" id="org.apache.spark.sql.Row" class="extype">Row</a>]</span></span><p class="shortcomment cmt">Returns the specified table/view as a <code>DataFrame</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Returns the specified table/view as a <code>DataFrame</code>. If it's a table, it must support batch
reading and the returned DataFrame is the batch scan query plan of this table. If it's a
view, the returned DataFrame is simply the query plan of the view, which can either be a
batch or streaming query plan.
</p></div><dl class="paramcmts block"><dt class="param">tableName</dt><dd class="cmt"><p>
  is either a qualified or unqualified name that designates a table or view. If a database is
  specified, it identifies the table/view from the database. Otherwise, it first attempts to
  find a temporary view with the given name and then match the table/view from the current
  database. Note that, the global temporary view database is also valid here.</p></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#xml" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="xml(xmlDataset:DS[String]):DS[org.apache.spark.sql.Row]" class="anchorToMember"></a><a id="xml(DS[String]):DS[Row]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#xml(xmlDataset:DS[String]):DS[org.apache.spark.sql.Row]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">abstract </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">xml</span><span class="params">(<span name="xmlDataset">xmlDataset: <span name="org.apache.spark.sql.api.DataFrameReader.DS" class="extype">DS</span>[<span name="scala.Predef.String" class="extype">String</span>]</span>)</span><span class="result">: <span name="org.apache.spark.sql.api.DataFrameReader.DS" class="extype">DS</span>[<a href="../Row.html" name="org.apache.spark.sql.Row" id="org.apache.spark.sql.Row" class="extype">Row</a>]</span></span><p class="shortcomment cmt">Loads an <code>Dataset[String]</code> storing XML object and returns the result as a <code>DataFrame</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Loads an <code>Dataset[String]</code> storing XML object and returns the result as a <code>DataFrame</code>.</p><p>If the schema is not specified using <code>schema</code> function and <code>inferSchema</code> option is enabled,
this function goes through the input once to determine the input schema.
</p></div><dl class="paramcmts block"><dt class="param">xmlDataset</dt><dd class="cmt"><p>
  input Dataset with one XML object per record</p></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>4.0.0</p></dd></dl></div></li></ol></div><div class="values members"><h3>Concrete Value Members</h3><ol><li class="indented0 " name="scala.AnyRef#!=" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="!=(x$1:Any):Boolean" class="anchorToMember"></a><a id="!=(Any):Boolean" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#!=(x$1:Any):Boolean" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name" title="gt4s: $bang$eq">!=</span><span class="params">(<span name="arg0">arg0: <span name="scala.Any" class="extype">Any</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div></li><li class="indented0 " name="scala.AnyRef###" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="##:Int" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html###:Int" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name" title="gt4s: $hash$hash">##</span><span class="result">: <span name="scala.Int" class="extype">Int</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div></li><li class="indented0 " name="scala.AnyRef#==" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="==(x$1:Any):Boolean" class="anchorToMember"></a><a id="==(Any):Boolean" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#==(x$1:Any):Boolean" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name" title="gt4s: $eq$eq">==</span><span class="params">(<span name="arg0">arg0: <span name="scala.Any" class="extype">Any</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div></li><li class="indented0 " name="scala.Any#asInstanceOf" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="asInstanceOf[T0]:T0" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#asInstanceOf[T0]:T0" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">asInstanceOf</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="result">: <span name="scala.Any.asInstanceOf.T0" class="extype">T0</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>Any</dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#assertNoSpecifiedSchema" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="prt"><a id="assertNoSpecifiedSchema(operation:String):Unit" class="anchorToMember"></a><a id="assertNoSpecifiedSchema(String):Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#assertNoSpecifiedSchema(operation:String):Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">assertNoSpecifiedSchema</span><span class="params">(<span name="operation">operation: <span name="scala.Predef.String" class="extype">String</span></span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><p class="shortcomment cmt">A convenient function for schema validation in APIs.</p><div class="fullcomment"><div class="comment cmt"><p>A convenient function for schema validation in APIs.
</p></div><dl class="attributes block"><dt>Attributes</dt><dd>protected </dd></dl></div></li><li class="indented0 " name="scala.AnyRef#clone" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="prt"><a id="clone():Object" class="anchorToMember"></a><a id="clone():AnyRef" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#clone():Object" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">clone</span><span class="params">()</span><span class="result">: <span name="scala.AnyRef" class="extype">AnyRef</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Attributes</dt><dd>protected[<span name="java.lang" class="extype">lang</span>] </dd><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd><span class="name">@throws</span><span class="args">(<span><span class="defval">classOf[java.lang.CloneNotSupportedException]</span></span>)</span> <span class="name">@IntrinsicCandidate</span><span class="args">()</span> <span class="name">@native</span><span class="args">()</span> </dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#csv" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="csv(paths:String*):DS[org.apache.spark.sql.Row]" class="anchorToMember"></a><a id="csv(String*):DS[Row]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#csv(paths:String*):DS[org.apache.spark.sql.Row]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">csv</span><span class="params">(<span name="paths">paths: <span name="scala.Predef.String" class="extype">String</span>*</span>)</span><span class="result">: <span name="org.apache.spark.sql.api.DataFrameReader.DS" class="extype">DS</span>[<a href="../Row.html" name="org.apache.spark.sql.Row" id="org.apache.spark.sql.Row" class="extype">Row</a>]</span></span><p class="shortcomment cmt">Loads CSV files and returns the result as a <code>DataFrame</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Loads CSV files and returns the result as a <code>DataFrame</code>.</p><p>This function will go through the input once to determine the input schema if <code>inferSchema</code>
is enabled. To avoid going through the entire data once, disable <code>inferSchema</code> option or
specify the schema explicitly using <code>schema</code>.</p><p>You can find the CSV-specific options for reading CSV files in &lt;a
href="https://spark.apache.org/docs/latest/sql-data-sources-csv.html#data-source-option"&gt;
Data Source Option</a> in the version you use.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@varargs</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#csv" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="csv(path:String):DS[org.apache.spark.sql.Row]" class="anchorToMember"></a><a id="csv(String):DS[Row]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#csv(path:String):DS[org.apache.spark.sql.Row]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">csv</span><span class="params">(<span name="path">path: <span name="scala.Predef.String" class="extype">String</span></span>)</span><span class="result">: <span name="org.apache.spark.sql.api.DataFrameReader.DS" class="extype">DS</span>[<a href="../Row.html" name="org.apache.spark.sql.Row" id="org.apache.spark.sql.Row" class="extype">Row</a>]</span></span><p class="shortcomment cmt">Loads a CSV file and returns the result as a <code>DataFrame</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Loads a CSV file and returns the result as a <code>DataFrame</code>. See the documentation on the other
overloaded <code>csv()</code> method for more details.
</p></div><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="scala.AnyRef#eq" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="eq(x$1:AnyRef):Boolean" class="anchorToMember"></a><a id="eq(AnyRef):Boolean" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#eq(x$1:AnyRef):Boolean" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">eq</span><span class="params">(<span name="arg0">arg0: <span name="scala.AnyRef" class="extype">AnyRef</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd></dl></div></li><li class="indented0 " name="scala.AnyRef#equals" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="equals(x$1:Object):Boolean" class="anchorToMember"></a><a id="equals(AnyRef):Boolean" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#equals(x$1:Object):Boolean" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">equals</span><span class="params">(<span name="arg0">arg0: <span name="scala.AnyRef" class="extype">AnyRef</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#extraOptions" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="prt"><a id="extraOptions:org.apache.spark.sql.catalyst.util.CaseInsensitiveMap[String]" class="anchorToMember"></a><a id="extraOptions:CaseInsensitiveMap[String]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#extraOptions:org.apache.spark.sql.catalyst.util.CaseInsensitiveMap[String]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">var</span></span> <span class="symbol"><span class="name">extraOptions</span><span class="result">: <span name="org.apache.spark.sql.catalyst.util.CaseInsensitiveMap" class="extype">CaseInsensitiveMap</span>[<span name="scala.Predef.String" class="extype">String</span>]</span></span><div class="fullcomment"><dl class="attributes block"><dt>Attributes</dt><dd>protected </dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#format" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="format(source:String):DataFrameReader.this.type" class="anchorToMember"></a><a id="format(String):DataFrameReader.this.type" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#format(source:String):DataFrameReader.this.type" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">format</span><span class="params">(<span name="source">source: <span name="scala.Predef.String" class="extype">String</span></span>)</span><span class="result">: <a href="" name="org.apache.spark.sql.api.DataFrameReader" id="org.apache.spark.sql.api.DataFrameReader" class="extype">DataFrameReader</a>.this.type</span></span><p class="shortcomment cmt">Specifies the input data source format.</p><div class="fullcomment"><div class="comment cmt"><p>Specifies the input data source format.
</p></div><dl class="attributes block"><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div></li><li class="indented0 " name="scala.AnyRef#getClass" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="getClass():Class[_]" class="anchorToMember"></a><a id="getClass():Class[_&lt;:AnyRef]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#getClass():Class[_]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">getClass</span><span class="params">()</span><span class="result">: <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Class.html#java.lang.Class" name="java.lang.Class" id="java.lang.Class" class="extype">Class</a>[_ &lt;: <span name="scala.AnyRef" class="extype">AnyRef</span>]</span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef → Any</dd><dt>Annotations</dt><dd><span class="name">@IntrinsicCandidate</span><span class="args">()</span> <span class="name">@native</span><span class="args">()</span> </dd></dl></div></li><li class="indented0 " name="scala.AnyRef#hashCode" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="hashCode():Int" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#hashCode():Int" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">hashCode</span><span class="params">()</span><span class="result">: <span name="scala.Int" class="extype">Int</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef → Any</dd><dt>Annotations</dt><dd><span class="name">@IntrinsicCandidate</span><span class="args">()</span> <span class="name">@native</span><span class="args">()</span> </dd></dl></div></li><li class="indented0 " name="scala.Any#isInstanceOf" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="isInstanceOf[T0]:Boolean" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#isInstanceOf[T0]:Boolean" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">isInstanceOf</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>Any</dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#jdbc" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="jdbc(url:String,table:String,columnName:String,lowerBound:Long,upperBound:Long,numPartitions:Int,connectionProperties:java.util.Properties):DS[org.apache.spark.sql.Row]" class="anchorToMember"></a><a id="jdbc(String,String,String,Long,Long,Int,Properties):DS[Row]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#jdbc(url:String,table:String,columnName:String,lowerBound:Long,upperBound:Long,numPartitions:Int,connectionProperties:java.util.Properties):DS[org.apache.spark.sql.Row]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">jdbc</span><span class="params">(<span name="url">url: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="table">table: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="columnName">columnName: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="lowerBound">lowerBound: <span name="scala.Long" class="extype">Long</span></span>, <span name="upperBound">upperBound: <span name="scala.Long" class="extype">Long</span></span>, <span name="numPartitions">numPartitions: <span name="scala.Int" class="extype">Int</span></span>, <span name="connectionProperties">connectionProperties: <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/Properties.html#java.util.Properties" name="java.util.Properties" id="java.util.Properties" class="extype">Properties</a></span>)</span><span class="result">: <span name="org.apache.spark.sql.api.DataFrameReader.DS" class="extype">DS</span>[<a href="../Row.html" name="org.apache.spark.sql.Row" id="org.apache.spark.sql.Row" class="extype">Row</a>]</span></span><p class="shortcomment cmt">Construct a <code>DataFrame</code> representing the database table accessible via JDBC URL url named
table.</p><div class="fullcomment"><div class="comment cmt"><p>Construct a <code>DataFrame</code> representing the database table accessible via JDBC URL url named
table. Partitions of the table will be retrieved in parallel based on the parameters passed
to this function.</p><p>Don't create too many partitions in parallel on a large cluster; otherwise Spark might crash
your external database systems.</p><p>You can find the JDBC-specific option and parameter documentation for reading tables via JDBC
in &lt;a
href="https://spark.apache.org/docs/latest/sql-data-sources-jdbc.html#data-source-option"&gt;
Data Source Option</a> in the version you use.
</p></div><dl class="paramcmts block"><dt class="param">table</dt><dd class="cmt"><p>
  Name of the table in the external database.</p></dd><dt class="param">columnName</dt><dd class="cmt"><p>
  Alias of <code>partitionColumn</code> option. Refer to <code>partitionColumn</code> in &lt;a
  href="https://spark.apache.org/docs/latest/sql-data-sources-jdbc.html#data-source-option"&gt;
  Data Source Option</a> in the version you use.</p></dd><dt class="param">connectionProperties</dt><dd class="cmt"><p>
  JDBC database connection arguments, a list of arbitrary string tag/value. Normally at least
  a "user" and "password" property should be included. "fetchsize" can be used to control the
  number of rows per fetch and "queryTimeout" can be used to wait for a Statement object to
  execute to the given number of seconds.</p></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#jdbc" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="jdbc(url:String,table:String,properties:java.util.Properties):DS[org.apache.spark.sql.Row]" class="anchorToMember"></a><a id="jdbc(String,String,Properties):DS[Row]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#jdbc(url:String,table:String,properties:java.util.Properties):DS[org.apache.spark.sql.Row]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">jdbc</span><span class="params">(<span name="url">url: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="table">table: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="properties">properties: <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/Properties.html#java.util.Properties" name="java.util.Properties" id="java.util.Properties" class="extype">Properties</a></span>)</span><span class="result">: <span name="org.apache.spark.sql.api.DataFrameReader.DS" class="extype">DS</span>[<a href="../Row.html" name="org.apache.spark.sql.Row" id="org.apache.spark.sql.Row" class="extype">Row</a>]</span></span><p class="shortcomment cmt">Construct a <code>DataFrame</code> representing the database table accessible via JDBC URL url named
table and connection properties.</p><div class="fullcomment"><div class="comment cmt"><p>Construct a <code>DataFrame</code> representing the database table accessible via JDBC URL url named
table and connection properties.</p><p>You can find the JDBC-specific option and parameter documentation for reading tables via JDBC
in &lt;a
href="https://spark.apache.org/docs/latest/sql-data-sources-jdbc.html#data-source-option"&gt;
Data Source Option</a> in the version you use.
</p></div><dl class="attributes block"><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#json" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="json(paths:String*):DS[org.apache.spark.sql.Row]" class="anchorToMember"></a><a id="json(String*):DS[Row]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#json(paths:String*):DS[org.apache.spark.sql.Row]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">json</span><span class="params">(<span name="paths">paths: <span name="scala.Predef.String" class="extype">String</span>*</span>)</span><span class="result">: <span name="org.apache.spark.sql.api.DataFrameReader.DS" class="extype">DS</span>[<a href="../Row.html" name="org.apache.spark.sql.Row" id="org.apache.spark.sql.Row" class="extype">Row</a>]</span></span><p class="shortcomment cmt">Loads JSON files and returns the results as a <code>DataFrame</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Loads JSON files and returns the results as a <code>DataFrame</code>.</p><p><a href="http://jsonlines.org/">JSON Lines</a> (newline-delimited JSON) is supported by
default. For JSON (one record per file), set the <code>multiLine</code> option to true.</p><p>This function goes through the input once to determine the input schema. If you know the
schema in advance, use the version that specifies the schema to avoid the extra scan.</p><p>You can find the JSON-specific options for reading JSON files in &lt;a
href="https://spark.apache.org/docs/latest/sql-data-sources-json.html#data-source-option"&gt;
Data Source Option</a> in the version you use.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@varargs</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#json" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="json(path:String):DS[org.apache.spark.sql.Row]" class="anchorToMember"></a><a id="json(String):DS[Row]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#json(path:String):DS[org.apache.spark.sql.Row]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">json</span><span class="params">(<span name="path">path: <span name="scala.Predef.String" class="extype">String</span></span>)</span><span class="result">: <span name="org.apache.spark.sql.api.DataFrameReader.DS" class="extype">DS</span>[<a href="../Row.html" name="org.apache.spark.sql.Row" id="org.apache.spark.sql.Row" class="extype">Row</a>]</span></span><p class="shortcomment cmt">Loads a JSON file and returns the results as a <code>DataFrame</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Loads a JSON file and returns the results as a <code>DataFrame</code>.</p><p>See the documentation on the overloaded <code>json()</code> method with varargs for more details.
</p></div><dl class="attributes block"><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div></li><li class="indented0 " name="scala.AnyRef#ne" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="ne(x$1:AnyRef):Boolean" class="anchorToMember"></a><a id="ne(AnyRef):Boolean" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#ne(x$1:AnyRef):Boolean" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">ne</span><span class="params">(<span name="arg0">arg0: <span name="scala.AnyRef" class="extype">AnyRef</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd></dl></div></li><li class="indented0 " name="scala.AnyRef#notify" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="notify():Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#notify():Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">notify</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd><span class="name">@IntrinsicCandidate</span><span class="args">()</span> <span class="name">@native</span><span class="args">()</span> </dd></dl></div></li><li class="indented0 " name="scala.AnyRef#notifyAll" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="notifyAll():Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#notifyAll():Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">notifyAll</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd><span class="name">@IntrinsicCandidate</span><span class="args">()</span> <span class="name">@native</span><span class="args">()</span> </dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#option" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="option(key:String,value:Double):DataFrameReader.this.type" class="anchorToMember"></a><a id="option(String,Double):DataFrameReader.this.type" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#option(key:String,value:Double):DataFrameReader.this.type" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">option</span><span class="params">(<span name="key">key: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="value">value: <span name="scala.Double" class="extype">Double</span></span>)</span><span class="result">: <a href="" name="org.apache.spark.sql.api.DataFrameReader" id="org.apache.spark.sql.api.DataFrameReader" class="extype">DataFrameReader</a>.this.type</span></span><p class="shortcomment cmt">Adds an input option for the underlying data source.</p><div class="fullcomment"><div class="comment cmt"><p>Adds an input option for the underlying data source.</p><p>All options are maintained in a case-insensitive way in terms of key names. If a new option
has the same key case-insensitively, it will override the existing option.
</p></div><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#option" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="option(key:String,value:Long):DataFrameReader.this.type" class="anchorToMember"></a><a id="option(String,Long):DataFrameReader.this.type" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#option(key:String,value:Long):DataFrameReader.this.type" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">option</span><span class="params">(<span name="key">key: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="value">value: <span name="scala.Long" class="extype">Long</span></span>)</span><span class="result">: <a href="" name="org.apache.spark.sql.api.DataFrameReader" id="org.apache.spark.sql.api.DataFrameReader" class="extype">DataFrameReader</a>.this.type</span></span><p class="shortcomment cmt">Adds an input option for the underlying data source.</p><div class="fullcomment"><div class="comment cmt"><p>Adds an input option for the underlying data source.</p><p>All options are maintained in a case-insensitive way in terms of key names. If a new option
has the same key case-insensitively, it will override the existing option.
</p></div><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#option" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="option(key:String,value:Boolean):DataFrameReader.this.type" class="anchorToMember"></a><a id="option(String,Boolean):DataFrameReader.this.type" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#option(key:String,value:Boolean):DataFrameReader.this.type" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">option</span><span class="params">(<span name="key">key: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="value">value: <span name="scala.Boolean" class="extype">Boolean</span></span>)</span><span class="result">: <a href="" name="org.apache.spark.sql.api.DataFrameReader" id="org.apache.spark.sql.api.DataFrameReader" class="extype">DataFrameReader</a>.this.type</span></span><p class="shortcomment cmt">Adds an input option for the underlying data source.</p><div class="fullcomment"><div class="comment cmt"><p>Adds an input option for the underlying data source.</p><p>All options are maintained in a case-insensitive way in terms of key names. If a new option
has the same key case-insensitively, it will override the existing option.
</p></div><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#option" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="option(key:String,value:String):DataFrameReader.this.type" class="anchorToMember"></a><a id="option(String,String):DataFrameReader.this.type" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#option(key:String,value:String):DataFrameReader.this.type" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">option</span><span class="params">(<span name="key">key: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="value">value: <span name="scala.Predef.String" class="extype">String</span></span>)</span><span class="result">: <a href="" name="org.apache.spark.sql.api.DataFrameReader" id="org.apache.spark.sql.api.DataFrameReader" class="extype">DataFrameReader</a>.this.type</span></span><p class="shortcomment cmt">Adds an input option for the underlying data source.</p><div class="fullcomment"><div class="comment cmt"><p>Adds an input option for the underlying data source.</p><p>All options are maintained in a case-insensitive way in terms of key names. If a new option
has the same key case-insensitively, it will override the existing option.
</p></div><dl class="attributes block"><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#options" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="options(opts:java.util.Map[String,String]):DataFrameReader.this.type" class="anchorToMember"></a><a id="options(Map[String,String]):DataFrameReader.this.type" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#options(opts:java.util.Map[String,String]):DataFrameReader.this.type" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">options</span><span class="params">(<span name="opts">opts: <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/Map.html#java.util.Map" name="java.util.Map" id="java.util.Map" class="extype">Map</a>[<span name="scala.Predef.String" class="extype">String</span>, <span name="scala.Predef.String" class="extype">String</span>]</span>)</span><span class="result">: <a href="" name="org.apache.spark.sql.api.DataFrameReader" id="org.apache.spark.sql.api.DataFrameReader" class="extype">DataFrameReader</a>.this.type</span></span><p class="shortcomment cmt">Adds input options for the underlying data source.</p><div class="fullcomment"><div class="comment cmt"><p>Adds input options for the underlying data source.</p><p>All options are maintained in a case-insensitive way in terms of key names. If a new option
has the same key case-insensitively, it will override the existing option.
</p></div><dl class="attributes block"><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#options" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="options(options:scala.collection.Map[String,String]):DataFrameReader.this.type" class="anchorToMember"></a><a id="options(Map[String,String]):DataFrameReader.this.type" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#options(options:scala.collection.Map[String,String]):DataFrameReader.this.type" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">options</span><span class="params">(<span name="options">options: <span name="scala.collection.Map" class="extype">Map</span>[<span name="scala.Predef.String" class="extype">String</span>, <span name="scala.Predef.String" class="extype">String</span>]</span>)</span><span class="result">: <a href="" name="org.apache.spark.sql.api.DataFrameReader" id="org.apache.spark.sql.api.DataFrameReader" class="extype">DataFrameReader</a>.this.type</span></span><p class="shortcomment cmt">(Scala-specific) Adds input options for the underlying data source.</p><div class="fullcomment"><div class="comment cmt"><p>(Scala-specific) Adds input options for the underlying data source.</p><p>All options are maintained in a case-insensitive way in terms of key names. If a new option
has the same key case-insensitively, it will override the existing option.
</p></div><dl class="attributes block"><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#orc" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="orc(paths:String*):DS[org.apache.spark.sql.Row]" class="anchorToMember"></a><a id="orc(String*):DS[Row]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#orc(paths:String*):DS[org.apache.spark.sql.Row]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">orc</span><span class="params">(<span name="paths">paths: <span name="scala.Predef.String" class="extype">String</span>*</span>)</span><span class="result">: <span name="org.apache.spark.sql.api.DataFrameReader.DS" class="extype">DS</span>[<a href="../Row.html" name="org.apache.spark.sql.Row" id="org.apache.spark.sql.Row" class="extype">Row</a>]</span></span><p class="shortcomment cmt">Loads ORC files and returns the result as a <code>DataFrame</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Loads ORC files and returns the result as a <code>DataFrame</code>.</p><p>ORC-specific option(s) for reading ORC files can be found in <a href=
"https://spark.apache.org/docs/latest/sql-data-sources-orc.html#data-source-option"> Data
Source Option</a> in the version you use.
</p></div><dl class="paramcmts block"><dt class="param">paths</dt><dd class="cmt"><p>
  input paths</p></dd></dl><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@varargs</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#orc" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="orc(path:String):DS[org.apache.spark.sql.Row]" class="anchorToMember"></a><a id="orc(String):DS[Row]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#orc(path:String):DS[org.apache.spark.sql.Row]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">orc</span><span class="params">(<span name="path">path: <span name="scala.Predef.String" class="extype">String</span></span>)</span><span class="result">: <span name="org.apache.spark.sql.api.DataFrameReader.DS" class="extype">DS</span>[<a href="../Row.html" name="org.apache.spark.sql.Row" id="org.apache.spark.sql.Row" class="extype">Row</a>]</span></span><p class="shortcomment cmt">Loads an ORC file and returns the result as a <code>DataFrame</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Loads an ORC file and returns the result as a <code>DataFrame</code>.
</p></div><dl class="paramcmts block"><dt class="param">path</dt><dd class="cmt"><p>
  input path</p></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>1.5.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#parquet" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="parquet(paths:String*):DS[org.apache.spark.sql.Row]" class="anchorToMember"></a><a id="parquet(String*):DS[Row]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#parquet(paths:String*):DS[org.apache.spark.sql.Row]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">parquet</span><span class="params">(<span name="paths">paths: <span name="scala.Predef.String" class="extype">String</span>*</span>)</span><span class="result">: <span name="org.apache.spark.sql.api.DataFrameReader.DS" class="extype">DS</span>[<a href="../Row.html" name="org.apache.spark.sql.Row" id="org.apache.spark.sql.Row" class="extype">Row</a>]</span></span><p class="shortcomment cmt">Loads a Parquet file, returning the result as a <code>DataFrame</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Loads a Parquet file, returning the result as a <code>DataFrame</code>.</p><p>Parquet-specific option(s) for reading Parquet files can be found in <a href=
"https://spark.apache.org/docs/latest/sql-data-sources-parquet.html#data-source-option"> Data
Source Option</a> in the version you use.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@varargs</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#parquet" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="parquet(path:String):DS[org.apache.spark.sql.Row]" class="anchorToMember"></a><a id="parquet(String):DS[Row]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#parquet(path:String):DS[org.apache.spark.sql.Row]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">parquet</span><span class="params">(<span name="path">path: <span name="scala.Predef.String" class="extype">String</span></span>)</span><span class="result">: <span name="org.apache.spark.sql.api.DataFrameReader.DS" class="extype">DS</span>[<a href="../Row.html" name="org.apache.spark.sql.Row" id="org.apache.spark.sql.Row" class="extype">Row</a>]</span></span><p class="shortcomment cmt">Loads a Parquet file, returning the result as a <code>DataFrame</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Loads a Parquet file, returning the result as a <code>DataFrame</code>. See the documentation on the
other overloaded <code>parquet()</code> method for more details.
</p></div><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#schema" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="schema(schemaString:String):DataFrameReader.this.type" class="anchorToMember"></a><a id="schema(String):DataFrameReader.this.type" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#schema(schemaString:String):DataFrameReader.this.type" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">schema</span><span class="params">(<span name="schemaString">schemaString: <span name="scala.Predef.String" class="extype">String</span></span>)</span><span class="result">: <a href="" name="org.apache.spark.sql.api.DataFrameReader" id="org.apache.spark.sql.api.DataFrameReader" class="extype">DataFrameReader</a>.this.type</span></span><p class="shortcomment cmt">Specifies the schema by using the input DDL-formatted string.</p><div class="fullcomment"><div class="comment cmt"><p>Specifies the schema by using the input DDL-formatted string. Some data sources (e.g. JSON)
can infer the input schema automatically from data. By specifying the schema here, the
underlying data source can skip the schema inference step, and thus speed up data loading.</p><pre>spark.read.schema(<span class="lit">"a INT, b STRING, c DOUBLE"</span>).csv(<span class="lit">"test.csv"</span>)</pre></div><dl class="attributes block"><dt>Since</dt><dd><p>2.3.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#schema" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="schema(schema:org.apache.spark.sql.types.StructType):DataFrameReader.this.type" class="anchorToMember"></a><a id="schema(StructType):DataFrameReader.this.type" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#schema(schema:org.apache.spark.sql.types.StructType):DataFrameReader.this.type" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">schema</span><span class="params">(<span name="schema">schema: <a href="../types/StructType.html" name="org.apache.spark.sql.types.StructType" id="org.apache.spark.sql.types.StructType" class="extype">StructType</a></span>)</span><span class="result">: <a href="" name="org.apache.spark.sql.api.DataFrameReader" id="org.apache.spark.sql.api.DataFrameReader" class="extype">DataFrameReader</a>.this.type</span></span><p class="shortcomment cmt">Specifies the input schema.</p><div class="fullcomment"><div class="comment cmt"><p>Specifies the input schema. Some data sources (e.g. JSON) can infer the input schema
automatically from data. By specifying the schema here, the underlying data source can skip
the schema inference step, and thus speed up data loading.
</p></div><dl class="attributes block"><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#source" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="prt"><a id="source:String" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#source:String" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">var</span></span> <span class="symbol"><span class="name">source</span><span class="result">: <span name="scala.Predef.String" class="extype">String</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Attributes</dt><dd>protected </dd></dl></div></li><li class="indented0 " name="scala.AnyRef#synchronized" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="synchronized[T0](x$1:=&gt;T0):T0" class="anchorToMember"></a><a id="synchronized[T0](=&gt;T0):T0" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#synchronized[T0](x$1:=&gt;T0):T0" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">synchronized</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="params">(<span name="arg0">arg0: =&gt; <span name="java.lang.AnyRef.synchronized.T0" class="extype">T0</span></span>)</span><span class="result">: <span name="java.lang.AnyRef.synchronized.T0" class="extype">T0</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#text" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="text(paths:String*):DS[org.apache.spark.sql.Row]" class="anchorToMember"></a><a id="text(String*):DS[Row]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#text(paths:String*):DS[org.apache.spark.sql.Row]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">text</span><span class="params">(<span name="paths">paths: <span name="scala.Predef.String" class="extype">String</span>*</span>)</span><span class="result">: <span name="org.apache.spark.sql.api.DataFrameReader.DS" class="extype">DS</span>[<a href="../Row.html" name="org.apache.spark.sql.Row" id="org.apache.spark.sql.Row" class="extype">Row</a>]</span></span><p class="shortcomment cmt">Loads text files and returns a <code>DataFrame</code> whose schema starts with a string column named
"value", and followed by partitioned columns if there are any.</p><div class="fullcomment"><div class="comment cmt"><p>Loads text files and returns a <code>DataFrame</code> whose schema starts with a string column named
"value", and followed by partitioned columns if there are any. The text files must be encoded
as UTF-8.</p><p>By default, each line in the text files is a new row in the resulting DataFrame. For example:</p><pre><span class="cmt">// Scala:</span>
spark.read.text(<span class="lit">"/path/to/spark/README.md"</span>)

<span class="cmt">// Java:</span>
spark.read().text(<span class="lit">"/path/to/spark/README.md"</span>)</pre><p>You can find the text-specific options for reading text files in &lt;a
href="https://spark.apache.org/docs/latest/sql-data-sources-text.html#data-source-option"&gt;
Data Source Option</a> in the version you use.
</p></div><dl class="paramcmts block"><dt class="param">paths</dt><dd class="cmt"><p>
  input paths</p></dd></dl><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@varargs</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>1.6.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#text" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="text(path:String):DS[org.apache.spark.sql.Row]" class="anchorToMember"></a><a id="text(String):DS[Row]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#text(path:String):DS[org.apache.spark.sql.Row]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">text</span><span class="params">(<span name="path">path: <span name="scala.Predef.String" class="extype">String</span></span>)</span><span class="result">: <span name="org.apache.spark.sql.api.DataFrameReader.DS" class="extype">DS</span>[<a href="../Row.html" name="org.apache.spark.sql.Row" id="org.apache.spark.sql.Row" class="extype">Row</a>]</span></span><p class="shortcomment cmt">Loads text files and returns a <code>DataFrame</code> whose schema starts with a string column named
"value", and followed by partitioned columns if there are any.</p><div class="fullcomment"><div class="comment cmt"><p>Loads text files and returns a <code>DataFrame</code> whose schema starts with a string column named
"value", and followed by partitioned columns if there are any. See the documentation on the
other overloaded <code>text()</code> method for more details.
</p></div><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#textFile" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="textFile(paths:String*):DS[String]" class="anchorToMember"></a><a id="textFile(String*):DS[String]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#textFile(paths:String*):DS[String]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">textFile</span><span class="params">(<span name="paths">paths: <span name="scala.Predef.String" class="extype">String</span>*</span>)</span><span class="result">: <span name="org.apache.spark.sql.api.DataFrameReader.DS" class="extype">DS</span>[<span name="scala.Predef.String" class="extype">String</span>]</span></span><p class="shortcomment cmt">Loads text files and returns a <a href="Dataset.html" name="org.apache.spark.sql.api.Dataset" id="org.apache.spark.sql.api.Dataset" class="extype">Dataset</a> of String.</p><div class="fullcomment"><div class="comment cmt"><p>Loads text files and returns a <a href="Dataset.html" name="org.apache.spark.sql.api.Dataset" id="org.apache.spark.sql.api.Dataset" class="extype">Dataset</a> of String. The underlying schema of the Dataset
contains a single string column named "value". The text files must be encoded as UTF-8.</p><p>If the directory structure of the text files contains partitioning information, those are
ignored in the resulting Dataset. To include partitioning information as columns, use <code>text</code>.</p><p>By default, each line in the text files is a new row in the resulting DataFrame. For example:</p><pre><span class="cmt">// Scala:</span>
spark.read.textFile(<span class="lit">"/path/to/spark/README.md"</span>)

<span class="cmt">// Java:</span>
spark.read().textFile(<span class="lit">"/path/to/spark/README.md"</span>)</pre><p>You can set the text-specific options as specified in <code>DataFrameReader.text</code>.
</p></div><dl class="paramcmts block"><dt class="param">paths</dt><dd class="cmt"><p>
  input path</p></dd></dl><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@varargs</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#textFile" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="textFile(path:String):DS[String]" class="anchorToMember"></a><a id="textFile(String):DS[String]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#textFile(path:String):DS[String]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">textFile</span><span class="params">(<span name="path">path: <span name="scala.Predef.String" class="extype">String</span></span>)</span><span class="result">: <span name="org.apache.spark.sql.api.DataFrameReader.DS" class="extype">DS</span>[<span name="scala.Predef.String" class="extype">String</span>]</span></span><p class="shortcomment cmt">Loads text files and returns a <a href="Dataset.html" name="org.apache.spark.sql.api.Dataset" id="org.apache.spark.sql.api.Dataset" class="extype">Dataset</a> of String.</p><div class="fullcomment"><div class="comment cmt"><p>Loads text files and returns a <a href="Dataset.html" name="org.apache.spark.sql.api.Dataset" id="org.apache.spark.sql.api.Dataset" class="extype">Dataset</a> of String. See the documentation on the other
overloaded <code>textFile()</code> method for more details.</p></div><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="scala.AnyRef#toString" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="toString():String" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#toString():String" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">toString</span><span class="params">()</span><span class="result">: <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html#java.lang.String" name="java.lang.String" id="java.lang.String" class="extype">String</a></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#userSpecifiedSchema" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="prt"><a id="userSpecifiedSchema:Option[org.apache.spark.sql.types.StructType]" class="anchorToMember"></a><a id="userSpecifiedSchema:Option[StructType]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#userSpecifiedSchema:Option[org.apache.spark.sql.types.StructType]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">var</span></span> <span class="symbol"><span class="name">userSpecifiedSchema</span><span class="result">: <span name="scala.Option" class="extype">Option</span>[<a href="../types/StructType.html" name="org.apache.spark.sql.types.StructType" id="org.apache.spark.sql.types.StructType" class="extype">StructType</a>]</span></span><div class="fullcomment"><dl class="attributes block"><dt>Attributes</dt><dd>protected </dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#validateJsonSchema" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="prt"><a id="validateJsonSchema():Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#validateJsonSchema():Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">validateJsonSchema</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Attributes</dt><dd>protected </dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#validateSingleVariantColumn" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="prt"><a id="validateSingleVariantColumn():Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#validateSingleVariantColumn():Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">validateSingleVariantColumn</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><p class="shortcomment cmt">Ensure that the <code>singleVariantColumn</code> option cannot be used if there is also a user specified
schema.</p><div class="fullcomment"><div class="comment cmt"><p>Ensure that the <code>singleVariantColumn</code> option cannot be used if there is also a user specified
schema.
</p></div><dl class="attributes block"><dt>Attributes</dt><dd>protected </dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#validateXmlSchema" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="prt"><a id="validateXmlSchema():Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#validateXmlSchema():Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">validateXmlSchema</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Attributes</dt><dd>protected </dd></dl></div></li><li class="indented0 " name="scala.AnyRef#wait" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="wait(x$1:Long,x$2:Int):Unit" class="anchorToMember"></a><a id="wait(Long,Int):Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#wait(x$1:Long,x$2:Int):Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">wait</span><span class="params">(<span name="arg0">arg0: <span name="scala.Long" class="extype">Long</span></span>, <span name="arg1">arg1: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd><span class="name">@throws</span><span class="args">(<span><span class="defval">classOf[java.lang.InterruptedException]</span></span>)</span> </dd></dl></div></li><li class="indented0 " name="scala.AnyRef#wait" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="wait(x$1:Long):Unit" class="anchorToMember"></a><a id="wait(Long):Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#wait(x$1:Long):Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">wait</span><span class="params">(<span name="arg0">arg0: <span name="scala.Long" class="extype">Long</span></span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd><span class="name">@throws</span><span class="args">(<span><span class="defval">classOf[java.lang.InterruptedException]</span></span>)</span> <span class="name">@native</span><span class="args">()</span> </dd></dl></div></li><li class="indented0 " name="scala.AnyRef#wait" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="wait():Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#wait():Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">wait</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd><span class="name">@throws</span><span class="args">(<span><span class="defval">classOf[java.lang.InterruptedException]</span></span>)</span> </dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#xml" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="xml(paths:String*):DS[org.apache.spark.sql.Row]" class="anchorToMember"></a><a id="xml(String*):DS[Row]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#xml(paths:String*):DS[org.apache.spark.sql.Row]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">xml</span><span class="params">(<span name="paths">paths: <span name="scala.Predef.String" class="extype">String</span>*</span>)</span><span class="result">: <span name="org.apache.spark.sql.api.DataFrameReader.DS" class="extype">DS</span>[<a href="../Row.html" name="org.apache.spark.sql.Row" id="org.apache.spark.sql.Row" class="extype">Row</a>]</span></span><p class="shortcomment cmt">Loads XML files and returns the result as a <code>DataFrame</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Loads XML files and returns the result as a <code>DataFrame</code>.</p><p>This function will go through the input once to determine the input schema if <code>inferSchema</code>
is enabled. To avoid going through the entire data once, disable <code>inferSchema</code> option or
specify the schema explicitly using <code>schema</code>.</p><p>You can find the XML-specific options for reading XML files in &lt;a
href="https://spark.apache.org/docs/latest/sql-data-sources-xml.html#data-source-option"&gt;
Data Source Option</a> in the version you use.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@varargs</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>4.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameReader#xml" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="xml(path:String):DS[org.apache.spark.sql.Row]" class="anchorToMember"></a><a id="xml(String):DS[Row]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#xml(path:String):DS[org.apache.spark.sql.Row]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">xml</span><span class="params">(<span name="path">path: <span name="scala.Predef.String" class="extype">String</span></span>)</span><span class="result">: <span name="org.apache.spark.sql.api.DataFrameReader.DS" class="extype">DS</span>[<a href="../Row.html" name="org.apache.spark.sql.Row" id="org.apache.spark.sql.Row" class="extype">Row</a>]</span></span><p class="shortcomment cmt">Loads a XML file and returns the result as a <code>DataFrame</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Loads a XML file and returns the result as a <code>DataFrame</code>. See the documentation on the other
overloaded <code>xml()</code> method for more details.
</p></div><dl class="attributes block"><dt>Since</dt><dd><p>4.0.0</p></dd></dl></div></li></ol></div><div class="values members"><h3>Deprecated Value Members</h3><ol><li class="indented0 " name="scala.AnyRef#finalize" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="prt"><a id="finalize():Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameReader.html#finalize():Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name deprecated" title="Deprecated: (Since version 9)">finalize</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Attributes</dt><dd>protected[<span name="java.lang" class="extype">lang</span>] </dd><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd><span class="name">@throws</span><span class="args">(<span><span class="symbol">classOf[java.lang.Throwable]</span></span>)</span> <span class="name">@Deprecated</span> </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 9)</i></p></dd></dl></div></li></ol></div></div><div id="inheritedMembers"><div name="scala.AnyRef" class="parent"><h3>Inherited from <span name="scala.AnyRef" class="extype">AnyRef</span></h3></div><div name="scala.Any" class="parent"><h3>Inherited from <span name="scala.Any" class="extype">Any</span></h3></div></div><div id="groupedMembers"><div name="Ungrouped" class="group"><h3>Ungrouped</h3></div></div></div><div id="tooltip"></div><div id="footer"></div></body></div></div></div></body></html>
