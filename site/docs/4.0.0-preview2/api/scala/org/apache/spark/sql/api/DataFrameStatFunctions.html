<!DOCTYPE html ><html><head><meta http-equiv="X-UA-Compatible" content="IE=edge"/><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" name="viewport"/><title>Spark 4.0.0-preview2 ScalaDoc  - org.apache.spark.sql.api.DataFrameStatFunctions</title><meta content="Spark 4.0.0 - preview2 ScalaDoc - org.apache.spark.sql.api.DataFrameStatFunctions" name="description"/><meta content="Spark 4.0.0 preview2 ScalaDoc org.apache.spark.sql.api.DataFrameStatFunctions" name="keywords"/><meta http-equiv="content-type" content="text/html; charset=UTF-8"/><link href="../../../../../lib/index.css" media="screen" type="text/css" rel="stylesheet"/><link href="../../../../../lib/template.css" media="screen" type="text/css" rel="stylesheet"/><link href="../../../../../lib/print.css" media="print" type="text/css" rel="stylesheet"/><link href="../../../../../lib/diagrams.css" media="screen" type="text/css" rel="stylesheet" id="diagrams-css"/><script type="text/javascript" src="../../../../../lib/jquery.min.js"></script><script type="text/javascript" src="../../../../../lib/index.js"></script><script type="text/javascript" src="../../../../../index.js"></script><script type="text/javascript" src="../../../../../lib/scheduler.js"></script><script type="text/javascript" src="../../../../../lib/template.js"></script><script type="text/javascript">/* this variable can be used by the JS to determine the path to the root document */
var toRoot = '../../../../../';</script></head><body><div id="search"><span id="doc-title">Spark 4.0.0-preview2 ScalaDoc<span id="doc-version"></span></span> <span class="close-results"><span class="left">&lt;</span> Back</span><div id="textfilter"><span class="input"><input autocapitalize="none" placeholder="Search" id="index-input" type="text" accesskey="/"/><i class="clear material-icons"></i><i id="search-icon" class="material-icons"></i></span></div></div><div id="search-results"><div id="search-progress"><div id="progress-fill"></div></div><div id="results-content"><div id="entity-results"></div><div id="member-results"></div></div></div><div id="content-scroll-container" style="-webkit-overflow-scrolling: touch;"><div id="content-container" style="-webkit-overflow-scrolling: touch;"><div id="subpackage-spacer"><div id="packages"><h1>Packages</h1><ul><li class="indented0 " name="_root_.root" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="_root_" class="anchorToMember"></a><a id="root:_root_" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../../../../index.html" title=""><span class="name">root</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../../../index.html" name="_root_" id="_root_" class="extype">root</a></dd></dl></div></li><li class="indented1 " name="_root_.org" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="org" class="anchorToMember"></a><a id="org:org" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../../../index.html" title=""><span class="name">org</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../../../index.html" name="_root_" id="_root_" class="extype">root</a></dd></dl></div></li><li class="indented2 " name="org.apache" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="apache" class="anchorToMember"></a><a id="apache:apache" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../../index.html" title=""><span class="name">apache</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../../index.html" name="org" id="org" class="extype">org</a></dd></dl></div></li><li class="indented3 " name="org.apache.spark" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="spark" class="anchorToMember"></a><a id="spark:spark" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../index.html" title="Core Spark functionality."><span class="name">spark</span></a></span><p class="shortcomment cmt">Core Spark functionality.</p><div class="fullcomment"><div class="comment cmt"><p>Core Spark functionality. <a href="../../SparkContext.html" name="org.apache.spark.SparkContext" id="org.apache.spark.SparkContext" class="extype">org.apache.spark.SparkContext</a> serves as the main entry point to
Spark, while <a href="../../rdd/RDD.html" name="org.apache.spark.rdd.RDD" id="org.apache.spark.rdd.RDD" class="extype">org.apache.spark.rdd.RDD</a> is the data type representing a distributed collection,
and provides most parallel operations.</p><p>In addition, <a href="../../rdd/PairRDDFunctions.html" name="org.apache.spark.rdd.PairRDDFunctions" id="org.apache.spark.rdd.PairRDDFunctions" class="extype">org.apache.spark.rdd.PairRDDFunctions</a> contains operations available only on RDDs
of key-value pairs, such as <code>groupByKey</code> and <code>join</code>; <a href="../../rdd/DoubleRDDFunctions.html" name="org.apache.spark.rdd.DoubleRDDFunctions" id="org.apache.spark.rdd.DoubleRDDFunctions" class="extype">org.apache.spark.rdd.DoubleRDDFunctions</a>
contains operations available only on RDDs of Doubles; and
<a href="../../rdd/SequenceFileRDDFunctions.html" name="org.apache.spark.rdd.SequenceFileRDDFunctions" id="org.apache.spark.rdd.SequenceFileRDDFunctions" class="extype">org.apache.spark.rdd.SequenceFileRDDFunctions</a> contains operations available on RDDs that can
be saved as SequenceFiles. These operations are automatically available on any RDD of the right
type (e.g. RDD[(Int, Int)] through implicit conversions.</p><p>Java programmers should reference the <a href="../../api/java/index.html" name="org.apache.spark.api.java" id="org.apache.spark.api.java" class="extype">org.apache.spark.api.java</a> package
for Spark programming APIs in Java.</p><p>Classes and methods marked with <span class="experimental badge" style="float: none;">
Experimental</span> are user-facing features which have not been officially adopted by the
Spark project. These are subject to change or removal in minor releases.</p><p>Classes and methods marked with <span class="developer badge" style="float: none;">
Developer API</span> are intended for advanced users want to extend Spark through lower
level interfaces. These are subject to changes or removal in minor releases.
</p></div><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../index.html" name="org.apache" id="org.apache" class="extype">apache</a></dd></dl></div></li><li class="indented4 " name="org.apache.spark.sql" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="sql" class="anchorToMember"></a><a id="sql:sql" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../index.html" title="Allows the execution of relational queries, including those expressed in SQL using Spark."><span class="name">sql</span></a></span><p class="shortcomment cmt">Allows the execution of relational queries, including those expressed in SQL using Spark.</p><div class="fullcomment"><div class="comment cmt"><p>Allows the execution of relational queries, including those expressed in SQL using Spark.
</p></div><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../index.html" name="org.apache.spark" id="org.apache.spark" class="extype">spark</a></dd></dl></div></li><li class="indented5 " name="org.apache.spark.sql.api" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="api" class="anchorToMember"></a><a id="api:api" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="index.html" title="Contains API classes that are specific to a single language (i.e."><span class="name">api</span></a></span><p class="shortcomment cmt">Contains API classes that are specific to a single language (i.e.</p><div class="fullcomment"><div class="comment cmt"><p>Contains API classes that are specific to a single language (i.e. Java).
</p></div><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../index.html" name="org.apache.spark.sql" id="org.apache.spark.sql" class="extype">sql</a></dd></dl></div></li><li class="indented6 " name="org.apache.spark.sql.api.java" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="java" class="anchorToMember"></a><a id="java:java" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/java/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="java/index.html" title=""><span class="name">java</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="index.html" name="org.apache.spark.sql.api" id="org.apache.spark.sql.api" class="extype">api</a></dd></dl></div></li><li class="current-entities indented5"><span class="separator"></span> <a href="Catalog.html" title="Catalog interface for Spark." class="class"></a><a href="Catalog.html" title="Catalog interface for Spark.">Catalog</a></li><li class="current-entities indented5"><span class="separator"></span> <a href="DataFrameNaFunctions.html" title="Functionality for working with missing data in DataFrames." class="class"></a><a href="DataFrameNaFunctions.html" title="Functionality for working with missing data in DataFrames.">DataFrameNaFunctions</a></li><li class="current-entities indented5"><span class="separator"></span> <a href="DataFrameReader.html" title="Interface used to load a Dataset from external storage systems (e.g." class="class"></a><a href="DataFrameReader.html" title="Interface used to load a Dataset from external storage systems (e.g.">DataFrameReader</a></li><li class="current-entities indented5"><span class="separator"></span> <a href="" title="Statistic functions for DataFrames." class="class"></a><a href="" title="Statistic functions for DataFrames.">DataFrameStatFunctions</a></li><li class="current-entities indented5"><span class="separator"></span> <a href="Dataset.html" title="A Dataset is a strongly typed collection of domain-specific objects that can be transformed in parallel using functional or relational operations." class="class"></a><a href="Dataset.html" title="A Dataset is a strongly typed collection of domain-specific objects that can be transformed in parallel using functional or relational operations.">Dataset</a></li><li class="current-entities indented5"><span class="separator"></span> <a href="KeyValueGroupedDataset.html" title="A Dataset has been logically grouped by a user specified grouping key." class="class"></a><a href="KeyValueGroupedDataset.html" title="A Dataset has been logically grouped by a user specified grouping key.">KeyValueGroupedDataset</a></li><li class="current-entities indented5"><span class="separator"></span> <a href="RelationalGroupedDataset.html" title="A set of methods for aggregations on a DataFrame, created by groupBy, cube or rollup (and also pivot)." class="class"></a><a href="RelationalGroupedDataset.html" title="A set of methods for aggregations on a DataFrame, created by groupBy, cube or rollup (and also pivot).">RelationalGroupedDataset</a></li><li class="current-entities indented5"><span class="separator"></span> <a href="SparkSession.html" title="The entry point to programming Spark with the Dataset and DataFrame API." class="class"></a><a href="SparkSession.html" title="The entry point to programming Spark with the Dataset and DataFrame API.">SparkSession</a></li><li class="current-entities indented5"><span class="separator"></span> <a href="StreamingQuery.html" title="A handle to a query that is executing continuously in the background as new data arrives." class="trait"></a><a href="StreamingQuery.html" title="A handle to a query that is executing continuously in the background as new data arrives.">StreamingQuery</a></li><li class="current-entities indented5"><span class="separator"></span> <a href="UDFRegistration.html" title="Functions for registering user-defined functions." class="class"></a><a href="UDFRegistration.html" title="Functions for registering user-defined functions.">UDFRegistration</a></li></ul></div></div><div id="content"><body class="class type"><div id="definition"><div class="big-circle class">c</div><p id="owner"><a href="../../../../index.html" name="org" id="org" class="extype">org</a>.<a href="../../../index.html" name="org.apache" id="org.apache" class="extype">apache</a>.<a href="../../index.html" name="org.apache.spark" id="org.apache.spark" class="extype">spark</a>.<a href="../index.html" name="org.apache.spark.sql" id="org.apache.spark.sql" class="extype">sql</a>.<a href="index.html" name="org.apache.spark.sql.api" id="org.apache.spark.sql.api" class="extype">api</a></p><h1>DataFrameStatFunctions<span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html" title="Permalink"><i class="material-icons"></i></a></span></h1><h3><span class="morelinks"></span></h3></div><h4 id="signature" class="signature"><span class="modifier_kind"><span class="modifier">abstract </span> <span class="kind">class</span></span> <span class="symbol"><span class="name">DataFrameStatFunctions</span><span class="tparams">[<span name="DS">DS<span class="tparams">[<span name="U">U</span>]</span> &lt;: <a href="Dataset.html" name="org.apache.spark.sql.api.Dataset" id="org.apache.spark.sql.api.Dataset" class="extype">Dataset</a>[<span name="org.apache.spark.sql.api.DataFrameStatFunctions.DS.U" class="extype">U</span>, <span name="org.apache.spark.sql.api.DataFrameStatFunctions.DS" class="extype">DS</span>]</span>]</span><span class="result"> extends <span name="scala.AnyRef" class="extype">AnyRef</span></span></span></h4><div id="comment" class="fullcommenttop"><div class="comment cmt"><p>Statistic functions for <code>DataFrame</code>s.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Stable</span><span class="args">()</span> </dd><dt>Source</dt><dd><a href="https://github.com/apache/spark/tree/v4.0.0-preview2/sql/api/src/main/scala/org/apache/spark/sql/api/DataFrameStatFunctions.scala" target="_blank">DataFrameStatFunctions.scala</a></dd><dt>Since</dt><dd><p>1.4.0</p></dd></dl><div class="toggleContainer"><div class="toggle block"><span>Linear Supertypes</span><div class="superTypes hiddenContent"><span name="scala.AnyRef" class="extype">AnyRef</span>, <span name="scala.Any" class="extype">Any</span></div></div></div><div class="toggleContainer"><div class="toggle block"><span>Known Subclasses</span><div class="subClasses hiddenContent"><a href="../DataFrameStatFunctions.html" name="org.apache.spark.sql.DataFrameStatFunctions" id="org.apache.spark.sql.DataFrameStatFunctions" class="extype">DataFrameStatFunctions</a></div></div></div></div><div id="mbrsel"><div class="toggle"></div><div id="memberfilter"><i class="material-icons arrow"></i><span class="input"><input placeholder="Filter all members" id="mbrsel-input" type="text" accesskey="/"/></span><i class="clear material-icons"></i></div><div id="filterby"><div id="order"><span class="filtertype">Ordering</span><ol><li class="alpha in"><span>Alphabetic</span></li><li class="inherit out"><span>By Inheritance</span></li></ol></div><div class="ancestors"><span class="filtertype">Inherited<br/></span><ol id="linearization"><li class="in" name="org.apache.spark.sql.api.DataFrameStatFunctions"><span>DataFrameStatFunctions</span></li><li class="in" name="scala.AnyRef"><span>AnyRef</span></li><li class="in" name="scala.Any"><span>Any</span></li></ol></div><div class="ancestors"><span class="filtertype"></span><ol><li class="hideall out"><span>Hide All</span></li><li class="showall in"><span>Show All</span></li></ol></div><div id="visbl"><span class="filtertype">Visibility</span><ol><li class="public in"><span>Public</span></li><li class="protected out"><span>Protected</span></li></ol></div></div></div><div id="template"><div id="allMembers"><div id="constructors" class="members"><h3>Instance Constructors</h3><ol><li class="indented0 " name="org.apache.spark.sql.api.DataFrameStatFunctions#&lt;init&gt;" group="Ungrouped" fullComment="no" data-isabs="false" visbl="pub"><a id="&lt;init&gt;():org.apache.spark.sql.api.DataFrameStatFunctions[DS]" class="anchorToMember"></a><a id="&lt;init&gt;:DataFrameStatFunctions[DS]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#&lt;init&gt;():org.apache.spark.sql.api.DataFrameStatFunctions[DS]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">new</span></span> <span class="symbol"><span class="name">DataFrameStatFunctions</span><span class="params">()</span></span></li></ol></div><div class="values members"><h3>Abstract Value Members</h3><ol><li class="indented0 " name="org.apache.spark.sql.api.DataFrameStatFunctions#approxQuantile" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="approxQuantile(cols:Array[String],probabilities:Array[Double],relativeError:Double):Array[Array[Double]]" class="anchorToMember"></a><a id="approxQuantile(Array[String],Array[Double],Double):Array[Array[Double]]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#approxQuantile(cols:Array[String],probabilities:Array[Double],relativeError:Double):Array[Array[Double]]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">abstract </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">approxQuantile</span><span class="params">(<span name="cols">cols: <span name="scala.Array" class="extype">Array</span>[<span name="scala.Predef.String" class="extype">String</span>]</span>, <span name="probabilities">probabilities: <span name="scala.Array" class="extype">Array</span>[<span name="scala.Double" class="extype">Double</span>]</span>, <span name="relativeError">relativeError: <span name="scala.Double" class="extype">Double</span></span>)</span><span class="result">: <span name="scala.Array" class="extype">Array</span>[<span name="scala.Array" class="extype">Array</span>[<span name="scala.Double" class="extype">Double</span>]]</span></span><p class="shortcomment cmt">Calculates the approximate quantiles of numerical columns of a DataFrame.</p><div class="fullcomment"><div class="comment cmt"><p>Calculates the approximate quantiles of numerical columns of a DataFrame.</p></div><dl class="paramcmts block"><dt class="param">cols</dt><dd class="cmt"><p>
  the names of the numerical columns</p></dd><dt class="param">probabilities</dt><dd class="cmt"><p>
  a list of quantile probabilities Each number must belong to [0, 1]. For example 0 is the
  minimum, 0.5 is the median, 1 is the maximum.</p></dd><dt class="param">relativeError</dt><dd class="cmt"><p>
  The relative target precision to achieve (greater than or equal to 0). If set to zero, the
  exact quantiles are computed, which could be very expensive. Note that values greater than
  1 are accepted but give the same result as 1.</p></dd><dt>returns</dt><dd class="cmt"><p>
  the approximate quantiles at the given probabilities of each column</p></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>2.2.0</p></dd><dt>Note</dt><dd><span class="cmt"><p>
  null and NaN values will be ignored in numerical columns before calculation. For columns
  only containing null or NaN values, an empty array is returned.</p></span></dd><dt>See also</dt><dd><span class="cmt"><p>
  <code>approxQuantile(col:Str* approxQuantile)</code> for detailed description.</p></span></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameStatFunctions#corr" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="corr(col1:String,col2:String,method:String):Double" class="anchorToMember"></a><a id="corr(String,String,String):Double" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#corr(col1:String,col2:String,method:String):Double" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">abstract </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">corr</span><span class="params">(<span name="col1">col1: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="col2">col2: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="method">method: <span name="scala.Predef.String" class="extype">String</span></span>)</span><span class="result">: <span name="scala.Double" class="extype">Double</span></span></span><p class="shortcomment cmt">Calculates the correlation of two columns of a DataFrame.</p><div class="fullcomment"><div class="comment cmt"><p>Calculates the correlation of two columns of a DataFrame. Currently only supports the Pearson
Correlation Coefficient. For Spearman Correlation, consider using RDD methods found in
MLlib's Statistics.
</p></div><dl class="paramcmts block"><dt class="param">col1</dt><dd class="cmt"><p>
  the name of the column</p></dd><dt class="param">col2</dt><dd class="cmt"><p>
  the name of the column to calculate the correlation against</p></dd><dt>returns</dt><dd class="cmt"><p>
  The Pearson Correlation Coefficient as a Double.</p><pre><span class="kw">val</span> df = sc.parallelize(<span class="num">0</span> until <span class="num">10</span>).toDF(<span class="lit">"id"</span>).withColumn(<span class="lit">"rand1"</span>, rand(seed=<span class="num">10</span>))
  .withColumn(<span class="lit">"rand2"</span>, rand(seed=<span class="num">27</span>))
df.stat.corr(<span class="lit">"rand1"</span>, <span class="lit">"rand2"</span>)
res1: <span class="std">Double</span> = <span class="num">0.613</span>...</pre></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameStatFunctions#cov" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="cov(col1:String,col2:String):Double" class="anchorToMember"></a><a id="cov(String,String):Double" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#cov(col1:String,col2:String):Double" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">abstract </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">cov</span><span class="params">(<span name="col1">col1: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="col2">col2: <span name="scala.Predef.String" class="extype">String</span></span>)</span><span class="result">: <span name="scala.Double" class="extype">Double</span></span></span><p class="shortcomment cmt">Calculate the sample covariance of two numerical columns of a DataFrame.</p><div class="fullcomment"><div class="comment cmt"><p>Calculate the sample covariance of two numerical columns of a DataFrame.
</p></div><dl class="paramcmts block"><dt class="param">col1</dt><dd class="cmt"><p>
  the name of the first column</p></dd><dt class="param">col2</dt><dd class="cmt"><p>
  the name of the second column</p></dd><dt>returns</dt><dd class="cmt"><p>
  the covariance of the two columns.</p><pre><span class="kw">val</span> df = sc.parallelize(<span class="num">0</span> until <span class="num">10</span>).toDF(<span class="lit">"id"</span>).withColumn(<span class="lit">"rand1"</span>, rand(seed=<span class="num">10</span>))
  .withColumn(<span class="lit">"rand2"</span>, rand(seed=<span class="num">27</span>))
df.stat.cov(<span class="lit">"rand1"</span>, <span class="lit">"rand2"</span>)
res1: <span class="std">Double</span> = <span class="num">0.065</span>...</pre></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameStatFunctions#crosstab" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="crosstab(col1:String,col2:String):DS[org.apache.spark.sql.Row]" class="anchorToMember"></a><a id="crosstab(String,String):DS[Row]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#crosstab(col1:String,col2:String):DS[org.apache.spark.sql.Row]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">abstract </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">crosstab</span><span class="params">(<span name="col1">col1: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="col2">col2: <span name="scala.Predef.String" class="extype">String</span></span>)</span><span class="result">: <span name="org.apache.spark.sql.api.DataFrameStatFunctions.DS" class="extype">DS</span>[<a href="../Row.html" name="org.apache.spark.sql.Row" id="org.apache.spark.sql.Row" class="extype">Row</a>]</span></span><p class="shortcomment cmt">Computes a pair-wise frequency table of the given columns.</p><div class="fullcomment"><div class="comment cmt"><p>Computes a pair-wise frequency table of the given columns. Also known as a contingency table.
The first column of each row will be the distinct values of <code>col1</code> and the column names will
be the distinct values of <code>col2</code>. The name of the first column will be <code>col1_col2</code>. Counts
will be returned as <code>Long</code>s. Pairs that have no occurrences will have zero as their counts.
Null elements will be replaced by "null", and back ticks will be dropped from elements if
they exist.
</p></div><dl class="paramcmts block"><dt class="param">col1</dt><dd class="cmt"><p>
  The name of the first column. Distinct items will make the first item of each row.</p></dd><dt class="param">col2</dt><dd class="cmt"><p>
  The name of the second column. Distinct items will make the column names of the DataFrame.</p></dd><dt>returns</dt><dd class="cmt"><p>
  A DataFrame containing for the contingency table.</p><pre><span class="kw">val</span> df = spark.createDataFrame(<span class="std">Seq</span>((<span class="num">1</span>, <span class="num">1</span>), (<span class="num">1</span>, <span class="num">2</span>), (<span class="num">2</span>, <span class="num">1</span>), (<span class="num">2</span>, <span class="num">1</span>), (<span class="num">2</span>, <span class="num">3</span>), (<span class="num">3</span>, <span class="num">2</span>), (<span class="num">3</span>, <span class="num">3</span>)))
  .toDF(<span class="lit">"key"</span>, <span class="lit">"value"</span>)
<span class="kw">val</span> ct = df.stat.crosstab(<span class="lit">"key"</span>, <span class="lit">"value"</span>)
ct.show()
+---------+---+---+---+
|key_value|  <span class="num">1</span>|  <span class="num">2</span>|  <span class="num">3</span>|
+---------+---+---+---+
|        <span class="num">2</span>|  <span class="num">2</span>|  <span class="num">0</span>|  <span class="num">1</span>|
|        <span class="num">1</span>|  <span class="num">1</span>|  <span class="num">1</span>|  <span class="num">0</span>|
|        <span class="num">3</span>|  <span class="num">0</span>|  <span class="num">1</span>|  <span class="num">1</span>|
+---------+---+---+---+</pre></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameStatFunctions#df" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="prt"><a id="df:DS[org.apache.spark.sql.Row]" class="anchorToMember"></a><a id="df:DS[Row]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#df:DS[org.apache.spark.sql.Row]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">abstract </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">df</span><span class="result">: <span name="org.apache.spark.sql.api.DataFrameStatFunctions.DS" class="extype">DS</span>[<a href="../Row.html" name="org.apache.spark.sql.Row" id="org.apache.spark.sql.Row" class="extype">Row</a>]</span></span><div class="fullcomment"><dl class="attributes block"><dt>Attributes</dt><dd>protected </dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameStatFunctions#freqItems" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="freqItems(cols:Seq[String],support:Double):DS[org.apache.spark.sql.Row]" class="anchorToMember"></a><a id="freqItems(Seq[String],Double):DS[Row]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#freqItems(cols:Seq[String],support:Double):DS[org.apache.spark.sql.Row]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">abstract </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">freqItems</span><span class="params">(<span name="cols">cols: <span name="scala.Seq" class="extype">Seq</span>[<span name="scala.Predef.String" class="extype">String</span>]</span>, <span name="support">support: <span name="scala.Double" class="extype">Double</span></span>)</span><span class="result">: <span name="org.apache.spark.sql.api.DataFrameStatFunctions.DS" class="extype">DS</span>[<a href="../Row.html" name="org.apache.spark.sql.Row" id="org.apache.spark.sql.Row" class="extype">Row</a>]</span></span><p class="shortcomment cmt">(Scala-specific) Finding frequent items for columns, possibly with false positives.</p><div class="fullcomment"><div class="comment cmt"><p>(Scala-specific) Finding frequent items for columns, possibly with false positives. Using the
frequent element count algorithm described in &lt;a
href="https://doi.org/10.1145/762471.762473"&gt;here</a>, proposed by Karp, Schenker, and
Papadimitriou.</p><p>This function is meant for exploratory data analysis, as we make no guarantee about the
backward compatibility of the schema of the resulting <code>DataFrame</code>.
</p></div><dl class="paramcmts block"><dt class="param">cols</dt><dd class="cmt"><p>
  the names of the columns to search frequent items in.</p></dd><dt>returns</dt><dd class="cmt"><p>
  A Local DataFrame with the Array of frequent items for each column.</p><pre><span class="kw">val</span> rows = <span class="std">Seq</span>.tabulate(<span class="num">100</span>) { i <span class="kw">=&gt;</span>
  <span class="kw">if</span> (i % <span class="num">2</span> == <span class="num">0</span>) (<span class="num">1</span>, -<span class="num">1.0</span>) <span class="kw">else</span> (i, i * -<span class="num">1.0</span>)
}
<span class="kw">val</span> df = spark.createDataFrame(rows).toDF(<span class="lit">"a"</span>, <span class="lit">"b"</span>)
<span class="cmt">// find the items with a frequency greater than 0.4 (observed 40% of the time) for columns</span>
<span class="cmt">// "a" and "b"</span>
<span class="kw">val</span> freqSingles = df.stat.freqItems(<span class="std">Seq</span>(<span class="lit">"a"</span>, <span class="lit">"b"</span>), <span class="num">0.4</span>)
freqSingles.show()
+-----------+-------------+
|a_freqItems|  b_freqItems|
+-----------+-------------+
|    [<span class="num">1</span>, <span class="num">99</span>]|[-<span class="num">1.0</span>, -<span class="num">99.0</span>]|
+-----------+-------------+
<span class="cmt">// find the pair of items with a frequency greater than 0.1 in columns "a" and "b"</span>
<span class="kw">val</span> pairDf = df.select(struct(<span class="lit">"a"</span>, <span class="lit">"b"</span>).as(<span class="lit">"a-b"</span>))
<span class="kw">val</span> freqPairs = pairDf.stat.freqItems(<span class="std">Seq</span>(<span class="lit">"a-b"</span>), <span class="num">0.1</span>)
freqPairs.select(explode($<span class="lit">"a-b_freqItems"</span>).as(<span class="lit">"freq_ab"</span>)).show()
+----------+
|   freq_ab|
+----------+
|  [<span class="num">1</span>,-<span class="num">1.0</span>]|
|   ...    |
+----------+</pre></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameStatFunctions#sampleBy" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="sampleBy[T](col:org.apache.spark.sql.Column,fractions:Map[T,Double],seed:Long):DS[org.apache.spark.sql.Row]" class="anchorToMember"></a><a id="sampleBy[T](Column,Map[T,Double],Long):DS[Row]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#sampleBy[T](col:org.apache.spark.sql.Column,fractions:Map[T,Double],seed:Long):DS[org.apache.spark.sql.Row]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">abstract </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">sampleBy</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="col">col: <a href="../Column.html" name="org.apache.spark.sql.Column" id="org.apache.spark.sql.Column" class="extype">Column</a></span>, <span name="fractions">fractions: <span name="scala.Predef.Map" class="extype">Map</span>[<span name="org.apache.spark.sql.api.DataFrameStatFunctions.sampleBy.T" class="extype">T</span>, <span name="scala.Double" class="extype">Double</span>]</span>, <span name="seed">seed: <span name="scala.Long" class="extype">Long</span></span>)</span><span class="result">: <span name="org.apache.spark.sql.api.DataFrameStatFunctions.DS" class="extype">DS</span>[<a href="../Row.html" name="org.apache.spark.sql.Row" id="org.apache.spark.sql.Row" class="extype">Row</a>]</span></span><p class="shortcomment cmt">Returns a stratified sample without replacement based on the fraction given on each stratum.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a stratified sample without replacement based on the fraction given on each stratum.</p></div><dl class="paramcmts block"><dt class="tparam">T</dt><dd class="cmt"><p>
  stratum type</p></dd><dt class="param">col</dt><dd class="cmt"><p>
  column that defines strata</p></dd><dt class="param">fractions</dt><dd class="cmt"><p>
  sampling fraction for each stratum. If a stratum is not specified, we treat its fraction as
  zero.</p></dd><dt class="param">seed</dt><dd class="cmt"><p>
  random seed</p></dd><dt>returns</dt><dd class="cmt"><p>
  a new <code>DataFrame</code> that represents the stratified sample
The stratified sample can be performed over multiple columns:</p><pre><span class="kw">import</span> org.apache.spark.sql.Row
<span class="kw">import</span> org.apache.spark.sql.functions.struct

<span class="kw">val</span> df = spark.createDataFrame(<span class="std">Seq</span>((<span class="lit">"Bob"</span>, <span class="num">17</span>), (<span class="lit">"Alice"</span>, <span class="num">10</span>), (<span class="lit">"Nico"</span>, <span class="num">8</span>), (<span class="lit">"Bob"</span>, <span class="num">17</span>),
  (<span class="lit">"Alice"</span>, <span class="num">10</span>))).toDF(<span class="lit">"name"</span>, <span class="lit">"age"</span>)
<span class="kw">val</span> fractions = <span class="std">Map</span>(Row(<span class="lit">"Alice"</span>, <span class="num">10</span>) -&gt; <span class="num">0.3</span>, Row(<span class="lit">"Nico"</span>, <span class="num">8</span>) -&gt; <span class="num">1.0</span>)
df.stat.sampleBy(struct($<span class="lit">"name"</span>, $<span class="lit">"age"</span>), fractions, <span class="num">36</span>L).show()
+-----+---+
| name|age|
+-----+---+
| Nico|  <span class="num">8</span>|
|Alice| <span class="num">10</span>|
+-----+---+</pre></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>3.0.0</p></dd></dl></div></li></ol></div><div class="values members"><h3>Concrete Value Members</h3><ol><li class="indented0 " name="scala.AnyRef#!=" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="!=(x$1:Any):Boolean" class="anchorToMember"></a><a id="!=(Any):Boolean" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#!=(x$1:Any):Boolean" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name" title="gt4s: $bang$eq">!=</span><span class="params">(<span name="arg0">arg0: <span name="scala.Any" class="extype">Any</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div></li><li class="indented0 " name="scala.AnyRef###" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="##:Int" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html###:Int" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name" title="gt4s: $hash$hash">##</span><span class="result">: <span name="scala.Int" class="extype">Int</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div></li><li class="indented0 " name="scala.AnyRef#==" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="==(x$1:Any):Boolean" class="anchorToMember"></a><a id="==(Any):Boolean" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#==(x$1:Any):Boolean" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name" title="gt4s: $eq$eq">==</span><span class="params">(<span name="arg0">arg0: <span name="scala.Any" class="extype">Any</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameStatFunctions#approxQuantile" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="approxQuantile(col:String,probabilities:Array[Double],relativeError:Double):Array[Double]" class="anchorToMember"></a><a id="approxQuantile(String,Array[Double],Double):Array[Double]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#approxQuantile(col:String,probabilities:Array[Double],relativeError:Double):Array[Double]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">approxQuantile</span><span class="params">(<span name="col">col: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="probabilities">probabilities: <span name="scala.Array" class="extype">Array</span>[<span name="scala.Double" class="extype">Double</span>]</span>, <span name="relativeError">relativeError: <span name="scala.Double" class="extype">Double</span></span>)</span><span class="result">: <span name="scala.Array" class="extype">Array</span>[<span name="scala.Double" class="extype">Double</span>]</span></span><p class="shortcomment cmt">Calculates the approximate quantiles of a numerical column of a DataFrame.</p><div class="fullcomment"><div class="comment cmt"><p>Calculates the approximate quantiles of a numerical column of a DataFrame.</p><p>The result of this algorithm has the following deterministic bound: If the DataFrame has N
elements and if we request the quantile at probability <code>p</code> up to error <code>err</code>, then the
algorithm will return a sample <code>x</code> from the DataFrame so that the *exact* rank of <code>x</code> is
close to (p * N). More precisely,</p><pre>floor((p - err) * N) &lt;= rank(x) &lt;= ceil((p + err) * N)</pre><p>This method implements a variation of the Greenwald-Khanna algorithm (with some speed
optimizations). The algorithm was first present in &lt;a
href="https://doi.org/10.1145/375663.375670"&gt; Space-efficient Online Computation of Quantile
Summaries</a> by Greenwald and Khanna.
</p></div><dl class="paramcmts block"><dt class="param">col</dt><dd class="cmt"><p>
  the name of the numerical column</p></dd><dt class="param">probabilities</dt><dd class="cmt"><p>
  a list of quantile probabilities Each number must belong to [0, 1]. For example 0 is the
  minimum, 0.5 is the median, 1 is the maximum.</p></dd><dt class="param">relativeError</dt><dd class="cmt"><p>
  The relative target precision to achieve (greater than or equal to 0). If set to zero, the
  exact quantiles are computed, which could be very expensive. Note that values greater than
  1 are accepted but give the same result as 1.</p></dd><dt>returns</dt><dd class="cmt"><p>
  the approximate quantiles at the given probabilities</p></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd><dt>Note</dt><dd><span class="cmt"><p>
  null and NaN values will be removed from the numerical column before calculation. If the
  dataframe is empty or the column only contains null or NaN, an empty array is returned.</p></span></dd></dl></div></li><li class="indented0 " name="scala.Any#asInstanceOf" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="asInstanceOf[T0]:T0" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#asInstanceOf[T0]:T0" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">asInstanceOf</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="result">: <span name="scala.Any.asInstanceOf.T0" class="extype">T0</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>Any</dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameStatFunctions#bloomFilter" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="bloomFilter(col:org.apache.spark.sql.Column,expectedNumItems:Long,numBits:Long):org.apache.spark.util.sketch.BloomFilter" class="anchorToMember"></a><a id="bloomFilter(Column,Long,Long):BloomFilter" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#bloomFilter(col:org.apache.spark.sql.Column,expectedNumItems:Long,numBits:Long):org.apache.spark.util.sketch.BloomFilter" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">bloomFilter</span><span class="params">(<span name="col">col: <a href="../Column.html" name="org.apache.spark.sql.Column" id="org.apache.spark.sql.Column" class="extype">Column</a></span>, <span name="expectedNumItems">expectedNumItems: <span name="scala.Long" class="extype">Long</span></span>, <span name="numBits">numBits: <span name="scala.Long" class="extype">Long</span></span>)</span><span class="result">: <a href="../../util/sketch/BloomFilter.html" name="org.apache.spark.util.sketch.BloomFilter" id="org.apache.spark.util.sketch.BloomFilter" class="extype">BloomFilter</a></span></span><p class="shortcomment cmt">Builds a Bloom filter over a specified column.</p><div class="fullcomment"><div class="comment cmt"><p>Builds a Bloom filter over a specified column.
</p></div><dl class="paramcmts block"><dt class="param">col</dt><dd class="cmt"><p>
  the column over which the filter is built</p></dd><dt class="param">expectedNumItems</dt><dd class="cmt"><p>
  expected number of items which will be put into the filter.</p></dd><dt class="param">numBits</dt><dd class="cmt"><p>
  expected number of bits of the filter.</p></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameStatFunctions#bloomFilter" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="bloomFilter(colName:String,expectedNumItems:Long,numBits:Long):org.apache.spark.util.sketch.BloomFilter" class="anchorToMember"></a><a id="bloomFilter(String,Long,Long):BloomFilter" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#bloomFilter(colName:String,expectedNumItems:Long,numBits:Long):org.apache.spark.util.sketch.BloomFilter" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">bloomFilter</span><span class="params">(<span name="colName">colName: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="expectedNumItems">expectedNumItems: <span name="scala.Long" class="extype">Long</span></span>, <span name="numBits">numBits: <span name="scala.Long" class="extype">Long</span></span>)</span><span class="result">: <a href="../../util/sketch/BloomFilter.html" name="org.apache.spark.util.sketch.BloomFilter" id="org.apache.spark.util.sketch.BloomFilter" class="extype">BloomFilter</a></span></span><p class="shortcomment cmt">Builds a Bloom filter over a specified column.</p><div class="fullcomment"><div class="comment cmt"><p>Builds a Bloom filter over a specified column.
</p></div><dl class="paramcmts block"><dt class="param">colName</dt><dd class="cmt"><p>
  name of the column over which the filter is built</p></dd><dt class="param">expectedNumItems</dt><dd class="cmt"><p>
  expected number of items which will be put into the filter.</p></dd><dt class="param">numBits</dt><dd class="cmt"><p>
  expected number of bits of the filter.</p></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameStatFunctions#bloomFilter" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="bloomFilter(col:org.apache.spark.sql.Column,expectedNumItems:Long,fpp:Double):org.apache.spark.util.sketch.BloomFilter" class="anchorToMember"></a><a id="bloomFilter(Column,Long,Double):BloomFilter" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#bloomFilter(col:org.apache.spark.sql.Column,expectedNumItems:Long,fpp:Double):org.apache.spark.util.sketch.BloomFilter" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">bloomFilter</span><span class="params">(<span name="col">col: <a href="../Column.html" name="org.apache.spark.sql.Column" id="org.apache.spark.sql.Column" class="extype">Column</a></span>, <span name="expectedNumItems">expectedNumItems: <span name="scala.Long" class="extype">Long</span></span>, <span name="fpp">fpp: <span name="scala.Double" class="extype">Double</span></span>)</span><span class="result">: <a href="../../util/sketch/BloomFilter.html" name="org.apache.spark.util.sketch.BloomFilter" id="org.apache.spark.util.sketch.BloomFilter" class="extype">BloomFilter</a></span></span><p class="shortcomment cmt">Builds a Bloom filter over a specified column.</p><div class="fullcomment"><div class="comment cmt"><p>Builds a Bloom filter over a specified column.
</p></div><dl class="paramcmts block"><dt class="param">col</dt><dd class="cmt"><p>
  the column over which the filter is built</p></dd><dt class="param">expectedNumItems</dt><dd class="cmt"><p>
  expected number of items which will be put into the filter.</p></dd><dt class="param">fpp</dt><dd class="cmt"><p>
  expected false positive probability of the filter.</p></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameStatFunctions#bloomFilter" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="bloomFilter(colName:String,expectedNumItems:Long,fpp:Double):org.apache.spark.util.sketch.BloomFilter" class="anchorToMember"></a><a id="bloomFilter(String,Long,Double):BloomFilter" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#bloomFilter(colName:String,expectedNumItems:Long,fpp:Double):org.apache.spark.util.sketch.BloomFilter" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">bloomFilter</span><span class="params">(<span name="colName">colName: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="expectedNumItems">expectedNumItems: <span name="scala.Long" class="extype">Long</span></span>, <span name="fpp">fpp: <span name="scala.Double" class="extype">Double</span></span>)</span><span class="result">: <a href="../../util/sketch/BloomFilter.html" name="org.apache.spark.util.sketch.BloomFilter" id="org.apache.spark.util.sketch.BloomFilter" class="extype">BloomFilter</a></span></span><p class="shortcomment cmt">Builds a Bloom filter over a specified column.</p><div class="fullcomment"><div class="comment cmt"><p>Builds a Bloom filter over a specified column.
</p></div><dl class="paramcmts block"><dt class="param">colName</dt><dd class="cmt"><p>
  name of the column over which the filter is built</p></dd><dt class="param">expectedNumItems</dt><dd class="cmt"><p>
  expected number of items which will be put into the filter.</p></dd><dt class="param">fpp</dt><dd class="cmt"><p>
  expected false positive probability of the filter.</p></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="scala.AnyRef#clone" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="prt"><a id="clone():Object" class="anchorToMember"></a><a id="clone():AnyRef" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#clone():Object" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">clone</span><span class="params">()</span><span class="result">: <span name="scala.AnyRef" class="extype">AnyRef</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Attributes</dt><dd>protected[<span name="java.lang" class="extype">lang</span>] </dd><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd><span class="name">@throws</span><span class="args">(<span><span class="defval">classOf[java.lang.CloneNotSupportedException]</span></span>)</span> <span class="name">@IntrinsicCandidate</span><span class="args">()</span> <span class="name">@native</span><span class="args">()</span> </dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameStatFunctions#corr" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="corr(col1:String,col2:String):Double" class="anchorToMember"></a><a id="corr(String,String):Double" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#corr(col1:String,col2:String):Double" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">corr</span><span class="params">(<span name="col1">col1: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="col2">col2: <span name="scala.Predef.String" class="extype">String</span></span>)</span><span class="result">: <span name="scala.Double" class="extype">Double</span></span></span><p class="shortcomment cmt">Calculates the Pearson Correlation Coefficient of two columns of a DataFrame.</p><div class="fullcomment"><div class="comment cmt"><p>Calculates the Pearson Correlation Coefficient of two columns of a DataFrame.
</p></div><dl class="paramcmts block"><dt class="param">col1</dt><dd class="cmt"><p>
  the name of the column</p></dd><dt class="param">col2</dt><dd class="cmt"><p>
  the name of the column to calculate the correlation against</p></dd><dt>returns</dt><dd class="cmt"><p>
  The Pearson Correlation Coefficient as a Double.</p><pre><span class="kw">val</span> df = sc.parallelize(<span class="num">0</span> until <span class="num">10</span>).toDF(<span class="lit">"id"</span>).withColumn(<span class="lit">"rand1"</span>, rand(seed=<span class="num">10</span>))
  .withColumn(<span class="lit">"rand2"</span>, rand(seed=<span class="num">27</span>))
df.stat.corr(<span class="lit">"rand1"</span>, <span class="lit">"rand2"</span>, <span class="lit">"pearson"</span>)
res1: <span class="std">Double</span> = <span class="num">0.613</span>...</pre></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameStatFunctions#countMinSketch" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="countMinSketch(col:org.apache.spark.sql.Column,eps:Double,confidence:Double,seed:Int):org.apache.spark.util.sketch.CountMinSketch" class="anchorToMember"></a><a id="countMinSketch(Column,Double,Double,Int):CountMinSketch" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#countMinSketch(col:org.apache.spark.sql.Column,eps:Double,confidence:Double,seed:Int):org.apache.spark.util.sketch.CountMinSketch" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">countMinSketch</span><span class="params">(<span name="col">col: <a href="../Column.html" name="org.apache.spark.sql.Column" id="org.apache.spark.sql.Column" class="extype">Column</a></span>, <span name="eps">eps: <span name="scala.Double" class="extype">Double</span></span>, <span name="confidence">confidence: <span name="scala.Double" class="extype">Double</span></span>, <span name="seed">seed: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <a href="../../util/sketch/CountMinSketch.html" name="org.apache.spark.util.sketch.CountMinSketch" id="org.apache.spark.util.sketch.CountMinSketch" class="extype">CountMinSketch</a></span></span><p class="shortcomment cmt">Builds a Count-min Sketch over a specified column.</p><div class="fullcomment"><div class="comment cmt"><p>Builds a Count-min Sketch over a specified column.
</p></div><dl class="paramcmts block"><dt class="param">col</dt><dd class="cmt"><p>
  the column over which the sketch is built</p></dd><dt class="param">eps</dt><dd class="cmt"><p>
  relative error of the sketch</p></dd><dt class="param">confidence</dt><dd class="cmt"><p>
  confidence of the sketch</p></dd><dt class="param">seed</dt><dd class="cmt"><p>
  random seed</p></dd><dt>returns</dt><dd class="cmt"><p>
  a <code>CountMinSketch</code> over column <code>colName</code></p></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameStatFunctions#countMinSketch" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="countMinSketch(col:org.apache.spark.sql.Column,depth:Int,width:Int,seed:Int):org.apache.spark.util.sketch.CountMinSketch" class="anchorToMember"></a><a id="countMinSketch(Column,Int,Int,Int):CountMinSketch" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#countMinSketch(col:org.apache.spark.sql.Column,depth:Int,width:Int,seed:Int):org.apache.spark.util.sketch.CountMinSketch" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">countMinSketch</span><span class="params">(<span name="col">col: <a href="../Column.html" name="org.apache.spark.sql.Column" id="org.apache.spark.sql.Column" class="extype">Column</a></span>, <span name="depth">depth: <span name="scala.Int" class="extype">Int</span></span>, <span name="width">width: <span name="scala.Int" class="extype">Int</span></span>, <span name="seed">seed: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <a href="../../util/sketch/CountMinSketch.html" name="org.apache.spark.util.sketch.CountMinSketch" id="org.apache.spark.util.sketch.CountMinSketch" class="extype">CountMinSketch</a></span></span><p class="shortcomment cmt">Builds a Count-min Sketch over a specified column.</p><div class="fullcomment"><div class="comment cmt"><p>Builds a Count-min Sketch over a specified column.
</p></div><dl class="paramcmts block"><dt class="param">col</dt><dd class="cmt"><p>
  the column over which the sketch is built</p></dd><dt class="param">depth</dt><dd class="cmt"><p>
  depth of the sketch</p></dd><dt class="param">width</dt><dd class="cmt"><p>
  width of the sketch</p></dd><dt class="param">seed</dt><dd class="cmt"><p>
  random seed</p></dd><dt>returns</dt><dd class="cmt"><p>
  a <code>CountMinSketch</code> over column <code>colName</code></p></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameStatFunctions#countMinSketch" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="countMinSketch(colName:String,eps:Double,confidence:Double,seed:Int):org.apache.spark.util.sketch.CountMinSketch" class="anchorToMember"></a><a id="countMinSketch(String,Double,Double,Int):CountMinSketch" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#countMinSketch(colName:String,eps:Double,confidence:Double,seed:Int):org.apache.spark.util.sketch.CountMinSketch" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">countMinSketch</span><span class="params">(<span name="colName">colName: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="eps">eps: <span name="scala.Double" class="extype">Double</span></span>, <span name="confidence">confidence: <span name="scala.Double" class="extype">Double</span></span>, <span name="seed">seed: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <a href="../../util/sketch/CountMinSketch.html" name="org.apache.spark.util.sketch.CountMinSketch" id="org.apache.spark.util.sketch.CountMinSketch" class="extype">CountMinSketch</a></span></span><p class="shortcomment cmt">Builds a Count-min Sketch over a specified column.</p><div class="fullcomment"><div class="comment cmt"><p>Builds a Count-min Sketch over a specified column.
</p></div><dl class="paramcmts block"><dt class="param">colName</dt><dd class="cmt"><p>
  name of the column over which the sketch is built</p></dd><dt class="param">eps</dt><dd class="cmt"><p>
  relative error of the sketch</p></dd><dt class="param">confidence</dt><dd class="cmt"><p>
  confidence of the sketch</p></dd><dt class="param">seed</dt><dd class="cmt"><p>
  random seed</p></dd><dt>returns</dt><dd class="cmt"><p>
  a <code>CountMinSketch</code> over column <code>colName</code></p></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameStatFunctions#countMinSketch" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="countMinSketch(colName:String,depth:Int,width:Int,seed:Int):org.apache.spark.util.sketch.CountMinSketch" class="anchorToMember"></a><a id="countMinSketch(String,Int,Int,Int):CountMinSketch" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#countMinSketch(colName:String,depth:Int,width:Int,seed:Int):org.apache.spark.util.sketch.CountMinSketch" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">countMinSketch</span><span class="params">(<span name="colName">colName: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="depth">depth: <span name="scala.Int" class="extype">Int</span></span>, <span name="width">width: <span name="scala.Int" class="extype">Int</span></span>, <span name="seed">seed: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <a href="../../util/sketch/CountMinSketch.html" name="org.apache.spark.util.sketch.CountMinSketch" id="org.apache.spark.util.sketch.CountMinSketch" class="extype">CountMinSketch</a></span></span><p class="shortcomment cmt">Builds a Count-min Sketch over a specified column.</p><div class="fullcomment"><div class="comment cmt"><p>Builds a Count-min Sketch over a specified column.
</p></div><dl class="paramcmts block"><dt class="param">colName</dt><dd class="cmt"><p>
  name of the column over which the sketch is built</p></dd><dt class="param">depth</dt><dd class="cmt"><p>
  depth of the sketch</p></dd><dt class="param">width</dt><dd class="cmt"><p>
  width of the sketch</p></dd><dt class="param">seed</dt><dd class="cmt"><p>
  random seed</p></dd><dt>returns</dt><dd class="cmt"><p>
  a <code>CountMinSketch</code> over column <code>colName</code></p></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="scala.AnyRef#eq" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="eq(x$1:AnyRef):Boolean" class="anchorToMember"></a><a id="eq(AnyRef):Boolean" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#eq(x$1:AnyRef):Boolean" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">eq</span><span class="params">(<span name="arg0">arg0: <span name="scala.AnyRef" class="extype">AnyRef</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd></dl></div></li><li class="indented0 " name="scala.AnyRef#equals" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="equals(x$1:Object):Boolean" class="anchorToMember"></a><a id="equals(AnyRef):Boolean" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#equals(x$1:Object):Boolean" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">equals</span><span class="params">(<span name="arg0">arg0: <span name="scala.AnyRef" class="extype">AnyRef</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameStatFunctions#freqItems" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="freqItems(cols:Seq[String]):DS[org.apache.spark.sql.Row]" class="anchorToMember"></a><a id="freqItems(Seq[String]):DS[Row]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#freqItems(cols:Seq[String]):DS[org.apache.spark.sql.Row]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">freqItems</span><span class="params">(<span name="cols">cols: <span name="scala.Seq" class="extype">Seq</span>[<span name="scala.Predef.String" class="extype">String</span>]</span>)</span><span class="result">: <span name="org.apache.spark.sql.api.DataFrameStatFunctions.DS" class="extype">DS</span>[<a href="../Row.html" name="org.apache.spark.sql.Row" id="org.apache.spark.sql.Row" class="extype">Row</a>]</span></span><p class="shortcomment cmt">(Scala-specific) Finding frequent items for columns, possibly with false positives.</p><div class="fullcomment"><div class="comment cmt"><p>(Scala-specific) Finding frequent items for columns, possibly with false positives. Using the
frequent element count algorithm described in &lt;a
href="https://doi.org/10.1145/762471.762473"&gt;here</a>, proposed by Karp, Schenker, and
Papadimitriou. Uses a <code>default</code> support of 1%.</p><p>This function is meant for exploratory data analysis, as we make no guarantee about the
backward compatibility of the schema of the resulting <code>DataFrame</code>.
</p></div><dl class="paramcmts block"><dt class="param">cols</dt><dd class="cmt"><p>
  the names of the columns to search frequent items in.</p></dd><dt>returns</dt><dd class="cmt"><p>
  A Local DataFrame with the Array of frequent items for each column.</p></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameStatFunctions#freqItems" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="freqItems(cols:Array[String]):DS[org.apache.spark.sql.Row]" class="anchorToMember"></a><a id="freqItems(Array[String]):DS[Row]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#freqItems(cols:Array[String]):DS[org.apache.spark.sql.Row]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">freqItems</span><span class="params">(<span name="cols">cols: <span name="scala.Array" class="extype">Array</span>[<span name="scala.Predef.String" class="extype">String</span>]</span>)</span><span class="result">: <span name="org.apache.spark.sql.api.DataFrameStatFunctions.DS" class="extype">DS</span>[<a href="../Row.html" name="org.apache.spark.sql.Row" id="org.apache.spark.sql.Row" class="extype">Row</a>]</span></span><p class="shortcomment cmt">Finding frequent items for columns, possibly with false positives.</p><div class="fullcomment"><div class="comment cmt"><p>Finding frequent items for columns, possibly with false positives. Using the frequent element
count algorithm described in <a href="https://doi.org/10.1145/762471.762473">here</a>,
proposed by Karp, Schenker, and Papadimitriou. Uses a <code>default</code> support of 1%.</p><p>This function is meant for exploratory data analysis, as we make no guarantee about the
backward compatibility of the schema of the resulting <code>DataFrame</code>.
</p></div><dl class="paramcmts block"><dt class="param">cols</dt><dd class="cmt"><p>
  the names of the columns to search frequent items in.</p></dd><dt>returns</dt><dd class="cmt"><p>
  A Local DataFrame with the Array of frequent items for each column.</p></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameStatFunctions#freqItems" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="freqItems(cols:Array[String],support:Double):DS[org.apache.spark.sql.Row]" class="anchorToMember"></a><a id="freqItems(Array[String],Double):DS[Row]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#freqItems(cols:Array[String],support:Double):DS[org.apache.spark.sql.Row]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">freqItems</span><span class="params">(<span name="cols">cols: <span name="scala.Array" class="extype">Array</span>[<span name="scala.Predef.String" class="extype">String</span>]</span>, <span name="support">support: <span name="scala.Double" class="extype">Double</span></span>)</span><span class="result">: <span name="org.apache.spark.sql.api.DataFrameStatFunctions.DS" class="extype">DS</span>[<a href="../Row.html" name="org.apache.spark.sql.Row" id="org.apache.spark.sql.Row" class="extype">Row</a>]</span></span><p class="shortcomment cmt">Finding frequent items for columns, possibly with false positives.</p><div class="fullcomment"><div class="comment cmt"><p>Finding frequent items for columns, possibly with false positives. Using the frequent element
count algorithm described in <a href="https://doi.org/10.1145/762471.762473">here</a>,
proposed by Karp, Schenker, and Papadimitriou. The <code>support</code> should be greater than 1e-4.</p><p>This function is meant for exploratory data analysis, as we make no guarantee about the
backward compatibility of the schema of the resulting <code>DataFrame</code>.
</p></div><dl class="paramcmts block"><dt class="param">cols</dt><dd class="cmt"><p>
  the names of the columns to search frequent items in.</p></dd><dt class="param">support</dt><dd class="cmt"><p>
  The minimum frequency for an item to be considered <code>frequent</code>. Should be greater than 1e-4.</p></dd><dt>returns</dt><dd class="cmt"><p>
  A Local DataFrame with the Array of frequent items for each column.</p><pre><span class="kw">val</span> rows = <span class="std">Seq</span>.tabulate(<span class="num">100</span>) { i <span class="kw">=&gt;</span>
  <span class="kw">if</span> (i % <span class="num">2</span> == <span class="num">0</span>) (<span class="num">1</span>, -<span class="num">1.0</span>) <span class="kw">else</span> (i, i * -<span class="num">1.0</span>)
}
<span class="kw">val</span> df = spark.createDataFrame(rows).toDF(<span class="lit">"a"</span>, <span class="lit">"b"</span>)
<span class="cmt">// find the items with a frequency greater than 0.4 (observed 40% of the time) for columns</span>
<span class="cmt">// "a" and "b"</span>
<span class="kw">val</span> freqSingles = df.stat.freqItems(<span class="std">Array</span>(<span class="lit">"a"</span>, <span class="lit">"b"</span>), <span class="num">0.4</span>)
freqSingles.show()
+-----------+-------------+
|a_freqItems|  b_freqItems|
+-----------+-------------+
|    [<span class="num">1</span>, <span class="num">99</span>]|[-<span class="num">1.0</span>, -<span class="num">99.0</span>]|
+-----------+-------------+
<span class="cmt">// find the pair of items with a frequency greater than 0.1 in columns "a" and "b"</span>
<span class="kw">val</span> pairDf = df.select(struct(<span class="lit">"a"</span>, <span class="lit">"b"</span>).as(<span class="lit">"a-b"</span>))
<span class="kw">val</span> freqPairs = pairDf.stat.freqItems(<span class="std">Array</span>(<span class="lit">"a-b"</span>), <span class="num">0.1</span>)
freqPairs.select(explode($<span class="lit">"a-b_freqItems"</span>).as(<span class="lit">"freq_ab"</span>)).show()
+----------+
|   freq_ab|
+----------+
|  [<span class="num">1</span>,-<span class="num">1.0</span>]|
|   ...    |
+----------+</pre></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>1.4.0</p></dd></dl></div></li><li class="indented0 " name="scala.AnyRef#getClass" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="getClass():Class[_]" class="anchorToMember"></a><a id="getClass():Class[_&lt;:AnyRef]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#getClass():Class[_]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">getClass</span><span class="params">()</span><span class="result">: <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Class.html#java.lang.Class" name="java.lang.Class" id="java.lang.Class" class="extype">Class</a>[_ &lt;: <span name="scala.AnyRef" class="extype">AnyRef</span>]</span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef → Any</dd><dt>Annotations</dt><dd><span class="name">@IntrinsicCandidate</span><span class="args">()</span> <span class="name">@native</span><span class="args">()</span> </dd></dl></div></li><li class="indented0 " name="scala.AnyRef#hashCode" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="hashCode():Int" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#hashCode():Int" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">hashCode</span><span class="params">()</span><span class="result">: <span name="scala.Int" class="extype">Int</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef → Any</dd><dt>Annotations</dt><dd><span class="name">@IntrinsicCandidate</span><span class="args">()</span> <span class="name">@native</span><span class="args">()</span> </dd></dl></div></li><li class="indented0 " name="scala.Any#isInstanceOf" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="isInstanceOf[T0]:Boolean" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#isInstanceOf[T0]:Boolean" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">isInstanceOf</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>Any</dd></dl></div></li><li class="indented0 " name="scala.AnyRef#ne" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="ne(x$1:AnyRef):Boolean" class="anchorToMember"></a><a id="ne(AnyRef):Boolean" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#ne(x$1:AnyRef):Boolean" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">ne</span><span class="params">(<span name="arg0">arg0: <span name="scala.AnyRef" class="extype">AnyRef</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd></dl></div></li><li class="indented0 " name="scala.AnyRef#notify" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="notify():Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#notify():Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">notify</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd><span class="name">@IntrinsicCandidate</span><span class="args">()</span> <span class="name">@native</span><span class="args">()</span> </dd></dl></div></li><li class="indented0 " name="scala.AnyRef#notifyAll" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="notifyAll():Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#notifyAll():Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">notifyAll</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd><span class="name">@IntrinsicCandidate</span><span class="args">()</span> <span class="name">@native</span><span class="args">()</span> </dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameStatFunctions#sampleBy" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="sampleBy[T](col:org.apache.spark.sql.Column,fractions:java.util.Map[T,Double],seed:Long):DS[org.apache.spark.sql.Row]" class="anchorToMember"></a><a id="sampleBy[T](Column,Map[T,Double],Long):DS[Row]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#sampleBy[T](col:org.apache.spark.sql.Column,fractions:java.util.Map[T,Double],seed:Long):DS[org.apache.spark.sql.Row]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">sampleBy</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="col">col: <a href="../Column.html" name="org.apache.spark.sql.Column" id="org.apache.spark.sql.Column" class="extype">Column</a></span>, <span name="fractions">fractions: <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/Map.html#java.util.Map" name="java.util.Map" id="java.util.Map" class="extype">Map</a>[<span name="org.apache.spark.sql.api.DataFrameStatFunctions.sampleBy.T" class="extype">T</span>, <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Double.html#java.lang.Double" name="java.lang.Double" id="java.lang.Double" class="extype">Double</a>]</span>, <span name="seed">seed: <span name="scala.Long" class="extype">Long</span></span>)</span><span class="result">: <span name="org.apache.spark.sql.api.DataFrameStatFunctions.DS" class="extype">DS</span>[<a href="../Row.html" name="org.apache.spark.sql.Row" id="org.apache.spark.sql.Row" class="extype">Row</a>]</span></span><p class="shortcomment cmt">(Java-specific) Returns a stratified sample without replacement based on the fraction given
on each stratum.</p><div class="fullcomment"><div class="comment cmt"><p>(Java-specific) Returns a stratified sample without replacement based on the fraction given
on each stratum.
</p></div><dl class="paramcmts block"><dt class="tparam">T</dt><dd class="cmt"><p>
  stratum type</p></dd><dt class="param">col</dt><dd class="cmt"><p>
  column that defines strata</p></dd><dt class="param">fractions</dt><dd class="cmt"><p>
  sampling fraction for each stratum. If a stratum is not specified, we treat its fraction as
  zero.</p></dd><dt class="param">seed</dt><dd class="cmt"><p>
  random seed</p></dd><dt>returns</dt><dd class="cmt"><p>
  a new <code>DataFrame</code> that represents the stratified sample</p></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>3.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameStatFunctions#sampleBy" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="sampleBy[T](col:String,fractions:java.util.Map[T,Double],seed:Long):DS[org.apache.spark.sql.Row]" class="anchorToMember"></a><a id="sampleBy[T](String,Map[T,Double],Long):DS[Row]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#sampleBy[T](col:String,fractions:java.util.Map[T,Double],seed:Long):DS[org.apache.spark.sql.Row]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">sampleBy</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="col">col: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="fractions">fractions: <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/Map.html#java.util.Map" name="java.util.Map" id="java.util.Map" class="extype">Map</a>[<span name="org.apache.spark.sql.api.DataFrameStatFunctions.sampleBy.T" class="extype">T</span>, <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Double.html#java.lang.Double" name="java.lang.Double" id="java.lang.Double" class="extype">Double</a>]</span>, <span name="seed">seed: <span name="scala.Long" class="extype">Long</span></span>)</span><span class="result">: <span name="org.apache.spark.sql.api.DataFrameStatFunctions.DS" class="extype">DS</span>[<a href="../Row.html" name="org.apache.spark.sql.Row" id="org.apache.spark.sql.Row" class="extype">Row</a>]</span></span><p class="shortcomment cmt">Returns a stratified sample without replacement based on the fraction given on each stratum.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a stratified sample without replacement based on the fraction given on each stratum.</p></div><dl class="paramcmts block"><dt class="tparam">T</dt><dd class="cmt"><p>
  stratum type</p></dd><dt class="param">col</dt><dd class="cmt"><p>
  column that defines strata</p></dd><dt class="param">fractions</dt><dd class="cmt"><p>
  sampling fraction for each stratum. If a stratum is not specified, we treat its fraction as
  zero.</p></dd><dt class="param">seed</dt><dd class="cmt"><p>
  random seed</p></dd><dt>returns</dt><dd class="cmt"><p>
  a new <code>DataFrame</code> that represents the stratified sample</p></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>1.5.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.api.DataFrameStatFunctions#sampleBy" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="sampleBy[T](col:String,fractions:Map[T,Double],seed:Long):DS[org.apache.spark.sql.Row]" class="anchorToMember"></a><a id="sampleBy[T](String,Map[T,Double],Long):DS[Row]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#sampleBy[T](col:String,fractions:Map[T,Double],seed:Long):DS[org.apache.spark.sql.Row]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">sampleBy</span><span class="tparams">[<span name="T">T</span>]</span><span class="params">(<span name="col">col: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="fractions">fractions: <span name="scala.Predef.Map" class="extype">Map</span>[<span name="org.apache.spark.sql.api.DataFrameStatFunctions.sampleBy.T" class="extype">T</span>, <span name="scala.Double" class="extype">Double</span>]</span>, <span name="seed">seed: <span name="scala.Long" class="extype">Long</span></span>)</span><span class="result">: <span name="org.apache.spark.sql.api.DataFrameStatFunctions.DS" class="extype">DS</span>[<a href="../Row.html" name="org.apache.spark.sql.Row" id="org.apache.spark.sql.Row" class="extype">Row</a>]</span></span><p class="shortcomment cmt">Returns a stratified sample without replacement based on the fraction given on each stratum.</p><div class="fullcomment"><div class="comment cmt"><p>Returns a stratified sample without replacement based on the fraction given on each stratum.</p></div><dl class="paramcmts block"><dt class="tparam">T</dt><dd class="cmt"><p>
  stratum type</p></dd><dt class="param">col</dt><dd class="cmt"><p>
  column that defines strata</p></dd><dt class="param">fractions</dt><dd class="cmt"><p>
  sampling fraction for each stratum. If a stratum is not specified, we treat its fraction as
  zero.</p></dd><dt class="param">seed</dt><dd class="cmt"><p>
  random seed</p></dd><dt>returns</dt><dd class="cmt"><p>
  a new <code>DataFrame</code> that represents the stratified sample</p><pre><span class="kw">val</span> df = spark.createDataFrame(<span class="std">Seq</span>((<span class="num">1</span>, <span class="num">1</span>), (<span class="num">1</span>, <span class="num">2</span>), (<span class="num">2</span>, <span class="num">1</span>), (<span class="num">2</span>, <span class="num">1</span>), (<span class="num">2</span>, <span class="num">3</span>), (<span class="num">3</span>, <span class="num">2</span>),
  (<span class="num">3</span>, <span class="num">3</span>))).toDF(<span class="lit">"key"</span>, <span class="lit">"value"</span>)
<span class="kw">val</span> fractions = <span class="std">Map</span>(<span class="num">1</span> -&gt; <span class="num">1.0</span>, <span class="num">3</span> -&gt; <span class="num">0.5</span>)
df.stat.sampleBy(<span class="lit">"key"</span>, fractions, <span class="num">36</span>L).show()
+---+-----+
|key|value|
+---+-----+
|  <span class="num">1</span>|    <span class="num">1</span>|
|  <span class="num">1</span>|    <span class="num">2</span>|
|  <span class="num">3</span>|    <span class="num">2</span>|
+---+-----+</pre></dd></dl><dl class="attributes block"><dt>Since</dt><dd><p>1.5.0</p></dd></dl></div></li><li class="indented0 " name="scala.AnyRef#synchronized" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="synchronized[T0](x$1:=&gt;T0):T0" class="anchorToMember"></a><a id="synchronized[T0](=&gt;T0):T0" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#synchronized[T0](x$1:=&gt;T0):T0" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">synchronized</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="params">(<span name="arg0">arg0: =&gt; <span name="java.lang.AnyRef.synchronized.T0" class="extype">T0</span></span>)</span><span class="result">: <span name="java.lang.AnyRef.synchronized.T0" class="extype">T0</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd></dl></div></li><li class="indented0 " name="scala.AnyRef#toString" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="toString():String" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#toString():String" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">toString</span><span class="params">()</span><span class="result">: <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html#java.lang.String" name="java.lang.String" id="java.lang.String" class="extype">String</a></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div></li><li class="indented0 " name="scala.AnyRef#wait" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="wait(x$1:Long,x$2:Int):Unit" class="anchorToMember"></a><a id="wait(Long,Int):Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#wait(x$1:Long,x$2:Int):Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">wait</span><span class="params">(<span name="arg0">arg0: <span name="scala.Long" class="extype">Long</span></span>, <span name="arg1">arg1: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd><span class="name">@throws</span><span class="args">(<span><span class="defval">classOf[java.lang.InterruptedException]</span></span>)</span> </dd></dl></div></li><li class="indented0 " name="scala.AnyRef#wait" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="wait(x$1:Long):Unit" class="anchorToMember"></a><a id="wait(Long):Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#wait(x$1:Long):Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">wait</span><span class="params">(<span name="arg0">arg0: <span name="scala.Long" class="extype">Long</span></span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd><span class="name">@throws</span><span class="args">(<span><span class="defval">classOf[java.lang.InterruptedException]</span></span>)</span> <span class="name">@native</span><span class="args">()</span> </dd></dl></div></li><li class="indented0 " name="scala.AnyRef#wait" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="wait():Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#wait():Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">wait</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd><span class="name">@throws</span><span class="args">(<span><span class="defval">classOf[java.lang.InterruptedException]</span></span>)</span> </dd></dl></div></li></ol></div><div class="values members"><h3>Deprecated Value Members</h3><ol><li class="indented0 " name="scala.AnyRef#finalize" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="prt"><a id="finalize():Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/api/DataFrameStatFunctions.html#finalize():Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name deprecated" title="Deprecated: (Since version 9)">finalize</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Attributes</dt><dd>protected[<span name="java.lang" class="extype">lang</span>] </dd><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd><span class="name">@throws</span><span class="args">(<span><span class="symbol">classOf[java.lang.Throwable]</span></span>)</span> <span class="name">@Deprecated</span> </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 9)</i></p></dd></dl></div></li></ol></div></div><div id="inheritedMembers"><div name="scala.AnyRef" class="parent"><h3>Inherited from <span name="scala.AnyRef" class="extype">AnyRef</span></h3></div><div name="scala.Any" class="parent"><h3>Inherited from <span name="scala.Any" class="extype">Any</span></h3></div></div><div id="groupedMembers"><div name="Ungrouped" class="group"><h3>Ungrouped</h3></div></div></div><div id="tooltip"></div><div id="footer"></div></body></div></div></div></body></html>
