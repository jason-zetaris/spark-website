<!DOCTYPE html ><html><head><meta http-equiv="X-UA-Compatible" content="IE=edge"/><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" name="viewport"/><title>Spark 4.0.0-preview2 ScalaDoc  - org.apache.spark.sql.connector.catalog</title><meta content="Spark 4.0.0 - preview2 ScalaDoc - org.apache.spark.sql.connector.catalog" name="description"/><meta content="Spark 4.0.0 preview2 ScalaDoc org.apache.spark.sql.connector.catalog" name="keywords"/><meta http-equiv="content-type" content="text/html; charset=UTF-8"/><link href="../../../../../../lib/index.css" media="screen" type="text/css" rel="stylesheet"/><link href="../../../../../../lib/template.css" media="screen" type="text/css" rel="stylesheet"/><link href="../../../../../../lib/print.css" media="print" type="text/css" rel="stylesheet"/><link href="../../../../../../lib/diagrams.css" media="screen" type="text/css" rel="stylesheet" id="diagrams-css"/><script type="text/javascript" src="../../../../../../lib/jquery.min.js"></script><script type="text/javascript" src="../../../../../../lib/index.js"></script><script type="text/javascript" src="../../../../../../index.js"></script><script type="text/javascript" src="../../../../../../lib/scheduler.js"></script><script type="text/javascript" src="../../../../../../lib/template.js"></script><script type="text/javascript">/* this variable can be used by the JS to determine the path to the root document */
var toRoot = '../../../../../../';</script></head><body><div id="search"><span id="doc-title">Spark 4.0.0-preview2 ScalaDoc<span id="doc-version"></span></span> <span class="close-results"><span class="left">&lt;</span> Back</span><div id="textfilter"><span class="input"><input autocapitalize="none" placeholder="Search" id="index-input" type="text" accesskey="/"/><i class="clear material-icons"></i><i id="search-icon" class="material-icons"></i></span></div></div><div id="search-results"><div id="search-progress"><div id="progress-fill"></div></div><div id="results-content"><div id="entity-results"></div><div id="member-results"></div></div></div><div id="content-scroll-container" style="-webkit-overflow-scrolling: touch;"><div id="content-container" style="-webkit-overflow-scrolling: touch;"><div id="subpackage-spacer"><div id="packages"><h1>Packages</h1><ul><li class="indented0 " name="_root_.root" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="_root_" class="anchorToMember"></a><a id="root:_root_" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../../../../../index.html" title=""><span class="name">root</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../../../../index.html" name="_root_" id="_root_" class="extype">root</a></dd></dl></div></li><li class="indented1 " name="_root_.org" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="org" class="anchorToMember"></a><a id="org:org" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../../../../index.html" title=""><span class="name">org</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../../../../index.html" name="_root_" id="_root_" class="extype">root</a></dd></dl></div></li><li class="indented2 " name="org.apache" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="apache" class="anchorToMember"></a><a id="apache:apache" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../../../index.html" title=""><span class="name">apache</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../../../index.html" name="org" id="org" class="extype">org</a></dd></dl></div></li><li class="indented3 " name="org.apache.spark" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="spark" class="anchorToMember"></a><a id="spark:spark" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../../index.html" title="Core Spark functionality."><span class="name">spark</span></a></span><p class="shortcomment cmt">Core Spark functionality.</p><div class="fullcomment"><div class="comment cmt"><p>Core Spark functionality. <a href="../../../SparkContext.html" name="org.apache.spark.SparkContext" id="org.apache.spark.SparkContext" class="extype">org.apache.spark.SparkContext</a> serves as the main entry point to
Spark, while <a href="../../../rdd/RDD.html" name="org.apache.spark.rdd.RDD" id="org.apache.spark.rdd.RDD" class="extype">org.apache.spark.rdd.RDD</a> is the data type representing a distributed collection,
and provides most parallel operations.</p><p>In addition, <a href="../../../rdd/PairRDDFunctions.html" name="org.apache.spark.rdd.PairRDDFunctions" id="org.apache.spark.rdd.PairRDDFunctions" class="extype">org.apache.spark.rdd.PairRDDFunctions</a> contains operations available only on RDDs
of key-value pairs, such as <code>groupByKey</code> and <code>join</code>; <a href="../../../rdd/DoubleRDDFunctions.html" name="org.apache.spark.rdd.DoubleRDDFunctions" id="org.apache.spark.rdd.DoubleRDDFunctions" class="extype">org.apache.spark.rdd.DoubleRDDFunctions</a>
contains operations available only on RDDs of Doubles; and
<a href="../../../rdd/SequenceFileRDDFunctions.html" name="org.apache.spark.rdd.SequenceFileRDDFunctions" id="org.apache.spark.rdd.SequenceFileRDDFunctions" class="extype">org.apache.spark.rdd.SequenceFileRDDFunctions</a> contains operations available on RDDs that can
be saved as SequenceFiles. These operations are automatically available on any RDD of the right
type (e.g. RDD[(Int, Int)] through implicit conversions.</p><p>Java programmers should reference the <a href="../../../api/java/index.html" name="org.apache.spark.api.java" id="org.apache.spark.api.java" class="extype">org.apache.spark.api.java</a> package
for Spark programming APIs in Java.</p><p>Classes and methods marked with <span class="experimental badge" style="float: none;">
Experimental</span> are user-facing features which have not been officially adopted by the
Spark project. These are subject to change or removal in minor releases.</p><p>Classes and methods marked with <span class="developer badge" style="float: none;">
Developer API</span> are intended for advanced users want to extend Spark through lower
level interfaces. These are subject to changes or removal in minor releases.
</p></div><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../../index.html" name="org.apache" id="org.apache" class="extype">apache</a></dd></dl></div></li><li class="indented4 " name="org.apache.spark.sql" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="sql" class="anchorToMember"></a><a id="sql:sql" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../index.html" title="Allows the execution of relational queries, including those expressed in SQL using Spark."><span class="name">sql</span></a></span><p class="shortcomment cmt">Allows the execution of relational queries, including those expressed in SQL using Spark.</p><div class="fullcomment"><div class="comment cmt"><p>Allows the execution of relational queries, including those expressed in SQL using Spark.
</p></div><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../index.html" name="org.apache.spark" id="org.apache.spark" class="extype">spark</a></dd></dl></div></li><li class="indented5 " name="org.apache.spark.sql.connector" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="connector" class="anchorToMember"></a><a id="connector:connector" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../index.html" title=""><span class="name">connector</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../index.html" name="org.apache.spark.sql" id="org.apache.spark.sql" class="extype">sql</a></dd></dl></div></li><li class="indented6 current" name="org.apache.spark.sql.connector.catalog" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="catalog" class="anchorToMember"></a><a id="catalog:catalog" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><span class="name">catalog</span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../index.html" name="org.apache.spark.sql.connector" id="org.apache.spark.sql.connector" class="extype">connector</a></dd></dl></div></li><li class="indented7 " name="org.apache.spark.sql.connector.catalog.functions" group="Ungrouped" fullComment="no" data-isabs="false" visbl="pub"><a id="functions" class="anchorToMember"></a><a id="functions:functions" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/functions/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="functions/index.html" title=""><span class="name">functions</span></a></span></li><li class="indented7 " name="org.apache.spark.sql.connector.catalog.index" group="Ungrouped" fullComment="no" data-isabs="false" visbl="pub"><a id="index" class="anchorToMember"></a><a id="index:index" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/index/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="index/index.html" title=""><span class="name">index</span></a></span></li><li class="indented7 " name="org.apache.spark.sql.connector.catalog.procedures" group="Ungrouped" fullComment="no" data-isabs="false" visbl="pub"><a id="procedures" class="anchorToMember"></a><a id="procedures:procedures" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/procedures/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="procedures/index.html" title=""><span class="name">procedures</span></a></span></li><li class="current-entities indented6"><span class="separator"></span> <a href="CatalogExtension.html" title="An API to extend the Spark built-in session catalog." class="trait"></a><a href="CatalogExtension.html" title="An API to extend the Spark built-in session catalog.">CatalogExtension</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="CatalogNotFoundException.html" title="" class="class"></a><a href="CatalogNotFoundException.html" title="">CatalogNotFoundException</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="CatalogPlugin.html" title="A marker interface to provide a catalog implementation for Spark." class="trait"></a><a href="CatalogPlugin.html" title="A marker interface to provide a catalog implementation for Spark.">CatalogPlugin</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="Column.html" title="An interface representing a column of a Table." class="trait"></a><a href="Column.html" title="An interface representing a column of a Table.">Column</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="ColumnDefaultValue.html" title="A class representing the default value of a column." class="class"></a><a href="ColumnDefaultValue.html" title="A class representing the default value of a column.">ColumnDefaultValue</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="DelegatingCatalogExtension.html" title="A simple implementation of CatalogExtension, which implements all the catalog functions by calling the built-in session catalog directly." class="class"></a><a href="DelegatingCatalogExtension.html" title="A simple implementation of CatalogExtension, which implements all the catalog functions by calling the built-in session catalog directly.">DelegatingCatalogExtension</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="FunctionCatalog.html" title="Catalog methods for working with Functions." class="trait"></a><a href="FunctionCatalog.html" title="Catalog methods for working with Functions.">FunctionCatalog</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="Identifier.html" title="Identifies an object in a catalog." class="trait"></a><a href="Identifier.html" title="Identifies an object in a catalog.">Identifier</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="IdentityColumnSpec.html" title="Identity column specification." class="class"></a><a href="IdentityColumnSpec.html" title="Identity column specification.">IdentityColumnSpec</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="MetadataColumn.html" title="Interface for a metadata column." class="trait"></a><a href="MetadataColumn.html" title="Interface for a metadata column.">MetadataColumn</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="NamespaceChange.html" title="NamespaceChange subclasses represent requested changes to a namespace." class="trait"></a><a href="NamespaceChange.html" title="NamespaceChange subclasses represent requested changes to a namespace.">NamespaceChange</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="ProcedureCatalog.html" title="A catalog API for working with procedures." class="trait"></a><a href="ProcedureCatalog.html" title="A catalog API for working with procedures.">ProcedureCatalog</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="SessionConfigSupport.html" title="A mix-in interface for TableProvider." class="trait"></a><a href="SessionConfigSupport.html" title="A mix-in interface for TableProvider.">SessionConfigSupport</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="StagedTable.html" title="Represents a table which is staged for being committed to the metastore." class="trait"></a><a href="StagedTable.html" title="Represents a table which is staged for being committed to the metastore.">StagedTable</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="StagingTableCatalog.html" title="An optional mix-in for implementations of TableCatalog that support staging creation of the a table before committing the table's metadata along with its contents in CREATE TABLE AS SELECT or REPLACE TABLE AS SELECT operations." class="trait"></a><a href="StagingTableCatalog.html" title="An optional mix-in for implementations of TableCatalog that support staging creation of the a table before committing the table's metadata along with its contents in CREATE TABLE AS SELECT or REPLACE TABLE AS SELECT operations.">StagingTableCatalog</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="SupportsAtomicPartitionManagement.html" title="An atomic partition interface of Table to operate multiple partitions atomically." class="trait"></a><a href="SupportsAtomicPartitionManagement.html" title="An atomic partition interface of Table to operate multiple partitions atomically.">SupportsAtomicPartitionManagement</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="SupportsCatalogOptions.html" title="An interface, which TableProviders can implement, to support table existence checks and creation through a catalog, without having to use table identifiers." class="trait"></a><a href="SupportsCatalogOptions.html" title="An interface, which TableProviders can implement, to support table existence checks and creation through a catalog, without having to use table identifiers.">SupportsCatalogOptions</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="SupportsDelete.html" title="A mix-in interface for Table delete support." class="trait"></a><a href="SupportsDelete.html" title="A mix-in interface for Table delete support.">SupportsDelete</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="SupportsDeleteV2.html" title="A mix-in interface for Table delete support." class="trait"></a><a href="SupportsDeleteV2.html" title="A mix-in interface for Table delete support.">SupportsDeleteV2</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="SupportsMetadataColumns.html" title="An interface for exposing data columns for a table that are not in the table schema." class="trait"></a><a href="SupportsMetadataColumns.html" title="An interface for exposing data columns for a table that are not in the table schema.">SupportsMetadataColumns</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="SupportsNamespaces.html" title="Catalog methods for working with namespaces." class="trait"></a><a href="SupportsNamespaces.html" title="Catalog methods for working with namespaces.">SupportsNamespaces</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="SupportsPartitionManagement.html" title="A partition interface of Table." class="trait"></a><a href="SupportsPartitionManagement.html" title="A partition interface of Table.">SupportsPartitionManagement</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="SupportsRead.html" title="A mix-in interface of Table, to indicate that it's readable." class="trait"></a><a href="SupportsRead.html" title="A mix-in interface of Table, to indicate that it's readable.">SupportsRead</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="SupportsRowLevelOperations.html" title="A mix-in interface for Table row-level operations support." class="trait"></a><a href="SupportsRowLevelOperations.html" title="A mix-in interface for Table row-level operations support.">SupportsRowLevelOperations</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="SupportsWrite.html" title="A mix-in interface of Table, to indicate that it's writable." class="trait"></a><a href="SupportsWrite.html" title="A mix-in interface of Table, to indicate that it's writable.">SupportsWrite</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="Table.html" title="An interface representing a logical structured data set of a data source." class="trait"></a><a href="Table.html" title="An interface representing a logical structured data set of a data source.">Table</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="TableCapability.html" title="Capabilities that can be provided by a Table implementation." class="class"></a><a href="TableCapability.html" title="Capabilities that can be provided by a Table implementation.">TableCapability</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="TableCatalog.html" title="Catalog methods for working with Tables." class="trait"></a><a href="TableCatalog.html" title="Catalog methods for working with Tables.">TableCatalog</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="TableCatalogCapability.html" title="Capabilities that can be provided by a TableCatalog implementation." class="class"></a><a href="TableCatalogCapability.html" title="Capabilities that can be provided by a TableCatalog implementation.">TableCatalogCapability</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="TableChange.html" title="TableChange subclasses represent requested changes to a table." class="trait"></a><a href="TableChange.html" title="TableChange subclasses represent requested changes to a table.">TableChange</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="TableProvider.html" title="The base interface for v2 data sources which don't have a real catalog." class="trait"></a><a href="TableProvider.html" title="The base interface for v2 data sources which don't have a real catalog.">TableProvider</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="TableWritePrivilege.html" title="The table write privileges that will be provided when loading a table." class="class"></a><a href="TableWritePrivilege.html" title="The table write privileges that will be provided when loading a table.">TableWritePrivilege</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="TruncatableTable.html" title="Represents a table which can be atomically truncated." class="trait"></a><a href="TruncatableTable.html" title="Represents a table which can be atomically truncated.">TruncatableTable</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="View.html" title="An interface representing a persisted view." class="trait"></a><a href="View.html" title="An interface representing a persisted view.">View</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="ViewCatalog.html" title="Catalog methods for working with views." class="trait"></a><a href="ViewCatalog.html" title="Catalog methods for working with views.">ViewCatalog</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="ViewChange.html" title="ViewChange subclasses represent requested changes to a view." class="trait"></a><a href="ViewChange.html" title="ViewChange subclasses represent requested changes to a view.">ViewChange</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="ViewInfo.html" title="A class that holds view information." class="class"></a><a href="ViewInfo.html" title="A class that holds view information.">ViewInfo</a></li><li class="indented6 " name="org.apache.spark.sql.connector.distributions" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="distributions" class="anchorToMember"></a><a id="distributions:distributions" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/distributions/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../distributions/index.html" title=""><span class="name">distributions</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../index.html" name="org.apache.spark.sql.connector" id="org.apache.spark.sql.connector" class="extype">connector</a></dd></dl></div></li><li class="indented6 " name="org.apache.spark.sql.connector.expressions" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="expressions" class="anchorToMember"></a><a id="expressions:expressions" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/expressions/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../expressions/index.html" title=""><span class="name">expressions</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../index.html" name="org.apache.spark.sql.connector" id="org.apache.spark.sql.connector" class="extype">connector</a></dd></dl></div></li><li class="indented6 " name="org.apache.spark.sql.connector.metric" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="metric" class="anchorToMember"></a><a id="metric:metric" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/metric/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../metric/index.html" title=""><span class="name">metric</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../index.html" name="org.apache.spark.sql.connector" id="org.apache.spark.sql.connector" class="extype">connector</a></dd></dl></div></li><li class="indented6 " name="org.apache.spark.sql.connector.read" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="read" class="anchorToMember"></a><a id="read:read" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/read/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../read/index.html" title=""><span class="name">read</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../index.html" name="org.apache.spark.sql.connector" id="org.apache.spark.sql.connector" class="extype">connector</a></dd></dl></div></li><li class="indented6 " name="org.apache.spark.sql.connector.util" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="util" class="anchorToMember"></a><a id="util:util" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/util/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../util/index.html" title=""><span class="name">util</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../index.html" name="org.apache.spark.sql.connector" id="org.apache.spark.sql.connector" class="extype">connector</a></dd></dl></div></li><li class="indented6 " name="org.apache.spark.sql.connector.write" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="write" class="anchorToMember"></a><a id="write:write" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/write/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../write/index.html" title=""><span class="name">write</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../index.html" name="org.apache.spark.sql.connector" id="org.apache.spark.sql.connector" class="extype">connector</a></dd></dl></div></li></ul></div></div><div id="content"><body class="package value"><div id="definition"><div class="big-circle package">p</div><p id="owner"><a href="../../../../../index.html" name="org" id="org" class="extype">org</a>.<a href="../../../../index.html" name="org.apache" id="org.apache" class="extype">apache</a>.<a href="../../../index.html" name="org.apache.spark" id="org.apache.spark" class="extype">spark</a>.<a href="../../index.html" name="org.apache.spark.sql" id="org.apache.spark.sql" class="extype">sql</a>.<a href="../index.html" name="org.apache.spark.sql.connector" id="org.apache.spark.sql.connector" class="extype">connector</a></p><h1>catalog<span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/index.html" title="Permalink"><i class="material-icons"></i></a></span></h1></div><h4 id="signature" class="signature"><span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><span class="name">catalog</span></span></h4><div id="comment" class="fullcommenttop"></div><div id="template"><div id="allMembers"><div id="packages" class="package members"><h3>Package Members</h3><ol><li class="indented0 " name="org.apache.spark.sql.connector.catalog.functions" group="Ungrouped" fullComment="no" data-isabs="false" visbl="pub"><a id="functions" class="anchorToMember"></a><a id="functions:functions" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/functions/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="functions/index.html" title=""><span class="name">functions</span></a></span></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.index" group="Ungrouped" fullComment="no" data-isabs="false" visbl="pub"><a id="index" class="anchorToMember"></a><a id="index:index" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/index/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="index/index.html" title=""><span class="name">index</span></a></span></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.procedures" group="Ungrouped" fullComment="no" data-isabs="false" visbl="pub"><a id="procedures" class="anchorToMember"></a><a id="procedures:procedures" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/procedures/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="procedures/index.html" title=""><span class="name">procedures</span></a></span></li></ol></div><div id="types" class="types members"><h3>Type Members</h3><ol><li class="indented0 " name="org.apache.spark.sql.connector.catalog.CatalogExtension" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="CatalogExtensionextendsTableCatalogwithFunctionCatalogwithSupportsNamespaces" class="anchorToMember"></a><a id="CatalogExtension:CatalogExtension" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/CatalogExtension.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="CatalogExtension.html" title="An API to extend the Spark built-in session catalog."><span class="name">CatalogExtension</span></a><span class="result"> extends <a href="TableCatalog.html" name="org.apache.spark.sql.connector.catalog.TableCatalog" id="org.apache.spark.sql.connector.catalog.TableCatalog" class="extype">TableCatalog</a> with <a href="FunctionCatalog.html" name="org.apache.spark.sql.connector.catalog.FunctionCatalog" id="org.apache.spark.sql.connector.catalog.FunctionCatalog" class="extype">FunctionCatalog</a> with <a href="SupportsNamespaces.html" name="org.apache.spark.sql.connector.catalog.SupportsNamespaces" id="org.apache.spark.sql.connector.catalog.SupportsNamespaces" class="extype">SupportsNamespaces</a></span></span><p class="shortcomment cmt">An API to extend the Spark built-in session catalog.</p><div class="fullcomment"><div class="comment cmt"><p>An API to extend the Spark built-in session catalog. Implementation can get the built-in session
catalog from <code><span name="#setDelegateCatalog(CatalogPlugin)" class="extype">#setDelegateCatalog(CatalogPlugin)</span></code>, implement catalog functions with
some custom logic and call the built-in session catalog at the end. For example, they can
implement <code>createTable</code>, do something else before calling <code>createTable</code> of the
built-in session catalog.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.CatalogNotFoundException" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="CatalogNotFoundExceptionextendsSparkException" class="anchorToMember"></a><a id="CatalogNotFoundException:CatalogNotFoundException" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/CatalogNotFoundException.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">class</span></span> <span class="symbol"><a href="CatalogNotFoundException.html" title=""><span class="name">CatalogNotFoundException</span></a><span class="result"> extends <a href="../../../SparkException.html" name="org.apache.spark.SparkException" id="org.apache.spark.SparkException" class="extype">SparkException</a></span></span><div class="fullcomment"><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Experimental</span><span class="args">()</span> </dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.CatalogPlugin" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="CatalogPluginextendsObject" class="anchorToMember"></a><a id="CatalogPlugin:CatalogPlugin" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/CatalogPlugin.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="CatalogPlugin.html" title="A marker interface to provide a catalog implementation for Spark."><span class="name">CatalogPlugin</span></a><span class="result"> extends <span name="scala.AnyRef" class="extype">AnyRef</span></span></span><p class="shortcomment cmt">A marker interface to provide a catalog implementation for Spark.</p><div class="fullcomment"><div class="comment cmt"><p>A marker interface to provide a catalog implementation for Spark.</p><p>Implementations can provide catalog functions by implementing additional interfaces for tables,
views, and functions.</p><p>Catalog implementations must implement this marker interface to be loaded by
<code><span name="Catalogs#load(String," class="extype">SQLConf)</span></code>. The loader will instantiate catalog classes using the
required public no-arg constructor. After creating an instance, it will be configured by calling
<code><span name="#initialize(String," class="extype">CaseInsensitiveStringMap)</span></code>.</p><p>Catalog implementations are registered to a name by adding a configuration option to Spark:
<code>spark.sql.catalog.catalog-name=com.example.YourCatalogClass</code>. All configuration properties
in the Spark configuration that share the catalog name prefix,
<code>spark.sql.catalog.catalog-name.(key)=(value)</code> will be passed in the case insensitive
string map of options in initialization with the prefix removed.
<code>name</code>, is also passed and is the catalog's name; in this case, "catalog-name".
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.Column" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="ColumnextendsObject" class="anchorToMember"></a><a id="Column:Column" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/Column.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="Column.html" title="An interface representing a column of a Table."><span class="name">Column</span></a><span class="result"> extends <span name="scala.AnyRef" class="extype">AnyRef</span></span></span><p class="shortcomment cmt">An interface representing a column of a <code><a href="Table.html" name="org.apache.spark.sql.connector.catalog.Table" id="org.apache.spark.sql.connector.catalog.Table" class="extype">Table</a></code>.</p><div class="fullcomment"><div class="comment cmt"><p>An interface representing a column of a <code><a href="Table.html" name="org.apache.spark.sql.connector.catalog.Table" id="org.apache.spark.sql.connector.catalog.Table" class="extype">Table</a></code>. It defines basic properties of a column,
such as name and data type, as well as some advanced ones like default column value.</p><p>Data Sources do not need to implement it. They should consume it in APIs like
<code><span name="TableCatalog#createTable(Identifier," class="extype">Column[], Transform[], Map)</span></code>, and report it in
<code><span name="Table#columns()" class="extype">Table#columns()</span></code> by calling the static <code>create</code> functions of this interface to
create it.</p><p>A column cannot have both a default value and a generation expression.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.ColumnDefaultValue" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="ColumnDefaultValueextendsObject" class="anchorToMember"></a><a id="ColumnDefaultValue:ColumnDefaultValue" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/ColumnDefaultValue.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">class</span></span> <span class="symbol"><a href="ColumnDefaultValue.html" title="A class representing the default value of a column."><span class="name">ColumnDefaultValue</span></a><span class="result"> extends <span name="scala.AnyRef" class="extype">AnyRef</span></span></span><p class="shortcomment cmt">A class representing the default value of a column.</p><div class="fullcomment"><div class="comment cmt"><p>A class representing the default value of a column. It contains both the SQL string and literal
value of the user-specified default value expression. The SQL string should be re-evaluated for
each table writing command, which may produce different values if the default value expression is
something like <code>CURRENT_DATE()</code>. The literal value is used to back-fill existing data if
new columns with default value are added. Note: the back-fill can be lazy. The data sources can
remember the column default value and let the reader fill the column value when reading existing
data that do not have these new columns.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.DelegatingCatalogExtension" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="DelegatingCatalogExtensionextendsCatalogExtension" class="anchorToMember"></a><a id="DelegatingCatalogExtension:DelegatingCatalogExtension" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/DelegatingCatalogExtension.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">abstract </span> <span class="kind">class</span></span> <span class="symbol"><a href="DelegatingCatalogExtension.html" title="A simple implementation of CatalogExtension, which implements all the catalog functions by calling the built-in session catalog directly."><span class="name">DelegatingCatalogExtension</span></a><span class="result"> extends <a href="CatalogExtension.html" name="org.apache.spark.sql.connector.catalog.CatalogExtension" id="org.apache.spark.sql.connector.catalog.CatalogExtension" class="extype">CatalogExtension</a></span></span><p class="shortcomment cmt">A simple implementation of <code><a href="CatalogExtension.html" name="org.apache.spark.sql.connector.catalog.CatalogExtension" id="org.apache.spark.sql.connector.catalog.CatalogExtension" class="extype">CatalogExtension</a></code>, which implements all the catalog functions
by calling the built-in session catalog directly.</p><div class="fullcomment"><div class="comment cmt"><p>A simple implementation of <code><a href="CatalogExtension.html" name="org.apache.spark.sql.connector.catalog.CatalogExtension" id="org.apache.spark.sql.connector.catalog.CatalogExtension" class="extype">CatalogExtension</a></code>, which implements all the catalog functions
by calling the built-in session catalog directly. This is created for convenience, so that users
only need to override some methods where they want to apply custom logic. For example, they can
override <code>createTable</code>, do something else before calling <code>super.createTable</code>.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.FunctionCatalog" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="FunctionCatalogextendsCatalogPlugin" class="anchorToMember"></a><a id="FunctionCatalog:FunctionCatalog" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/FunctionCatalog.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="FunctionCatalog.html" title="Catalog methods for working with Functions."><span class="name">FunctionCatalog</span></a><span class="result"> extends <a href="CatalogPlugin.html" name="org.apache.spark.sql.connector.catalog.CatalogPlugin" id="org.apache.spark.sql.connector.catalog.CatalogPlugin" class="extype">CatalogPlugin</a></span></span><p class="shortcomment cmt">Catalog methods for working with Functions.</p><div class="fullcomment"><div class="comment cmt"><p>Catalog methods for working with Functions.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.2.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.Identifier" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="IdentifierextendsObject" class="anchorToMember"></a><a id="Identifier:Identifier" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/Identifier.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="Identifier.html" title="Identifies an object in a catalog."><span class="name">Identifier</span></a><span class="result"> extends <span name="scala.AnyRef" class="extype">AnyRef</span></span></span><p class="shortcomment cmt">Identifies an object in a catalog.</p><div class="fullcomment"><div class="comment cmt"><p>Identifies an object in a catalog.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.IdentityColumnSpec" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="IdentityColumnSpecextendsObject" class="anchorToMember"></a><a id="IdentityColumnSpec:IdentityColumnSpec" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/IdentityColumnSpec.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">class</span></span> <span class="symbol"><a href="IdentityColumnSpec.html" title="Identity column specification."><span class="name">IdentityColumnSpec</span></a><span class="result"> extends <span name="scala.AnyRef" class="extype">AnyRef</span></span></span><p class="shortcomment cmt">Identity column specification.</p><div class="fullcomment"><div class="comment cmt"><p>Identity column specification.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.MetadataColumn" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="MetadataColumnextendsObject" class="anchorToMember"></a><a id="MetadataColumn:MetadataColumn" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/MetadataColumn.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="MetadataColumn.html" title="Interface for a metadata column."><span class="name">MetadataColumn</span></a><span class="result"> extends <span name="scala.AnyRef" class="extype">AnyRef</span></span></span><p class="shortcomment cmt">Interface for a metadata column.</p><div class="fullcomment"><div class="comment cmt"><p>Interface for a metadata column.</p><p>A metadata column can expose additional metadata about a row. For example, rows from Kafka can
use metadata columns to expose a message's topic, partition number, and offset.</p><p>A metadata column could also be the result of a transform applied to a value in the row. For
example, a partition value produced by bucket(id, 16) could be exposed by a metadata column. In
this case, <code><span name="#transform()" class="extype">#transform()</span></code> should return a non-null <code><span name="Transform" class="extype">Transform</span></code> that produced the
metadata column's values.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.1.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.NamespaceChange" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="NamespaceChangeextendsObject" class="anchorToMember"></a><a id="NamespaceChange:NamespaceChange" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/NamespaceChange.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="NamespaceChange.html" title="NamespaceChange subclasses represent requested changes to a namespace."><span class="name">NamespaceChange</span></a><span class="result"> extends <span name="scala.AnyRef" class="extype">AnyRef</span></span></span><p class="shortcomment cmt">NamespaceChange subclasses represent requested changes to a namespace.</p><div class="fullcomment"><div class="comment cmt"><p>NamespaceChange subclasses represent requested changes to a namespace. These are passed to
<code><a href="SupportsNamespaces.html#alterNamespace(namespace:Array[String],changes:org.apache.spark.sql.connector.catalog.NamespaceChange*):Unit" name="org.apache.spark.sql.connector.catalog.SupportsNamespaces#alterNamespace" id="org.apache.spark.sql.connector.catalog.SupportsNamespaces#alterNamespace" class="extmbr">SupportsNamespaces#alterNamespace</a></code>. For example,
<pre>
  import NamespaceChange._
  val catalog = Catalogs.load(name)
  catalog.alterNamespace(ident,
      setProperty("prop", "value"),
      removeProperty("other_prop")
    )
</pre>
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.ProcedureCatalog" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="ProcedureCatalogextendsCatalogPlugin" class="anchorToMember"></a><a id="ProcedureCatalog:ProcedureCatalog" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/ProcedureCatalog.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="ProcedureCatalog.html" title="A catalog API for working with procedures."><span class="name">ProcedureCatalog</span></a><span class="result"> extends <a href="CatalogPlugin.html" name="org.apache.spark.sql.connector.catalog.CatalogPlugin" id="org.apache.spark.sql.connector.catalog.CatalogPlugin" class="extype">CatalogPlugin</a></span></span><p class="shortcomment cmt">A catalog API for working with procedures.</p><div class="fullcomment"><div class="comment cmt"><p>A catalog API for working with procedures.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>4.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.SessionConfigSupport" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="SessionConfigSupportextendsTableProvider" class="anchorToMember"></a><a id="SessionConfigSupport:SessionConfigSupport" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/SessionConfigSupport.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="SessionConfigSupport.html" title="A mix-in interface for TableProvider."><span class="name">SessionConfigSupport</span></a><span class="result"> extends <a href="TableProvider.html" name="org.apache.spark.sql.connector.catalog.TableProvider" id="org.apache.spark.sql.connector.catalog.TableProvider" class="extype">TableProvider</a></span></span><p class="shortcomment cmt">A mix-in interface for <code><a href="TableProvider.html" name="org.apache.spark.sql.connector.catalog.TableProvider" id="org.apache.spark.sql.connector.catalog.TableProvider" class="extype">TableProvider</a></code>.</p><div class="fullcomment"><div class="comment cmt"><p>A mix-in interface for <code><a href="TableProvider.html" name="org.apache.spark.sql.connector.catalog.TableProvider" id="org.apache.spark.sql.connector.catalog.TableProvider" class="extype">TableProvider</a></code>. Data sources can implement this interface to
propagate session configs with the specified key-prefix to all data source operations in this
session.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.StagedTable" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="StagedTableextendsTable" class="anchorToMember"></a><a id="StagedTable:StagedTable" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/StagedTable.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="StagedTable.html" title="Represents a table which is staged for being committed to the metastore."><span class="name">StagedTable</span></a><span class="result"> extends <a href="Table.html" name="org.apache.spark.sql.connector.catalog.Table" id="org.apache.spark.sql.connector.catalog.Table" class="extype">Table</a></span></span><p class="shortcomment cmt">Represents a table which is staged for being committed to the metastore.</p><div class="fullcomment"><div class="comment cmt"><p>Represents a table which is staged for being committed to the metastore.</p><p>This is used to implement atomic CREATE TABLE AS SELECT and REPLACE TABLE AS SELECT queries. The
planner will create one of these via
<code><span name="StagingTableCatalog#stageCreate(Identifier," class="extype">StructType, Transform[], Map)</span></code> or
<code><span name="StagingTableCatalog#stageReplace(Identifier," class="extype">StructType, Transform[], Map)</span></code> to prepare the
table for being written to. This table should usually implement <code><a href="SupportsWrite.html" name="org.apache.spark.sql.connector.catalog.SupportsWrite" id="org.apache.spark.sql.connector.catalog.SupportsWrite" class="extype">SupportsWrite</a></code>. A new
writer will be constructed via <code><span name="SupportsWrite#newWriteBuilder(LogicalWriteInfo)" class="extype">SupportsWrite#newWriteBuilder(LogicalWriteInfo)</span></code>, and the
write will be committed. The job concludes with a call to <code><span name="#commitStagedChanges()" class="extype">#commitStagedChanges()</span></code>, at
which point implementations are expected to commit the table's metadata into the metastore along
with the data that was written by the writes from the write builder this table created.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.StagingTableCatalog" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="StagingTableCatalogextendsTableCatalog" class="anchorToMember"></a><a id="StagingTableCatalog:StagingTableCatalog" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/StagingTableCatalog.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="StagingTableCatalog.html" title="An optional mix-in for implementations of TableCatalog that support staging creation of the a table before committing the table's metadata along with its contents in CREATE TABLE AS SELECT or REPLACE TABLE AS SELECT operations."><span class="name">StagingTableCatalog</span></a><span class="result"> extends <a href="TableCatalog.html" name="org.apache.spark.sql.connector.catalog.TableCatalog" id="org.apache.spark.sql.connector.catalog.TableCatalog" class="extype">TableCatalog</a></span></span><p class="shortcomment cmt">An optional mix-in for implementations of <code><a href="TableCatalog.html" name="org.apache.spark.sql.connector.catalog.TableCatalog" id="org.apache.spark.sql.connector.catalog.TableCatalog" class="extype">TableCatalog</a></code> that support staging creation of
the a table before committing the table's metadata along with its contents in CREATE TABLE AS
SELECT or REPLACE TABLE AS SELECT operations.</p><div class="fullcomment"><div class="comment cmt"><p>An optional mix-in for implementations of <code><a href="TableCatalog.html" name="org.apache.spark.sql.connector.catalog.TableCatalog" id="org.apache.spark.sql.connector.catalog.TableCatalog" class="extype">TableCatalog</a></code> that support staging creation of
the a table before committing the table's metadata along with its contents in CREATE TABLE AS
SELECT or REPLACE TABLE AS SELECT operations.</p><p>It is highly recommended to implement this trait whenever possible so that CREATE TABLE AS
SELECT and REPLACE TABLE AS SELECT operations are atomic. For example, when one runs a REPLACE
TABLE AS SELECT operation, if the catalog does not implement this trait, the planner will first
drop the table via <code><span name="TableCatalog#dropTable(Identifier)" class="extype">TableCatalog#dropTable(Identifier)</span></code>, then create the table via
<code><span name="TableCatalog#createTable(Identifier," class="extype">Column[], Transform[], Map)</span></code>, and then perform
the write via <code><span name="SupportsWrite#newWriteBuilder(LogicalWriteInfo)" class="extype">SupportsWrite#newWriteBuilder(LogicalWriteInfo)</span></code>.
However, if the write operation fails, the catalog will have already dropped the table, and the
planner cannot roll back the dropping of the table.</p><p>If the catalog implements this plugin, the catalog can implement the methods to "stage" the
creation and the replacement of a table. After the table's
<code><span name="BatchWrite#commit(WriterCommitMessage[])" class="extype">BatchWrite#commit(WriterCommitMessage[])</span></code> is called,
<code><span name="StagedTable#commitStagedChanges()" class="extype">StagedTable#commitStagedChanges()</span></code> is called, at which point the staged table can
complete both the data write and the metadata swap operation atomically.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.SupportsAtomicPartitionManagement" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="SupportsAtomicPartitionManagementextendsSupportsPartitionManagement" class="anchorToMember"></a><a id="SupportsAtomicPartitionManagement:SupportsAtomicPartitionManagement" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/SupportsAtomicPartitionManagement.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="SupportsAtomicPartitionManagement.html" title="An atomic partition interface of Table to operate multiple partitions atomically."><span class="name">SupportsAtomicPartitionManagement</span></a><span class="result"> extends <a href="SupportsPartitionManagement.html" name="org.apache.spark.sql.connector.catalog.SupportsPartitionManagement" id="org.apache.spark.sql.connector.catalog.SupportsPartitionManagement" class="extype">SupportsPartitionManagement</a></span></span><p class="shortcomment cmt">An atomic partition interface of <code><a href="Table.html" name="org.apache.spark.sql.connector.catalog.Table" id="org.apache.spark.sql.connector.catalog.Table" class="extype">Table</a></code> to operate multiple partitions atomically.</p><div class="fullcomment"><div class="comment cmt"><p>An atomic partition interface of <code><a href="Table.html" name="org.apache.spark.sql.connector.catalog.Table" id="org.apache.spark.sql.connector.catalog.Table" class="extype">Table</a></code> to operate multiple partitions atomically.</p><p>These APIs are used to modify table partition or partition metadata,
they will change the table data as well.</p><ul><li><code><a href="SupportsAtomicPartitionManagement.html#createPartitions(idents:Array[org.apache.spark.sql.catalyst.InternalRow],properties:Array[java.util.Map[String,String]]):Unit" name="org.apache.spark.sql.connector.catalog.SupportsAtomicPartitionManagement#createPartitions" id="org.apache.spark.sql.connector.catalog.SupportsAtomicPartitionManagement#createPartitions" class="extmbr">#createPartitions</a></code>: add an array of partitions and any data they contain to the
  table</li><li><code><a href="SupportsAtomicPartitionManagement.html#dropPartitions(idents:Array[org.apache.spark.sql.catalyst.InternalRow]):Boolean" name="org.apache.spark.sql.connector.catalog.SupportsAtomicPartitionManagement#dropPartitions" id="org.apache.spark.sql.connector.catalog.SupportsAtomicPartitionManagement#dropPartitions" class="extmbr">#dropPartitions</a></code>: remove an array of partitions and any data they contain from
  the table</li><li><code><a href="SupportsAtomicPartitionManagement.html#purgePartitions(idents:Array[org.apache.spark.sql.catalyst.InternalRow]):Boolean" name="org.apache.spark.sql.connector.catalog.SupportsAtomicPartitionManagement#purgePartitions" id="org.apache.spark.sql.connector.catalog.SupportsAtomicPartitionManagement#purgePartitions" class="extmbr">#purgePartitions</a></code>: remove an array of partitions and any data they contain from
  the table by skipping a trash even if it is supported</li><li><code><a href="SupportsAtomicPartitionManagement.html#truncatePartitions(idents:Array[org.apache.spark.sql.catalyst.InternalRow]):Boolean" name="org.apache.spark.sql.connector.catalog.SupportsAtomicPartitionManagement#truncatePartitions" id="org.apache.spark.sql.connector.catalog.SupportsAtomicPartitionManagement#truncatePartitions" class="extmbr">#truncatePartitions</a></code>: truncate an array of partitions by removing partitions
  data</li></ul></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Experimental</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.1.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.SupportsCatalogOptions" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="SupportsCatalogOptionsextendsTableProvider" class="anchorToMember"></a><a id="SupportsCatalogOptions:SupportsCatalogOptions" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/SupportsCatalogOptions.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="SupportsCatalogOptions.html" title="An interface, which TableProviders can implement, to support table existence checks and creation through a catalog, without having to use table identifiers."><span class="name">SupportsCatalogOptions</span></a><span class="result"> extends <a href="TableProvider.html" name="org.apache.spark.sql.connector.catalog.TableProvider" id="org.apache.spark.sql.connector.catalog.TableProvider" class="extype">TableProvider</a></span></span><p class="shortcomment cmt">An interface, which TableProviders can implement, to support table existence checks and creation
through a catalog, without having to use table identifiers.</p><div class="fullcomment"><div class="comment cmt"><p>An interface, which TableProviders can implement, to support table existence checks and creation
through a catalog, without having to use table identifiers. For example, when file based data
sources use the <code>DataFrameWriter.save(path)</code> method, the option <code>path</code> can translate to a
PathIdentifier. A catalog can then use this PathIdentifier to check the existence of a table, or
whether a table can be created at a given directory.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.SupportsDelete" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="SupportsDeleteextendsSupportsDeleteV2" class="anchorToMember"></a><a id="SupportsDelete:SupportsDelete" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/SupportsDelete.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="SupportsDelete.html" title="A mix-in interface for Table delete support."><span class="name">SupportsDelete</span></a><span class="result"> extends <a href="SupportsDeleteV2.html" name="org.apache.spark.sql.connector.catalog.SupportsDeleteV2" id="org.apache.spark.sql.connector.catalog.SupportsDeleteV2" class="extype">SupportsDeleteV2</a></span></span><p class="shortcomment cmt">A mix-in interface for <code><a href="Table.html" name="org.apache.spark.sql.connector.catalog.Table" id="org.apache.spark.sql.connector.catalog.Table" class="extype">Table</a></code> delete support.</p><div class="fullcomment"><div class="comment cmt"><p>A mix-in interface for <code><a href="Table.html" name="org.apache.spark.sql.connector.catalog.Table" id="org.apache.spark.sql.connector.catalog.Table" class="extype">Table</a></code> delete support. Data sources can implement this
interface to provide the ability to delete data from tables that matches filter expressions.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.SupportsDeleteV2" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="SupportsDeleteV2extendsTruncatableTable" class="anchorToMember"></a><a id="SupportsDeleteV2:SupportsDeleteV2" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/SupportsDeleteV2.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="SupportsDeleteV2.html" title="A mix-in interface for Table delete support."><span class="name">SupportsDeleteV2</span></a><span class="result"> extends <a href="TruncatableTable.html" name="org.apache.spark.sql.connector.catalog.TruncatableTable" id="org.apache.spark.sql.connector.catalog.TruncatableTable" class="extype">TruncatableTable</a></span></span><p class="shortcomment cmt">A mix-in interface for <code><a href="Table.html" name="org.apache.spark.sql.connector.catalog.Table" id="org.apache.spark.sql.connector.catalog.Table" class="extype">Table</a></code> delete support.</p><div class="fullcomment"><div class="comment cmt"><p>A mix-in interface for <code><a href="Table.html" name="org.apache.spark.sql.connector.catalog.Table" id="org.apache.spark.sql.connector.catalog.Table" class="extype">Table</a></code> delete support. Data sources can implement this
interface to provide the ability to delete data from tables that matches filter expressions.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.4.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.SupportsMetadataColumns" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="SupportsMetadataColumnsextendsTable" class="anchorToMember"></a><a id="SupportsMetadataColumns:SupportsMetadataColumns" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/SupportsMetadataColumns.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="SupportsMetadataColumns.html" title="An interface for exposing data columns for a table that are not in the table schema."><span class="name">SupportsMetadataColumns</span></a><span class="result"> extends <a href="Table.html" name="org.apache.spark.sql.connector.catalog.Table" id="org.apache.spark.sql.connector.catalog.Table" class="extype">Table</a></span></span><p class="shortcomment cmt">An interface for exposing data columns for a table that are not in the table schema.</p><div class="fullcomment"><div class="comment cmt"><p>An interface for exposing data columns for a table that are not in the table schema. For example,
a file source could expose a "file" column that contains the path of the file that contained each
row.</p><p>The columns returned by <code><span name="#metadataColumns()" class="extype">#metadataColumns()</span></code> may be passed as <code><span name="StructField" class="extype">StructField</span></code> in
requested projections. Sources that implement this interface and column projection using
<code><span name="SupportsPushDownRequiredColumns" class="extype">SupportsPushDownRequiredColumns</span></code> must accept metadata fields passed to
<code><span name="SupportsPushDownRequiredColumns#pruneColumns(StructType)" class="extype">SupportsPushDownRequiredColumns#pruneColumns(StructType)</span></code>.</p><p>If a table column and a metadata column have the same name, the conflict is resolved by either
renaming or suppressing the metadata column. See <code><a href="SupportsMetadataColumns.html#canRenameConflictingMetadataColumns():Boolean" name="org.apache.spark.sql.connector.catalog.SupportsMetadataColumns#canRenameConflictingMetadataColumns" id="org.apache.spark.sql.connector.catalog.SupportsMetadataColumns#canRenameConflictingMetadataColumns" class="extmbr">canRenameConflictingMetadataColumns</a></code>.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.1.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.SupportsNamespaces" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="SupportsNamespacesextendsCatalogPlugin" class="anchorToMember"></a><a id="SupportsNamespaces:SupportsNamespaces" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/SupportsNamespaces.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="SupportsNamespaces.html" title="Catalog methods for working with namespaces."><span class="name">SupportsNamespaces</span></a><span class="result"> extends <a href="CatalogPlugin.html" name="org.apache.spark.sql.connector.catalog.CatalogPlugin" id="org.apache.spark.sql.connector.catalog.CatalogPlugin" class="extype">CatalogPlugin</a></span></span><p class="shortcomment cmt">Catalog methods for working with namespaces.</p><div class="fullcomment"><div class="comment cmt"><p>Catalog methods for working with namespaces.</p><p>If an object such as a table, view, or function exists, its parent namespaces must also exist
and must be returned by the discovery methods <code><span name="#listNamespaces()" class="extype">#listNamespaces()</span></code> and
<code><span name="#listNamespaces(String[])" class="extype">#listNamespaces(String[])</span></code>.</p><p>Catalog implementations are not required to maintain the existence of namespaces independent of
objects in a namespace. For example, a function catalog that loads functions using reflection
and uses Java packages as namespaces is not required to support the methods to create, alter, or
drop a namespace. Implementations are allowed to discover the existence of objects or namespaces
without throwing <code><span name="NoSuchNamespaceException" class="extype">NoSuchNamespaceException</span></code> when no namespace is found.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.SupportsPartitionManagement" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="SupportsPartitionManagementextendsTable" class="anchorToMember"></a><a id="SupportsPartitionManagement:SupportsPartitionManagement" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/SupportsPartitionManagement.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="SupportsPartitionManagement.html" title="A partition interface of Table."><span class="name">SupportsPartitionManagement</span></a><span class="result"> extends <a href="Table.html" name="org.apache.spark.sql.connector.catalog.Table" id="org.apache.spark.sql.connector.catalog.Table" class="extype">Table</a></span></span><p class="shortcomment cmt">A partition interface of <code><a href="Table.html" name="org.apache.spark.sql.connector.catalog.Table" id="org.apache.spark.sql.connector.catalog.Table" class="extype">Table</a></code>.</p><div class="fullcomment"><div class="comment cmt"><p>A partition interface of <code><a href="Table.html" name="org.apache.spark.sql.connector.catalog.Table" id="org.apache.spark.sql.connector.catalog.Table" class="extype">Table</a></code>.
A partition is composed of identifier and properties,
and properties contains metadata information of the partition.</p><p>These APIs are used to modify table partition identifier or partition metadata.
In some cases, they will change the table data as well.</p><ul><li><code><a href="SupportsPartitionManagement.html#createPartition(ident:org.apache.spark.sql.catalyst.InternalRow,properties:java.util.Map[String,String]):Unit" name="org.apache.spark.sql.connector.catalog.SupportsPartitionManagement#createPartition" id="org.apache.spark.sql.connector.catalog.SupportsPartitionManagement#createPartition" class="extmbr">#createPartition</a></code>: add a partition and any data it contains to the table</li><li><code><a href="SupportsPartitionManagement.html#dropPartition(ident:org.apache.spark.sql.catalyst.InternalRow):Boolean" name="org.apache.spark.sql.connector.catalog.SupportsPartitionManagement#dropPartition" id="org.apache.spark.sql.connector.catalog.SupportsPartitionManagement#dropPartition" class="extmbr">#dropPartition</a></code>: remove a partition and any data it contains from the table</li><li><code><a href="SupportsPartitionManagement.html#purgePartition(ident:org.apache.spark.sql.catalyst.InternalRow):Boolean" name="org.apache.spark.sql.connector.catalog.SupportsPartitionManagement#purgePartition" id="org.apache.spark.sql.connector.catalog.SupportsPartitionManagement#purgePartition" class="extmbr">#purgePartition</a></code>: remove a partition and any data it contains from the table by
  skipping a trash even if it is supported.</li><li><code><a href="SupportsPartitionManagement.html#replacePartitionMetadata(ident:org.apache.spark.sql.catalyst.InternalRow,properties:java.util.Map[String,String]):Unit" name="org.apache.spark.sql.connector.catalog.SupportsPartitionManagement#replacePartitionMetadata" id="org.apache.spark.sql.connector.catalog.SupportsPartitionManagement#replacePartitionMetadata" class="extmbr">#replacePartitionMetadata</a></code>: point a partition to a new location, which will swap
  one location's data for the other</li><li><code><a href="SupportsPartitionManagement.html#truncatePartition(ident:org.apache.spark.sql.catalyst.InternalRow):Boolean" name="org.apache.spark.sql.connector.catalog.SupportsPartitionManagement#truncatePartition" id="org.apache.spark.sql.connector.catalog.SupportsPartitionManagement#truncatePartition" class="extmbr">#truncatePartition</a></code>: remove partition data from the table</li></ul></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Experimental</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.1.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.SupportsRead" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="SupportsReadextendsTable" class="anchorToMember"></a><a id="SupportsRead:SupportsRead" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/SupportsRead.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="SupportsRead.html" title="A mix-in interface of Table, to indicate that it's readable."><span class="name">SupportsRead</span></a><span class="result"> extends <a href="Table.html" name="org.apache.spark.sql.connector.catalog.Table" id="org.apache.spark.sql.connector.catalog.Table" class="extype">Table</a></span></span><p class="shortcomment cmt">A mix-in interface of <code><a href="Table.html" name="org.apache.spark.sql.connector.catalog.Table" id="org.apache.spark.sql.connector.catalog.Table" class="extype">Table</a></code>, to indicate that it's readable.</p><div class="fullcomment"><div class="comment cmt"><p>A mix-in interface of <code><a href="Table.html" name="org.apache.spark.sql.connector.catalog.Table" id="org.apache.spark.sql.connector.catalog.Table" class="extype">Table</a></code>, to indicate that it's readable. This adds
<code><span name="#newScanBuilder(CaseInsensitiveStringMap)" class="extype">#newScanBuilder(CaseInsensitiveStringMap)</span></code> that is used to create a scan for batch,
micro-batch, or continuous processing.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.SupportsRowLevelOperations" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="SupportsRowLevelOperationsextendsTable" class="anchorToMember"></a><a id="SupportsRowLevelOperations:SupportsRowLevelOperations" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/SupportsRowLevelOperations.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="SupportsRowLevelOperations.html" title="A mix-in interface for Table row-level operations support."><span class="name">SupportsRowLevelOperations</span></a><span class="result"> extends <a href="Table.html" name="org.apache.spark.sql.connector.catalog.Table" id="org.apache.spark.sql.connector.catalog.Table" class="extype">Table</a></span></span><p class="shortcomment cmt">A mix-in interface for <code><a href="Table.html" name="org.apache.spark.sql.connector.catalog.Table" id="org.apache.spark.sql.connector.catalog.Table" class="extype">Table</a></code> row-level operations support.</p><div class="fullcomment"><div class="comment cmt"><p>A mix-in interface for <code><a href="Table.html" name="org.apache.spark.sql.connector.catalog.Table" id="org.apache.spark.sql.connector.catalog.Table" class="extype">Table</a></code> row-level operations support. Data sources can implement
this interface to indicate they support rewriting data for DELETE, UPDATE, MERGE operations.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Experimental</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.3.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.SupportsWrite" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="SupportsWriteextendsTable" class="anchorToMember"></a><a id="SupportsWrite:SupportsWrite" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/SupportsWrite.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="SupportsWrite.html" title="A mix-in interface of Table, to indicate that it's writable."><span class="name">SupportsWrite</span></a><span class="result"> extends <a href="Table.html" name="org.apache.spark.sql.connector.catalog.Table" id="org.apache.spark.sql.connector.catalog.Table" class="extype">Table</a></span></span><p class="shortcomment cmt">A mix-in interface of <code><a href="Table.html" name="org.apache.spark.sql.connector.catalog.Table" id="org.apache.spark.sql.connector.catalog.Table" class="extype">Table</a></code>, to indicate that it's writable.</p><div class="fullcomment"><div class="comment cmt"><p>A mix-in interface of <code><a href="Table.html" name="org.apache.spark.sql.connector.catalog.Table" id="org.apache.spark.sql.connector.catalog.Table" class="extype">Table</a></code>, to indicate that it's writable. This adds
<code><span name="#newWriteBuilder(LogicalWriteInfo)" class="extype">#newWriteBuilder(LogicalWriteInfo)</span></code> that is used to create a
write for batch or streaming.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.Table" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="TableextendsObject" class="anchorToMember"></a><a id="Table:Table" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/Table.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="Table.html" title="An interface representing a logical structured data set of a data source."><span class="name">Table</span></a><span class="result"> extends <span name="scala.AnyRef" class="extype">AnyRef</span></span></span><p class="shortcomment cmt">An interface representing a logical structured data set of a data source.</p><div class="fullcomment"><div class="comment cmt"><p>An interface representing a logical structured data set of a data source. For example, the
implementation can be a directory on the file system, a topic of Kafka, or a table in the
catalog, etc.</p><p>This interface can mixin <code>SupportsRead</code> and <code>SupportsWrite</code> to provide data reading
and writing ability.</p><p>The default implementation of <code><span name="#partitioning()" class="extype">#partitioning()</span></code> returns an empty array of partitions, and
the default implementation of <code><span name="#properties()" class="extype">#properties()</span></code> returns an empty map. These should be
overridden by implementations that support partitioning and table properties.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.TableCapability" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="TableCapabilityextendsEnum[org.apache.spark.sql.connector.catalog.TableCapability]" class="anchorToMember"></a><a id="TableCapability:TableCapability" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/TableCapability.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">sealed final </span> <span class="kind">class</span></span> <span class="symbol"><a href="TableCapability.html" title="Capabilities that can be provided by a Table implementation."><span class="name">TableCapability</span></a><span class="result"> extends <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Enum.html#java.lang.Enum" name="java.lang.Enum" id="java.lang.Enum" class="extype">Enum</a>[<a href="TableCapability.html" name="org.apache.spark.sql.connector.catalog.TableCapability" id="org.apache.spark.sql.connector.catalog.TableCapability" class="extype">TableCapability</a>]</span></span><p class="shortcomment cmt">Capabilities that can be provided by a <code><a href="Table.html" name="org.apache.spark.sql.connector.catalog.Table" id="org.apache.spark.sql.connector.catalog.Table" class="extype">Table</a></code> implementation.</p><div class="fullcomment"><div class="comment cmt"><p>Capabilities that can be provided by a <code><a href="Table.html" name="org.apache.spark.sql.connector.catalog.Table" id="org.apache.spark.sql.connector.catalog.Table" class="extype">Table</a></code> implementation.</p><p>Tables use <code><span name="Table#capabilities()" class="extype">Table#capabilities()</span></code> to return a set of capabilities. Each capability signals
to Spark that the table supports a feature identified by the capability. For example, returning
<code><span name="#BATCH_READ" class="extype">#BATCH_READ</span></code> allows Spark to read from the table using a batch scan.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.TableCatalog" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="TableCatalogextendsCatalogPlugin" class="anchorToMember"></a><a id="TableCatalog:TableCatalog" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/TableCatalog.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="TableCatalog.html" title="Catalog methods for working with Tables."><span class="name">TableCatalog</span></a><span class="result"> extends <a href="CatalogPlugin.html" name="org.apache.spark.sql.connector.catalog.CatalogPlugin" id="org.apache.spark.sql.connector.catalog.CatalogPlugin" class="extype">CatalogPlugin</a></span></span><p class="shortcomment cmt">Catalog methods for working with Tables.</p><div class="fullcomment"><div class="comment cmt"><p>Catalog methods for working with Tables.</p><p>TableCatalog implementations may be case sensitive or case insensitive. Spark will pass
<code><a href="Identifier.html" name="org.apache.spark.sql.connector.catalog.Identifier" id="org.apache.spark.sql.connector.catalog.Identifier" class="extype">table identifiers</a></code> without modification. Field names passed to
<code><span name="#alterTable(Identifier," class="extype">TableChange...)</span></code> will be normalized to match the case used in the
table schema when updating, renaming, or dropping existing columns when catalyst analysis is case
insensitive.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.TableCatalogCapability" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="TableCatalogCapabilityextendsEnum[org.apache.spark.sql.connector.catalog.TableCatalogCapability]" class="anchorToMember"></a><a id="TableCatalogCapability:TableCatalogCapability" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/TableCatalogCapability.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">sealed final </span> <span class="kind">class</span></span> <span class="symbol"><a href="TableCatalogCapability.html" title="Capabilities that can be provided by a TableCatalog implementation."><span class="name">TableCatalogCapability</span></a><span class="result"> extends <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Enum.html#java.lang.Enum" name="java.lang.Enum" id="java.lang.Enum" class="extype">Enum</a>[<a href="TableCatalogCapability.html" name="org.apache.spark.sql.connector.catalog.TableCatalogCapability" id="org.apache.spark.sql.connector.catalog.TableCatalogCapability" class="extype">TableCatalogCapability</a>]</span></span><p class="shortcomment cmt">Capabilities that can be provided by a <code><a href="TableCatalog.html" name="org.apache.spark.sql.connector.catalog.TableCatalog" id="org.apache.spark.sql.connector.catalog.TableCatalog" class="extype">TableCatalog</a></code> implementation.</p><div class="fullcomment"><div class="comment cmt"><p>Capabilities that can be provided by a <code><a href="TableCatalog.html" name="org.apache.spark.sql.connector.catalog.TableCatalog" id="org.apache.spark.sql.connector.catalog.TableCatalog" class="extype">TableCatalog</a></code> implementation.</p><p>TableCatalogs use <code><span name="TableCatalog#capabilities()" class="extype">TableCatalog#capabilities()</span></code> to return a set of capabilities. Each
capability signals to Spark that the catalog supports a feature identified by the capability.
For example, returning <code><span name="#SUPPORTS_CREATE_TABLE_WITH_GENERATED_COLUMNS" class="extype">#SUPPORTS_CREATE_TABLE_WITH_GENERATED_COLUMNS</span></code> allows Spark to
accept <code>GENERATED ALWAYS AS</code> expressions in <code>CREATE TABLE</code> statements.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.4.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.TableChange" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="TableChangeextendsObject" class="anchorToMember"></a><a id="TableChange:TableChange" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/TableChange.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="TableChange.html" title="TableChange subclasses represent requested changes to a table."><span class="name">TableChange</span></a><span class="result"> extends <span name="scala.AnyRef" class="extype">AnyRef</span></span></span><p class="shortcomment cmt">TableChange subclasses represent requested changes to a table.</p><div class="fullcomment"><div class="comment cmt"><p>TableChange subclasses represent requested changes to a table. These are passed to
<code><a href="TableCatalog.html#alterTable(ident:org.apache.spark.sql.connector.catalog.Identifier,changes:org.apache.spark.sql.connector.catalog.TableChange*):org.apache.spark.sql.connector.catalog.Table" name="org.apache.spark.sql.connector.catalog.TableCatalog#alterTable" id="org.apache.spark.sql.connector.catalog.TableCatalog#alterTable" class="extmbr">TableCatalog#alterTable</a></code>. For example,
<pre>
  import TableChange._
  val catalog = Catalogs.load(name)
  catalog.asTableCatalog.alterTable(ident,
      addColumn("x", IntegerType),
      renameColumn("a", "b"),
      deleteColumn("c")
    )
</pre>
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.TableProvider" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="TableProviderextendsObject" class="anchorToMember"></a><a id="TableProvider:TableProvider" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/TableProvider.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="TableProvider.html" title="The base interface for v2 data sources which don't have a real catalog."><span class="name">TableProvider</span></a><span class="result"> extends <span name="scala.AnyRef" class="extype">AnyRef</span></span></span><p class="shortcomment cmt">The base interface for v2 data sources which don't have a real catalog.</p><div class="fullcomment"><div class="comment cmt"><p>The base interface for v2 data sources which don't have a real catalog. Implementations must
have a public, 0-arg constructor.</p><p>Note that, TableProvider can only apply data operations to existing tables, like read, append,
delete, and overwrite. It does not support the operations that require metadata changes, like
create/drop tables.</p><p>The major responsibility of this interface is to return a <code><a href="Table.html" name="org.apache.spark.sql.connector.catalog.Table" id="org.apache.spark.sql.connector.catalog.Table" class="extype">Table</a></code> for read/write.</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.TableWritePrivilege" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="TableWritePrivilegeextendsEnum[org.apache.spark.sql.connector.catalog.TableWritePrivilege]" class="anchorToMember"></a><a id="TableWritePrivilege:TableWritePrivilege" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/TableWritePrivilege.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">sealed final </span> <span class="kind">class</span></span> <span class="symbol"><a href="TableWritePrivilege.html" title="The table write privileges that will be provided when loading a table."><span class="name">TableWritePrivilege</span></a><span class="result"> extends <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Enum.html#java.lang.Enum" name="java.lang.Enum" id="java.lang.Enum" class="extype">Enum</a>[<a href="TableWritePrivilege.html" name="org.apache.spark.sql.connector.catalog.TableWritePrivilege" id="org.apache.spark.sql.connector.catalog.TableWritePrivilege" class="extype">TableWritePrivilege</a>]</span></span><p class="shortcomment cmt">The table write privileges that will be provided when loading a table.</p><div class="fullcomment"><div class="comment cmt"><p>The table write privileges that will be provided when loading a table.
</p></div><dl class="attributes block"><dt>Since</dt><dd><p>3.5.3</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.TruncatableTable" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="TruncatableTableextendsTable" class="anchorToMember"></a><a id="TruncatableTable:TruncatableTable" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/TruncatableTable.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="TruncatableTable.html" title="Represents a table which can be atomically truncated."><span class="name">TruncatableTable</span></a><span class="result"> extends <a href="Table.html" name="org.apache.spark.sql.connector.catalog.Table" id="org.apache.spark.sql.connector.catalog.Table" class="extype">Table</a></span></span><p class="shortcomment cmt">Represents a table which can be atomically truncated.</p><div class="fullcomment"><div class="comment cmt"><p>Represents a table which can be atomically truncated.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.2.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.View" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="ViewextendsObject" class="anchorToMember"></a><a id="View:View" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/View.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="View.html" title="An interface representing a persisted view."><span class="name">View</span></a><span class="result"> extends <span name="scala.AnyRef" class="extype">AnyRef</span></span></span><p class="shortcomment cmt">An interface representing a persisted view.</p><div class="fullcomment"><div class="comment cmt"><p>An interface representing a persisted view.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@DeveloperApi</span><span class="args">()</span> </dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.ViewCatalog" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="ViewCatalogextendsCatalogPlugin" class="anchorToMember"></a><a id="ViewCatalog:ViewCatalog" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/ViewCatalog.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="ViewCatalog.html" title="Catalog methods for working with views."><span class="name">ViewCatalog</span></a><span class="result"> extends <a href="CatalogPlugin.html" name="org.apache.spark.sql.connector.catalog.CatalogPlugin" id="org.apache.spark.sql.connector.catalog.CatalogPlugin" class="extype">CatalogPlugin</a></span></span><p class="shortcomment cmt">Catalog methods for working with views.</p><div class="fullcomment"><div class="comment cmt"><p>Catalog methods for working with views.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@DeveloperApi</span><span class="args">()</span> </dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.ViewChange" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="ViewChangeextendsObject" class="anchorToMember"></a><a id="ViewChange:ViewChange" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/ViewChange.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="ViewChange.html" title="ViewChange subclasses represent requested changes to a view."><span class="name">ViewChange</span></a><span class="result"> extends <span name="scala.AnyRef" class="extype">AnyRef</span></span></span><p class="shortcomment cmt">ViewChange subclasses represent requested changes to a view.</p><div class="fullcomment"><div class="comment cmt"><p>ViewChange subclasses represent requested changes to a view.
These are passed to <code><a href="ViewCatalog.html#alterView(ident:org.apache.spark.sql.connector.catalog.Identifier,changes:org.apache.spark.sql.connector.catalog.ViewChange*):org.apache.spark.sql.connector.catalog.View" name="org.apache.spark.sql.connector.catalog.ViewCatalog#alterView" id="org.apache.spark.sql.connector.catalog.ViewCatalog#alterView" class="extmbr">ViewCatalog#alterView</a></code>.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@DeveloperApi</span><span class="args">()</span> </dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.catalog.ViewInfo" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="ViewInfoextendsObject" class="anchorToMember"></a><a id="ViewInfo:ViewInfo" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/ViewInfo.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">class</span></span> <span class="symbol"><a href="ViewInfo.html" title="A class that holds view information."><span class="name">ViewInfo</span></a><span class="result"> extends <span name="scala.AnyRef" class="extype">AnyRef</span></span></span><p class="shortcomment cmt">A class that holds view information.</p><div class="fullcomment"><div class="comment cmt"><p>A class that holds view information.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@DeveloperApi</span><span class="args">()</span> </dd></dl></div></li></ol></div></div><div id="inheritedMembers"></div><div id="groupedMembers"><div name="Ungrouped" class="group"><h3>Ungrouped</h3></div></div></div><div id="tooltip"></div><div id="footer"></div></body></div></div></div></body></html>
