<!DOCTYPE html ><html><head><meta http-equiv="X-UA-Compatible" content="IE=edge"/><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" name="viewport"/><title>Spark 4.0.0-preview2 ScalaDoc  - org.apache.spark.sql.connector.write</title><meta content="Spark 4.0.0 - preview2 ScalaDoc - org.apache.spark.sql.connector.write" name="description"/><meta content="Spark 4.0.0 preview2 ScalaDoc org.apache.spark.sql.connector.write" name="keywords"/><meta http-equiv="content-type" content="text/html; charset=UTF-8"/><link href="../../../../../../lib/index.css" media="screen" type="text/css" rel="stylesheet"/><link href="../../../../../../lib/template.css" media="screen" type="text/css" rel="stylesheet"/><link href="../../../../../../lib/print.css" media="print" type="text/css" rel="stylesheet"/><link href="../../../../../../lib/diagrams.css" media="screen" type="text/css" rel="stylesheet" id="diagrams-css"/><script type="text/javascript" src="../../../../../../lib/jquery.min.js"></script><script type="text/javascript" src="../../../../../../lib/index.js"></script><script type="text/javascript" src="../../../../../../index.js"></script><script type="text/javascript" src="../../../../../../lib/scheduler.js"></script><script type="text/javascript" src="../../../../../../lib/template.js"></script><script type="text/javascript">/* this variable can be used by the JS to determine the path to the root document */
var toRoot = '../../../../../../';</script></head><body><div id="search"><span id="doc-title">Spark 4.0.0-preview2 ScalaDoc<span id="doc-version"></span></span> <span class="close-results"><span class="left">&lt;</span> Back</span><div id="textfilter"><span class="input"><input autocapitalize="none" placeholder="Search" id="index-input" type="text" accesskey="/"/><i class="clear material-icons"></i><i id="search-icon" class="material-icons"></i></span></div></div><div id="search-results"><div id="search-progress"><div id="progress-fill"></div></div><div id="results-content"><div id="entity-results"></div><div id="member-results"></div></div></div><div id="content-scroll-container" style="-webkit-overflow-scrolling: touch;"><div id="content-container" style="-webkit-overflow-scrolling: touch;"><div id="subpackage-spacer"><div id="packages"><h1>Packages</h1><ul><li class="indented0 " name="_root_.root" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="_root_" class="anchorToMember"></a><a id="root:_root_" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../../../../../index.html" title=""><span class="name">root</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../../../../index.html" name="_root_" id="_root_" class="extype">root</a></dd></dl></div></li><li class="indented1 " name="_root_.org" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="org" class="anchorToMember"></a><a id="org:org" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../../../../index.html" title=""><span class="name">org</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../../../../index.html" name="_root_" id="_root_" class="extype">root</a></dd></dl></div></li><li class="indented2 " name="org.apache" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="apache" class="anchorToMember"></a><a id="apache:apache" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../../../index.html" title=""><span class="name">apache</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../../../index.html" name="org" id="org" class="extype">org</a></dd></dl></div></li><li class="indented3 " name="org.apache.spark" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="spark" class="anchorToMember"></a><a id="spark:spark" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../../index.html" title="Core Spark functionality."><span class="name">spark</span></a></span><p class="shortcomment cmt">Core Spark functionality.</p><div class="fullcomment"><div class="comment cmt"><p>Core Spark functionality. <a href="../../../SparkContext.html" name="org.apache.spark.SparkContext" id="org.apache.spark.SparkContext" class="extype">org.apache.spark.SparkContext</a> serves as the main entry point to
Spark, while <a href="../../../rdd/RDD.html" name="org.apache.spark.rdd.RDD" id="org.apache.spark.rdd.RDD" class="extype">org.apache.spark.rdd.RDD</a> is the data type representing a distributed collection,
and provides most parallel operations.</p><p>In addition, <a href="../../../rdd/PairRDDFunctions.html" name="org.apache.spark.rdd.PairRDDFunctions" id="org.apache.spark.rdd.PairRDDFunctions" class="extype">org.apache.spark.rdd.PairRDDFunctions</a> contains operations available only on RDDs
of key-value pairs, such as <code>groupByKey</code> and <code>join</code>; <a href="../../../rdd/DoubleRDDFunctions.html" name="org.apache.spark.rdd.DoubleRDDFunctions" id="org.apache.spark.rdd.DoubleRDDFunctions" class="extype">org.apache.spark.rdd.DoubleRDDFunctions</a>
contains operations available only on RDDs of Doubles; and
<a href="../../../rdd/SequenceFileRDDFunctions.html" name="org.apache.spark.rdd.SequenceFileRDDFunctions" id="org.apache.spark.rdd.SequenceFileRDDFunctions" class="extype">org.apache.spark.rdd.SequenceFileRDDFunctions</a> contains operations available on RDDs that can
be saved as SequenceFiles. These operations are automatically available on any RDD of the right
type (e.g. RDD[(Int, Int)] through implicit conversions.</p><p>Java programmers should reference the <a href="../../../api/java/index.html" name="org.apache.spark.api.java" id="org.apache.spark.api.java" class="extype">org.apache.spark.api.java</a> package
for Spark programming APIs in Java.</p><p>Classes and methods marked with <span class="experimental badge" style="float: none;">
Experimental</span> are user-facing features which have not been officially adopted by the
Spark project. These are subject to change or removal in minor releases.</p><p>Classes and methods marked with <span class="developer badge" style="float: none;">
Developer API</span> are intended for advanced users want to extend Spark through lower
level interfaces. These are subject to changes or removal in minor releases.
</p></div><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../../index.html" name="org.apache" id="org.apache" class="extype">apache</a></dd></dl></div></li><li class="indented4 " name="org.apache.spark.sql" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="sql" class="anchorToMember"></a><a id="sql:sql" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../index.html" title="Allows the execution of relational queries, including those expressed in SQL using Spark."><span class="name">sql</span></a></span><p class="shortcomment cmt">Allows the execution of relational queries, including those expressed in SQL using Spark.</p><div class="fullcomment"><div class="comment cmt"><p>Allows the execution of relational queries, including those expressed in SQL using Spark.
</p></div><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../index.html" name="org.apache.spark" id="org.apache.spark" class="extype">spark</a></dd></dl></div></li><li class="indented5 " name="org.apache.spark.sql.connector" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="connector" class="anchorToMember"></a><a id="connector:connector" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../index.html" title=""><span class="name">connector</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../index.html" name="org.apache.spark.sql" id="org.apache.spark.sql" class="extype">sql</a></dd></dl></div></li><li class="indented6 " name="org.apache.spark.sql.connector.catalog" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="catalog" class="anchorToMember"></a><a id="catalog:catalog" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/catalog/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../catalog/index.html" title=""><span class="name">catalog</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../index.html" name="org.apache.spark.sql.connector" id="org.apache.spark.sql.connector" class="extype">connector</a></dd></dl></div></li><li class="indented6 " name="org.apache.spark.sql.connector.distributions" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="distributions" class="anchorToMember"></a><a id="distributions:distributions" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/distributions/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../distributions/index.html" title=""><span class="name">distributions</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../index.html" name="org.apache.spark.sql.connector" id="org.apache.spark.sql.connector" class="extype">connector</a></dd></dl></div></li><li class="indented6 " name="org.apache.spark.sql.connector.expressions" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="expressions" class="anchorToMember"></a><a id="expressions:expressions" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/expressions/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../expressions/index.html" title=""><span class="name">expressions</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../index.html" name="org.apache.spark.sql.connector" id="org.apache.spark.sql.connector" class="extype">connector</a></dd></dl></div></li><li class="indented6 " name="org.apache.spark.sql.connector.metric" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="metric" class="anchorToMember"></a><a id="metric:metric" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/metric/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../metric/index.html" title=""><span class="name">metric</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../index.html" name="org.apache.spark.sql.connector" id="org.apache.spark.sql.connector" class="extype">connector</a></dd></dl></div></li><li class="indented6 " name="org.apache.spark.sql.connector.read" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="read" class="anchorToMember"></a><a id="read:read" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/read/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../read/index.html" title=""><span class="name">read</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../index.html" name="org.apache.spark.sql.connector" id="org.apache.spark.sql.connector" class="extype">connector</a></dd></dl></div></li><li class="indented6 " name="org.apache.spark.sql.connector.util" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="util" class="anchorToMember"></a><a id="util:util" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/util/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../util/index.html" title=""><span class="name">util</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../index.html" name="org.apache.spark.sql.connector" id="org.apache.spark.sql.connector" class="extype">connector</a></dd></dl></div></li><li class="indented6 current" name="org.apache.spark.sql.connector.write" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="write" class="anchorToMember"></a><a id="write:write" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/write/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><span class="name">write</span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../index.html" name="org.apache.spark.sql.connector" id="org.apache.spark.sql.connector" class="extype">connector</a></dd></dl></div></li><li class="indented7 " name="org.apache.spark.sql.connector.write.streaming" group="Ungrouped" fullComment="no" data-isabs="false" visbl="pub"><a id="streaming" class="anchorToMember"></a><a id="streaming:streaming" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/write/streaming/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="streaming/index.html" title=""><span class="name">streaming</span></a></span></li><li class="current-entities indented6"><span class="separator"></span> <a href="BatchWrite.html" title="An interface that defines how to write the data to data source for batch processing." class="trait"></a><a href="BatchWrite.html" title="An interface that defines how to write the data to data source for batch processing.">BatchWrite</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="DataWriter.html" title="A data writer returned by long) and is responsible for writing data for an input RDD partition." class="trait"></a><a href="DataWriter.html" title="A data writer returned by long) and is responsible for writing data for an input RDD partition.">DataWriter</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="DataWriterFactory.html" title="A factory of DataWriter returned by BatchWrite#createBatchWriterFactory(PhysicalWriteInfo), which is responsible for creating and initializing the actual data writer at executor side." class="trait"></a><a href="DataWriterFactory.html" title="A factory of DataWriter returned by BatchWrite#createBatchWriterFactory(PhysicalWriteInfo), which is responsible for creating and initializing the actual data writer at executor side.">DataWriterFactory</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="DeltaBatchWrite.html" title="An interface that defines how to write a delta of rows during batch processing." class="trait"></a><a href="DeltaBatchWrite.html" title="An interface that defines how to write a delta of rows during batch processing.">DeltaBatchWrite</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="DeltaWrite.html" title="A logical representation of a data source write that handles a delta of rows." class="trait"></a><a href="DeltaWrite.html" title="A logical representation of a data source write that handles a delta of rows.">DeltaWrite</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="DeltaWriteBuilder.html" title="An interface for building a DeltaWrite." class="trait"></a><a href="DeltaWriteBuilder.html" title="An interface for building a DeltaWrite.">DeltaWriteBuilder</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="DeltaWriter.html" title="A data writer returned by long) and is responsible for writing a delta of rows." class="trait"></a><a href="DeltaWriter.html" title="A data writer returned by long) and is responsible for writing a delta of rows.">DeltaWriter</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="DeltaWriterFactory.html" title="A factory for creating DeltaWriters returned by DeltaBatchWrite#createBatchWriterFactory(PhysicalWriteInfo), which is responsible for creating and initializing writers at the executor side." class="trait"></a><a href="DeltaWriterFactory.html" title="A factory for creating DeltaWriters returned by DeltaBatchWrite#createBatchWriterFactory(PhysicalWriteInfo), which is responsible for creating and initializing writers at the executor side.">DeltaWriterFactory</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="LogicalWriteInfo.html" title="This interface contains logical write information that data sources can use when generating a WriteBuilder." class="trait"></a><a href="LogicalWriteInfo.html" title="This interface contains logical write information that data sources can use when generating a WriteBuilder.">LogicalWriteInfo</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="PhysicalWriteInfo.html" title="This interface contains physical write information that data sources can use when generating a DataWriterFactory or a StreamingDataWriterFactory." class="trait"></a><a href="PhysicalWriteInfo.html" title="This interface contains physical write information that data sources can use when generating a DataWriterFactory or a StreamingDataWriterFactory.">PhysicalWriteInfo</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="RequiresDistributionAndOrdering.html" title="A write that requires a specific distribution and ordering of data." class="trait"></a><a href="RequiresDistributionAndOrdering.html" title="A write that requires a specific distribution and ordering of data.">RequiresDistributionAndOrdering</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="RowLevelOperation.html" title="A logical representation of a data source DELETE, UPDATE, or MERGE operation that requires rewriting data." class="trait"></a><a href="RowLevelOperation.html" title="A logical representation of a data source DELETE, UPDATE, or MERGE operation that requires rewriting data.">RowLevelOperation</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="RowLevelOperationBuilder.html" title="An interface for building a RowLevelOperation." class="trait"></a><a href="RowLevelOperationBuilder.html" title="An interface for building a RowLevelOperation.">RowLevelOperationBuilder</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="RowLevelOperationInfo.html" title="An interface with logical information for a row-level operation such as DELETE, UPDATE, MERGE." class="trait"></a><a href="RowLevelOperationInfo.html" title="An interface with logical information for a row-level operation such as DELETE, UPDATE, MERGE.">RowLevelOperationInfo</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="SupportsDelta.html" title="A mix-in interface for RowLevelOperation." class="trait"></a><a href="SupportsDelta.html" title="A mix-in interface for RowLevelOperation.">SupportsDelta</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="SupportsDynamicOverwrite.html" title="Write builder trait for tables that support dynamic partition overwrite." class="trait"></a><a href="SupportsDynamicOverwrite.html" title="Write builder trait for tables that support dynamic partition overwrite.">SupportsDynamicOverwrite</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="SupportsOverwrite.html" title="Write builder trait for tables that support overwrite by filter." class="trait"></a><a href="SupportsOverwrite.html" title="Write builder trait for tables that support overwrite by filter.">SupportsOverwrite</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="SupportsOverwriteV2.html" title="Write builder trait for tables that support overwrite by filter." class="trait"></a><a href="SupportsOverwriteV2.html" title="Write builder trait for tables that support overwrite by filter.">SupportsOverwriteV2</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="SupportsTruncate.html" title="Write builder trait for tables that support truncation." class="trait"></a><a href="SupportsTruncate.html" title="Write builder trait for tables that support truncation.">SupportsTruncate</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="V1Write.html" title="A logical write that should be executed using V1 InsertableRelation interface." class="trait"></a><a href="V1Write.html" title="A logical write that should be executed using V1 InsertableRelation interface.">V1Write</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="Write.html" title="A logical representation of a data source write." class="trait"></a><a href="Write.html" title="A logical representation of a data source write.">Write</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="WriteBuilder.html" title="An interface for building the Write." class="trait"></a><a href="WriteBuilder.html" title="An interface for building the Write.">WriteBuilder</a></li><li class="current-entities indented6"><span class="separator"></span> <a href="WriterCommitMessage.html" title="A commit message returned by DataWriter#commit() and will be sent back to the driver side as the input parameter of BatchWrite#commit(WriterCommitMessage[]) or WriterCommitMessage[])." class="trait"></a><a href="WriterCommitMessage.html" title="A commit message returned by DataWriter#commit() and will be sent back to the driver side as the input parameter of BatchWrite#commit(WriterCommitMessage[]) or WriterCommitMessage[]).">WriterCommitMessage</a></li></ul></div></div><div id="content"><body class="package value"><div id="definition"><div class="big-circle package">p</div><p id="owner"><a href="../../../../../index.html" name="org" id="org" class="extype">org</a>.<a href="../../../../index.html" name="org.apache" id="org.apache" class="extype">apache</a>.<a href="../../../index.html" name="org.apache.spark" id="org.apache.spark" class="extype">spark</a>.<a href="../../index.html" name="org.apache.spark.sql" id="org.apache.spark.sql" class="extype">sql</a>.<a href="../index.html" name="org.apache.spark.sql.connector" id="org.apache.spark.sql.connector" class="extype">connector</a></p><h1>write<span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/write/index.html" title="Permalink"><i class="material-icons"></i></a></span></h1></div><h4 id="signature" class="signature"><span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><span class="name">write</span></span></h4><div id="comment" class="fullcommenttop"></div><div id="template"><div id="allMembers"><div id="packages" class="package members"><h3>Package Members</h3><ol><li class="indented0 " name="org.apache.spark.sql.connector.write.streaming" group="Ungrouped" fullComment="no" data-isabs="false" visbl="pub"><a id="streaming" class="anchorToMember"></a><a id="streaming:streaming" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/write/streaming/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="streaming/index.html" title=""><span class="name">streaming</span></a></span></li></ol></div><div id="types" class="types members"><h3>Type Members</h3><ol><li class="indented0 " name="org.apache.spark.sql.connector.write.BatchWrite" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="BatchWriteextendsObject" class="anchorToMember"></a><a id="BatchWrite:BatchWrite" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/write/BatchWrite.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="BatchWrite.html" title="An interface that defines how to write the data to data source for batch processing."><span class="name">BatchWrite</span></a><span class="result"> extends <span name="scala.AnyRef" class="extype">AnyRef</span></span></span><p class="shortcomment cmt">An interface that defines how to write the data to data source for batch processing.</p><div class="fullcomment"><div class="comment cmt"><p>An interface that defines how to write the data to data source for batch processing.</p><p>The writing procedure is:</p><ul><li>Create a writer factory by <code><span name="#createBatchWriterFactory(PhysicalWriteInfo)" class="extype">#createBatchWriterFactory(PhysicalWriteInfo)</span></code>, serialize
    and send it to all the partitions of the input data(RDD).</li><li>For each partition, create the data writer, and write the data of the partition with this
    writer. If all the data are written successfully, call <code><span name="DataWriter#commit()" class="extype">DataWriter#commit()</span></code>. If
    exception happens during the writing, call <code><span name="DataWriter#abort()" class="extype">DataWriter#abort()</span></code>.</li><li>If all writers are successfully committed, call <code><span name="#commit(WriterCommitMessage[])" class="extype">#commit(WriterCommitMessage[])</span></code>. If
    some writers are aborted, or the job failed with an unknown reason, call
    <code><span name="#abort(WriterCommitMessage[])" class="extype">#abort(WriterCommitMessage[])</span></code>.</li></ul><p>While Spark will retry failed writing tasks, Spark won't retry failed writing jobs. Users should
do it manually in their Spark applications if they want to retry.</p><p>Please refer to the documentation of commit/abort methods for detailed specifications.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.write.DataWriter" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="DataWriter[T]extendsCloseable" class="anchorToMember"></a><a id="DataWriter[T]:DataWriter[T]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/write/DataWriter.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="DataWriter.html" title="A data writer returned by long) and is responsible for writing data for an input RDD partition."><span class="name">DataWriter</span></a><span class="tparams">[<span name="T">T</span>]</span><span class="result"> extends <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/io/Closeable.html#java.io.Closeable" name="java.io.Closeable" id="java.io.Closeable" class="extype">Closeable</a></span></span><p class="shortcomment cmt">A data writer returned by <code><span name="DataWriterFactory#createWriter(int," class="extype">long)</span></code> and is
responsible for writing data for an input RDD partition.</p><div class="fullcomment"><div class="comment cmt"><p>A data writer returned by <code><span name="DataWriterFactory#createWriter(int," class="extype">long)</span></code> and is
responsible for writing data for an input RDD partition.</p><p>One Spark task has one exclusive data writer, so there is no thread-safe concern.</p><p><code><span name="#write(Object)" class="extype">#write(Object)</span></code> is called for each record in the input RDD partition. If one record fails
the <code><span name="#write(Object)" class="extype">#write(Object)</span></code>, <code><span name="#abort()" class="extype">#abort()</span></code> is called afterwards and the remaining records will
not be processed. If all records are successfully written, <code><span name="#commit()" class="extype">#commit()</span></code> is called.</p><p>Once a data writer returns successfully from <code><span name="#commit()" class="extype">#commit()</span></code> or <code><span name="#abort()" class="extype">#abort()</span></code>, Spark will
call <code><span name="#close()" class="extype">#close()</span></code> to let DataWriter doing resource cleanup. After calling <code><span name="#close()" class="extype">#close()</span></code>,
its lifecycle is over and Spark will not use it again.</p><p>If this data writer succeeds(all records are successfully written and <code><span name="#commit()" class="extype">#commit()</span></code>
succeeds), a <code><a href="WriterCommitMessage.html" name="org.apache.spark.sql.connector.write.WriterCommitMessage" id="org.apache.spark.sql.connector.write.WriterCommitMessage" class="extype">WriterCommitMessage</a></code> will be sent to the driver side and pass to
<code><span name="BatchWrite#commit(WriterCommitMessage[])" class="extype">BatchWrite#commit(WriterCommitMessage[])</span></code> with commit messages from other data
writers. If this data writer fails(one record fails to write or <code><span name="#commit()" class="extype">#commit()</span></code> fails), an
exception will be sent to the driver side, and Spark may retry this writing task a few times.
In each retry, <code><span name="DataWriterFactory#createWriter(int," class="extype">long)</span></code> will receive a
different <code>taskId</code>. Spark will call <code><span name="BatchWrite#abort(WriterCommitMessage[])" class="extype">BatchWrite#abort(WriterCommitMessage[])</span></code>
when the configured number of retries is exhausted.</p><p>Besides the retry mechanism, Spark may launch speculative tasks if the existing writing task
takes too long to finish. Different from retried tasks, which are launched one by one after the
previous one fails, speculative tasks are running simultaneously. It's possible that one input
RDD partition has multiple data writers with different <code>taskId</code> running at the same time,
and data sources should guarantee that these data writers don't conflict and can work together.
Implementations can coordinate with driver during <code><span name="#commit()" class="extype">#commit()</span></code> to make sure only one of
these data writers can commit successfully. Or implementations can allow all of them to commit
successfully, and have a way to revert committed data writers without the commit message, because
Spark only accepts the commit message that arrives first and ignore others.</p><p>Note that, Currently the type <code>T</code> can only be
<code><span name="org.apache.spark.sql.catalyst.InternalRow" class="extype">org.apache.spark.sql.catalyst.InternalRow</span></code>.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.write.DataWriterFactory" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="DataWriterFactoryextendsSerializable" class="anchorToMember"></a><a id="DataWriterFactory:DataWriterFactory" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/write/DataWriterFactory.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="DataWriterFactory.html" title="A factory of DataWriter returned by BatchWrite#createBatchWriterFactory(PhysicalWriteInfo), which is responsible for creating and initializing the actual data writer at executor side."><span class="name">DataWriterFactory</span></a><span class="result"> extends <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/io/Serializable.html#java.io.Serializable" name="java.io.Serializable" id="java.io.Serializable" class="extype">Serializable</a></span></span><p class="shortcomment cmt">A factory of <code><a href="DataWriter.html" name="org.apache.spark.sql.connector.write.DataWriter" id="org.apache.spark.sql.connector.write.DataWriter" class="extype">DataWriter</a></code> returned by
<code><span name="BatchWrite#createBatchWriterFactory(PhysicalWriteInfo)" class="extype">BatchWrite#createBatchWriterFactory(PhysicalWriteInfo)</span></code>, which is responsible for
creating and initializing the actual data writer at executor side.</p><div class="fullcomment"><div class="comment cmt"><p>A factory of <code><a href="DataWriter.html" name="org.apache.spark.sql.connector.write.DataWriter" id="org.apache.spark.sql.connector.write.DataWriter" class="extype">DataWriter</a></code> returned by
<code><span name="BatchWrite#createBatchWriterFactory(PhysicalWriteInfo)" class="extype">BatchWrite#createBatchWriterFactory(PhysicalWriteInfo)</span></code>, which is responsible for
creating and initializing the actual data writer at executor side.</p><p>Note that, the writer factory will be serialized and sent to executors, then the data writer
will be created on executors and do the actual writing. So this interface must be
serializable and <code><a href="DataWriter.html" name="org.apache.spark.sql.connector.write.DataWriter" id="org.apache.spark.sql.connector.write.DataWriter" class="extype">DataWriter</a></code> doesn't need to be.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.write.DeltaBatchWrite" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="DeltaBatchWriteextendsBatchWrite" class="anchorToMember"></a><a id="DeltaBatchWrite:DeltaBatchWrite" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/write/DeltaBatchWrite.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="DeltaBatchWrite.html" title="An interface that defines how to write a delta of rows during batch processing."><span class="name">DeltaBatchWrite</span></a><span class="result"> extends <a href="BatchWrite.html" name="org.apache.spark.sql.connector.write.BatchWrite" id="org.apache.spark.sql.connector.write.BatchWrite" class="extype">BatchWrite</a></span></span><p class="shortcomment cmt">An interface that defines how to write a delta of rows during batch processing.</p><div class="fullcomment"><div class="comment cmt"><p>An interface that defines how to write a delta of rows during batch processing.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Experimental</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.4.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.write.DeltaWrite" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="DeltaWriteextendsWrite" class="anchorToMember"></a><a id="DeltaWrite:DeltaWrite" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/write/DeltaWrite.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="DeltaWrite.html" title="A logical representation of a data source write that handles a delta of rows."><span class="name">DeltaWrite</span></a><span class="result"> extends <a href="Write.html" name="org.apache.spark.sql.connector.write.Write" id="org.apache.spark.sql.connector.write.Write" class="extype">Write</a></span></span><p class="shortcomment cmt">A logical representation of a data source write that handles a delta of rows.</p><div class="fullcomment"><div class="comment cmt"><p>A logical representation of a data source write that handles a delta of rows.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Experimental</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.4.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.write.DeltaWriteBuilder" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="DeltaWriteBuilderextendsWriteBuilder" class="anchorToMember"></a><a id="DeltaWriteBuilder:DeltaWriteBuilder" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/write/DeltaWriteBuilder.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="DeltaWriteBuilder.html" title="An interface for building a DeltaWrite."><span class="name">DeltaWriteBuilder</span></a><span class="result"> extends <a href="WriteBuilder.html" name="org.apache.spark.sql.connector.write.WriteBuilder" id="org.apache.spark.sql.connector.write.WriteBuilder" class="extype">WriteBuilder</a></span></span><p class="shortcomment cmt">An interface for building a <code><a href="DeltaWrite.html" name="org.apache.spark.sql.connector.write.DeltaWrite" id="org.apache.spark.sql.connector.write.DeltaWrite" class="extype">DeltaWrite</a></code>.</p><div class="fullcomment"><div class="comment cmt"><p>An interface for building a <code><a href="DeltaWrite.html" name="org.apache.spark.sql.connector.write.DeltaWrite" id="org.apache.spark.sql.connector.write.DeltaWrite" class="extype">DeltaWrite</a></code>.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Experimental</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.4.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.write.DeltaWriter" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="DeltaWriter[T]extendsDataWriter[T]" class="anchorToMember"></a><a id="DeltaWriter[T]:DeltaWriter[T]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/write/DeltaWriter.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="DeltaWriter.html" title="A data writer returned by long) and is responsible for writing a delta of rows."><span class="name">DeltaWriter</span></a><span class="tparams">[<span name="T">T</span>]</span><span class="result"> extends <a href="DataWriter.html" name="org.apache.spark.sql.connector.write.DataWriter" id="org.apache.spark.sql.connector.write.DataWriter" class="extype">DataWriter</a>[<span name="org.apache.spark.sql.connector.write.DeltaWriter.T" class="extype">T</span>]</span></span><p class="shortcomment cmt">A data writer returned by <code><span name="DeltaWriterFactory#createWriter(int," class="extype">long)</span></code> and is
responsible for writing a delta of rows.</p><div class="fullcomment"><div class="comment cmt"><p>A data writer returned by <code><span name="DeltaWriterFactory#createWriter(int," class="extype">long)</span></code> and is
responsible for writing a delta of rows.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Experimental</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.4.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.write.DeltaWriterFactory" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="DeltaWriterFactoryextendsDataWriterFactory" class="anchorToMember"></a><a id="DeltaWriterFactory:DeltaWriterFactory" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/write/DeltaWriterFactory.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="DeltaWriterFactory.html" title="A factory for creating DeltaWriters returned by DeltaBatchWrite#createBatchWriterFactory(PhysicalWriteInfo), which is responsible for creating and initializing writers at the executor side."><span class="name">DeltaWriterFactory</span></a><span class="result"> extends <a href="DataWriterFactory.html" name="org.apache.spark.sql.connector.write.DataWriterFactory" id="org.apache.spark.sql.connector.write.DataWriterFactory" class="extype">DataWriterFactory</a></span></span><p class="shortcomment cmt">A factory for creating <code><a href="DeltaWriter.html" name="org.apache.spark.sql.connector.write.DeltaWriter" id="org.apache.spark.sql.connector.write.DeltaWriter" class="extype">DeltaWriter</a></code>s returned by
<code><span name="DeltaBatchWrite#createBatchWriterFactory(PhysicalWriteInfo)" class="extype">DeltaBatchWrite#createBatchWriterFactory(PhysicalWriteInfo)</span></code>, which is responsible for
creating and initializing writers at the executor side.</p><div class="fullcomment"><div class="comment cmt"><p>A factory for creating <code><a href="DeltaWriter.html" name="org.apache.spark.sql.connector.write.DeltaWriter" id="org.apache.spark.sql.connector.write.DeltaWriter" class="extype">DeltaWriter</a></code>s returned by
<code><span name="DeltaBatchWrite#createBatchWriterFactory(PhysicalWriteInfo)" class="extype">DeltaBatchWrite#createBatchWriterFactory(PhysicalWriteInfo)</span></code>, which is responsible for
creating and initializing writers at the executor side.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Experimental</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.4.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.write.LogicalWriteInfo" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="LogicalWriteInfoextendsObject" class="anchorToMember"></a><a id="LogicalWriteInfo:LogicalWriteInfo" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/write/LogicalWriteInfo.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="LogicalWriteInfo.html" title="This interface contains logical write information that data sources can use when generating a WriteBuilder."><span class="name">LogicalWriteInfo</span></a><span class="result"> extends <span name="scala.AnyRef" class="extype">AnyRef</span></span></span><p class="shortcomment cmt">This interface contains logical write information that data sources can use when generating a
<code><a href="WriteBuilder.html" name="org.apache.spark.sql.connector.write.WriteBuilder" id="org.apache.spark.sql.connector.write.WriteBuilder" class="extype">WriteBuilder</a></code>.</p><div class="fullcomment"><div class="comment cmt"><p>This interface contains logical write information that data sources can use when generating a
<code><a href="WriteBuilder.html" name="org.apache.spark.sql.connector.write.WriteBuilder" id="org.apache.spark.sql.connector.write.WriteBuilder" class="extype">WriteBuilder</a></code>.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.write.PhysicalWriteInfo" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="PhysicalWriteInfoextendsObject" class="anchorToMember"></a><a id="PhysicalWriteInfo:PhysicalWriteInfo" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/write/PhysicalWriteInfo.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="PhysicalWriteInfo.html" title="This interface contains physical write information that data sources can use when generating a DataWriterFactory or a StreamingDataWriterFactory."><span class="name">PhysicalWriteInfo</span></a><span class="result"> extends <span name="scala.AnyRef" class="extype">AnyRef</span></span></span><p class="shortcomment cmt">This interface contains physical write information that data sources can use when
generating a <code><a href="DataWriterFactory.html" name="org.apache.spark.sql.connector.write.DataWriterFactory" id="org.apache.spark.sql.connector.write.DataWriterFactory" class="extype">DataWriterFactory</a></code> or a <code><span name="StreamingDataWriterFactory" class="extype">StreamingDataWriterFactory</span></code>.</p><div class="fullcomment"><div class="comment cmt"><p>This interface contains physical write information that data sources can use when
generating a <code><a href="DataWriterFactory.html" name="org.apache.spark.sql.connector.write.DataWriterFactory" id="org.apache.spark.sql.connector.write.DataWriterFactory" class="extype">DataWriterFactory</a></code> or a <code><span name="StreamingDataWriterFactory" class="extype">StreamingDataWriterFactory</span></code>.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.write.RequiresDistributionAndOrdering" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="RequiresDistributionAndOrderingextendsWrite" class="anchorToMember"></a><a id="RequiresDistributionAndOrdering:RequiresDistributionAndOrdering" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/write/RequiresDistributionAndOrdering.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="RequiresDistributionAndOrdering.html" title="A write that requires a specific distribution and ordering of data."><span class="name">RequiresDistributionAndOrdering</span></a><span class="result"> extends <a href="Write.html" name="org.apache.spark.sql.connector.write.Write" id="org.apache.spark.sql.connector.write.Write" class="extype">Write</a></span></span><p class="shortcomment cmt">A write that requires a specific distribution and ordering of data.</p><div class="fullcomment"><div class="comment cmt"><p>A write that requires a specific distribution and ordering of data.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Experimental</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.2.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.write.RowLevelOperation" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="RowLevelOperationextendsObject" class="anchorToMember"></a><a id="RowLevelOperation:RowLevelOperation" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/write/RowLevelOperation.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="RowLevelOperation.html" title="A logical representation of a data source DELETE, UPDATE, or MERGE operation that requires rewriting data."><span class="name">RowLevelOperation</span></a><span class="result"> extends <span name="scala.AnyRef" class="extype">AnyRef</span></span></span><p class="shortcomment cmt">A logical representation of a data source DELETE, UPDATE, or MERGE operation that requires
rewriting data.</p><div class="fullcomment"><div class="comment cmt"><p>A logical representation of a data source DELETE, UPDATE, or MERGE operation that requires
rewriting data.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Experimental</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.3.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.write.RowLevelOperationBuilder" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="RowLevelOperationBuilderextendsObject" class="anchorToMember"></a><a id="RowLevelOperationBuilder:RowLevelOperationBuilder" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/write/RowLevelOperationBuilder.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="RowLevelOperationBuilder.html" title="An interface for building a RowLevelOperation."><span class="name">RowLevelOperationBuilder</span></a><span class="result"> extends <span name="scala.AnyRef" class="extype">AnyRef</span></span></span><p class="shortcomment cmt">An interface for building a <code><a href="RowLevelOperation.html" name="org.apache.spark.sql.connector.write.RowLevelOperation" id="org.apache.spark.sql.connector.write.RowLevelOperation" class="extype">RowLevelOperation</a></code>.</p><div class="fullcomment"><div class="comment cmt"><p>An interface for building a <code><a href="RowLevelOperation.html" name="org.apache.spark.sql.connector.write.RowLevelOperation" id="org.apache.spark.sql.connector.write.RowLevelOperation" class="extype">RowLevelOperation</a></code>.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Experimental</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.3.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.write.RowLevelOperationInfo" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="RowLevelOperationInfoextendsObject" class="anchorToMember"></a><a id="RowLevelOperationInfo:RowLevelOperationInfo" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/write/RowLevelOperationInfo.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="RowLevelOperationInfo.html" title="An interface with logical information for a row-level operation such as DELETE, UPDATE, MERGE."><span class="name">RowLevelOperationInfo</span></a><span class="result"> extends <span name="scala.AnyRef" class="extype">AnyRef</span></span></span><p class="shortcomment cmt">An interface with logical information for a row-level operation such as DELETE, UPDATE, MERGE.</p><div class="fullcomment"><div class="comment cmt"><p>An interface with logical information for a row-level operation such as DELETE, UPDATE, MERGE.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Experimental</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.3.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.write.SupportsDelta" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="SupportsDeltaextendsRowLevelOperation" class="anchorToMember"></a><a id="SupportsDelta:SupportsDelta" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/write/SupportsDelta.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="SupportsDelta.html" title="A mix-in interface for RowLevelOperation."><span class="name">SupportsDelta</span></a><span class="result"> extends <a href="RowLevelOperation.html" name="org.apache.spark.sql.connector.write.RowLevelOperation" id="org.apache.spark.sql.connector.write.RowLevelOperation" class="extype">RowLevelOperation</a></span></span><p class="shortcomment cmt">A mix-in interface for <code><a href="RowLevelOperation.html" name="org.apache.spark.sql.connector.write.RowLevelOperation" id="org.apache.spark.sql.connector.write.RowLevelOperation" class="extype">RowLevelOperation</a></code>.</p><div class="fullcomment"><div class="comment cmt"><p>A mix-in interface for <code><a href="RowLevelOperation.html" name="org.apache.spark.sql.connector.write.RowLevelOperation" id="org.apache.spark.sql.connector.write.RowLevelOperation" class="extype">RowLevelOperation</a></code>. Data sources can implement this interface
to indicate they support handling deltas of rows.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Experimental</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.4.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.write.SupportsDynamicOverwrite" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="SupportsDynamicOverwriteextendsWriteBuilder" class="anchorToMember"></a><a id="SupportsDynamicOverwrite:SupportsDynamicOverwrite" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/write/SupportsDynamicOverwrite.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="SupportsDynamicOverwrite.html" title="Write builder trait for tables that support dynamic partition overwrite."><span class="name">SupportsDynamicOverwrite</span></a><span class="result"> extends <a href="WriteBuilder.html" name="org.apache.spark.sql.connector.write.WriteBuilder" id="org.apache.spark.sql.connector.write.WriteBuilder" class="extype">WriteBuilder</a></span></span><p class="shortcomment cmt">Write builder trait for tables that support dynamic partition overwrite.</p><div class="fullcomment"><div class="comment cmt"><p>Write builder trait for tables that support dynamic partition overwrite.</p><p>A write that dynamically overwrites partitions removes all existing data in each logical
partition for which the write will commit new data. Any existing logical partition for which the
write does not contain data will remain unchanged.</p><p>This is provided to implement SQL compatible with Hive table operations but is not recommended.
Instead, use the <code><a href="SupportsOverwriteV2.html" name="org.apache.spark.sql.connector.write.SupportsOverwriteV2" id="org.apache.spark.sql.connector.write.SupportsOverwriteV2" class="extype">overwrite by filter API</a></code> to explicitly replace data.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.write.SupportsOverwrite" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="SupportsOverwriteextendsSupportsOverwriteV2" class="anchorToMember"></a><a id="SupportsOverwrite:SupportsOverwrite" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/write/SupportsOverwrite.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="SupportsOverwrite.html" title="Write builder trait for tables that support overwrite by filter."><span class="name">SupportsOverwrite</span></a><span class="result"> extends <a href="SupportsOverwriteV2.html" name="org.apache.spark.sql.connector.write.SupportsOverwriteV2" id="org.apache.spark.sql.connector.write.SupportsOverwriteV2" class="extype">SupportsOverwriteV2</a></span></span><p class="shortcomment cmt">Write builder trait for tables that support overwrite by filter.</p><div class="fullcomment"><div class="comment cmt"><p>Write builder trait for tables that support overwrite by filter.</p><p>Overwriting data by filter will delete any data that matches the filter and replace it with data
that is committed in the write.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.write.SupportsOverwriteV2" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="SupportsOverwriteV2extendsWriteBuilderwithSupportsTruncate" class="anchorToMember"></a><a id="SupportsOverwriteV2:SupportsOverwriteV2" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/write/SupportsOverwriteV2.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="SupportsOverwriteV2.html" title="Write builder trait for tables that support overwrite by filter."><span class="name">SupportsOverwriteV2</span></a><span class="result"> extends <a href="WriteBuilder.html" name="org.apache.spark.sql.connector.write.WriteBuilder" id="org.apache.spark.sql.connector.write.WriteBuilder" class="extype">WriteBuilder</a> with <a href="SupportsTruncate.html" name="org.apache.spark.sql.connector.write.SupportsTruncate" id="org.apache.spark.sql.connector.write.SupportsTruncate" class="extype">SupportsTruncate</a></span></span><p class="shortcomment cmt">Write builder trait for tables that support overwrite by filter.</p><div class="fullcomment"><div class="comment cmt"><p>Write builder trait for tables that support overwrite by filter.</p><p>Overwriting data by filter will delete any data that matches the filter and replace it with data
that is committed in the write.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.4.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.write.SupportsTruncate" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="SupportsTruncateextendsWriteBuilder" class="anchorToMember"></a><a id="SupportsTruncate:SupportsTruncate" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/write/SupportsTruncate.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="SupportsTruncate.html" title="Write builder trait for tables that support truncation."><span class="name">SupportsTruncate</span></a><span class="result"> extends <a href="WriteBuilder.html" name="org.apache.spark.sql.connector.write.WriteBuilder" id="org.apache.spark.sql.connector.write.WriteBuilder" class="extype">WriteBuilder</a></span></span><p class="shortcomment cmt">Write builder trait for tables that support truncation.</p><div class="fullcomment"><div class="comment cmt"><p>Write builder trait for tables that support truncation.</p><p>Truncation removes all data in a table and replaces it with data that is committed in the write.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.write.V1Write" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="V1WriteextendsWrite" class="anchorToMember"></a><a id="V1Write:V1Write" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/write/V1Write.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="V1Write.html" title="A logical write that should be executed using V1 InsertableRelation interface."><span class="name">V1Write</span></a><span class="result"> extends <a href="Write.html" name="org.apache.spark.sql.connector.write.Write" id="org.apache.spark.sql.connector.write.Write" class="extype">Write</a></span></span><p class="shortcomment cmt">A logical write that should be executed using V1 InsertableRelation interface.</p><div class="fullcomment"><div class="comment cmt"><p>A logical write that should be executed using V1 InsertableRelation interface.</p><p>Tables that have <code><span name="TableCapability#V1_BATCH_WRITE" class="extype">TableCapability#V1_BATCH_WRITE</span></code> in the list of their capabilities
must build <code><a href="V1Write.html" name="org.apache.spark.sql.connector.write.V1Write" id="org.apache.spark.sql.connector.write.V1Write" class="extype">V1Write</a></code>.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Unstable</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.2.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.write.Write" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="WriteextendsObject" class="anchorToMember"></a><a id="Write:Write" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/write/Write.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="Write.html" title="A logical representation of a data source write."><span class="name">Write</span></a><span class="result"> extends <span name="scala.AnyRef" class="extype">AnyRef</span></span></span><p class="shortcomment cmt">A logical representation of a data source write.</p><div class="fullcomment"><div class="comment cmt"><p>A logical representation of a data source write.</p><p>This logical representation is shared between batch and streaming write. Data sources must
implement the corresponding methods in this interface to match what the table promises
to support. For example, <code><span name="#toBatch()" class="extype">#toBatch()</span></code> must be implemented if the <code><span name="Table" class="extype">Table</span></code> that
creates this <code><a href="Write.html" name="org.apache.spark.sql.connector.write.Write" id="org.apache.spark.sql.connector.write.Write" class="extype">Write</a></code> returns <code><span name="TableCapability#BATCH_WRITE" class="extype">TableCapability#BATCH_WRITE</span></code> support in its
<code><span name="Table#capabilities()" class="extype">Table#capabilities()</span></code>.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.2.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.write.WriteBuilder" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="WriteBuilderextendsObject" class="anchorToMember"></a><a id="WriteBuilder:WriteBuilder" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/write/WriteBuilder.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="WriteBuilder.html" title="An interface for building the Write."><span class="name">WriteBuilder</span></a><span class="result"> extends <span name="scala.AnyRef" class="extype">AnyRef</span></span></span><p class="shortcomment cmt">An interface for building the <code><a href="Write.html" name="org.apache.spark.sql.connector.write.Write" id="org.apache.spark.sql.connector.write.Write" class="extype">Write</a></code>.</p><div class="fullcomment"><div class="comment cmt"><p>An interface for building the <code><a href="Write.html" name="org.apache.spark.sql.connector.write.Write" id="org.apache.spark.sql.connector.write.Write" class="extype">Write</a></code>. Implementations can mix in some interfaces to
support different ways to write data to data sources.</p><p>Unless modified by a mixin interface, the <code><a href="Write.html" name="org.apache.spark.sql.connector.write.Write" id="org.apache.spark.sql.connector.write.Write" class="extype">Write</a></code> configured by this builder is to
append data without affecting existing data.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.write.WriterCommitMessage" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="WriterCommitMessageextendsSerializable" class="anchorToMember"></a><a id="WriterCommitMessage:WriterCommitMessage" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../org/apache/spark/sql/connector/write/WriterCommitMessage.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="WriterCommitMessage.html" title="A commit message returned by DataWriter#commit() and will be sent back to the driver side as the input parameter of BatchWrite#commit(WriterCommitMessage[]) or WriterCommitMessage[])."><span class="name">WriterCommitMessage</span></a><span class="result"> extends <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/io/Serializable.html#java.io.Serializable" name="java.io.Serializable" id="java.io.Serializable" class="extype">Serializable</a></span></span><p class="shortcomment cmt">A commit message returned by <code><span name="DataWriter#commit()" class="extype">DataWriter#commit()</span></code> and will be sent back to the driver side
as the input parameter of <code><span name="BatchWrite#commit(WriterCommitMessage[])" class="extype">BatchWrite#commit(WriterCommitMessage[])</span></code> or
<code><span name="StreamingWrite#commit(long," class="extype">WriterCommitMessage[])</span></code>.</p><div class="fullcomment"><div class="comment cmt"><p>A commit message returned by <code><span name="DataWriter#commit()" class="extype">DataWriter#commit()</span></code> and will be sent back to the driver side
as the input parameter of <code><span name="BatchWrite#commit(WriterCommitMessage[])" class="extype">BatchWrite#commit(WriterCommitMessage[])</span></code> or
<code><span name="StreamingWrite#commit(long," class="extype">WriterCommitMessage[])</span></code>.</p><p>This is an empty interface, data sources should define their own message class and use it when
generating messages at executor side and handling the messages at driver side.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.0.0</p></dd></dl></div></li></ol></div></div><div id="inheritedMembers"></div><div id="groupedMembers"><div name="Ungrouped" class="group"><h3>Ungrouped</h3></div></div></div><div id="tooltip"></div><div id="footer"></div></body></div></div></div></body></html>
