<!DOCTYPE html ><html><head><meta http-equiv="X-UA-Compatible" content="IE=edge"/><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" name="viewport"/><title>Spark 4.0.0-preview2 ScalaDoc  - org.apache.spark.sql.connector.write.streaming</title><meta content="Spark 4.0.0 - preview2 ScalaDoc - org.apache.spark.sql.connector.write.streaming" name="description"/><meta content="Spark 4.0.0 preview2 ScalaDoc org.apache.spark.sql.connector.write.streaming" name="keywords"/><meta http-equiv="content-type" content="text/html; charset=UTF-8"/><link href="../../../../../../../lib/index.css" media="screen" type="text/css" rel="stylesheet"/><link href="../../../../../../../lib/template.css" media="screen" type="text/css" rel="stylesheet"/><link href="../../../../../../../lib/print.css" media="print" type="text/css" rel="stylesheet"/><link href="../../../../../../../lib/diagrams.css" media="screen" type="text/css" rel="stylesheet" id="diagrams-css"/><script type="text/javascript" src="../../../../../../../lib/jquery.min.js"></script><script type="text/javascript" src="../../../../../../../lib/index.js"></script><script type="text/javascript" src="../../../../../../../index.js"></script><script type="text/javascript" src="../../../../../../../lib/scheduler.js"></script><script type="text/javascript" src="../../../../../../../lib/template.js"></script><script type="text/javascript">/* this variable can be used by the JS to determine the path to the root document */
var toRoot = '../../../../../../../';</script></head><body><div id="search"><span id="doc-title">Spark 4.0.0-preview2 ScalaDoc<span id="doc-version"></span></span> <span class="close-results"><span class="left">&lt;</span> Back</span><div id="textfilter"><span class="input"><input autocapitalize="none" placeholder="Search" id="index-input" type="text" accesskey="/"/><i class="clear material-icons"></i><i id="search-icon" class="material-icons"></i></span></div></div><div id="search-results"><div id="search-progress"><div id="progress-fill"></div></div><div id="results-content"><div id="entity-results"></div><div id="member-results"></div></div></div><div id="content-scroll-container" style="-webkit-overflow-scrolling: touch;"><div id="content-container" style="-webkit-overflow-scrolling: touch;"><div id="subpackage-spacer"><div id="packages"><h1>Packages</h1><ul><li class="indented0 " name="_root_.root" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="_root_" class="anchorToMember"></a><a id="root:_root_" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../../index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../../../../../../index.html" title=""><span class="name">root</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../../../../../index.html" name="_root_" id="_root_" class="extype">root</a></dd></dl></div></li><li class="indented1 " name="_root_.org" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="org" class="anchorToMember"></a><a id="org:org" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../../org/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../../../../../index.html" title=""><span class="name">org</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../../../../../index.html" name="_root_" id="_root_" class="extype">root</a></dd></dl></div></li><li class="indented2 " name="org.apache" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="apache" class="anchorToMember"></a><a id="apache:apache" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../../org/apache/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../../../../index.html" title=""><span class="name">apache</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../../../../index.html" name="org" id="org" class="extype">org</a></dd></dl></div></li><li class="indented3 " name="org.apache.spark" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="spark" class="anchorToMember"></a><a id="spark:spark" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../../org/apache/spark/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../../../index.html" title="Core Spark functionality."><span class="name">spark</span></a></span><p class="shortcomment cmt">Core Spark functionality.</p><div class="fullcomment"><div class="comment cmt"><p>Core Spark functionality. <a href="../../../../SparkContext.html" name="org.apache.spark.SparkContext" id="org.apache.spark.SparkContext" class="extype">org.apache.spark.SparkContext</a> serves as the main entry point to
Spark, while <a href="../../../../rdd/RDD.html" name="org.apache.spark.rdd.RDD" id="org.apache.spark.rdd.RDD" class="extype">org.apache.spark.rdd.RDD</a> is the data type representing a distributed collection,
and provides most parallel operations.</p><p>In addition, <a href="../../../../rdd/PairRDDFunctions.html" name="org.apache.spark.rdd.PairRDDFunctions" id="org.apache.spark.rdd.PairRDDFunctions" class="extype">org.apache.spark.rdd.PairRDDFunctions</a> contains operations available only on RDDs
of key-value pairs, such as <code>groupByKey</code> and <code>join</code>; <a href="../../../../rdd/DoubleRDDFunctions.html" name="org.apache.spark.rdd.DoubleRDDFunctions" id="org.apache.spark.rdd.DoubleRDDFunctions" class="extype">org.apache.spark.rdd.DoubleRDDFunctions</a>
contains operations available only on RDDs of Doubles; and
<a href="../../../../rdd/SequenceFileRDDFunctions.html" name="org.apache.spark.rdd.SequenceFileRDDFunctions" id="org.apache.spark.rdd.SequenceFileRDDFunctions" class="extype">org.apache.spark.rdd.SequenceFileRDDFunctions</a> contains operations available on RDDs that can
be saved as SequenceFiles. These operations are automatically available on any RDD of the right
type (e.g. RDD[(Int, Int)] through implicit conversions.</p><p>Java programmers should reference the <a href="../../../../api/java/index.html" name="org.apache.spark.api.java" id="org.apache.spark.api.java" class="extype">org.apache.spark.api.java</a> package
for Spark programming APIs in Java.</p><p>Classes and methods marked with <span class="experimental badge" style="float: none;">
Experimental</span> are user-facing features which have not been officially adopted by the
Spark project. These are subject to change or removal in minor releases.</p><p>Classes and methods marked with <span class="developer badge" style="float: none;">
Developer API</span> are intended for advanced users want to extend Spark through lower
level interfaces. These are subject to changes or removal in minor releases.
</p></div><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../../../index.html" name="org.apache" id="org.apache" class="extype">apache</a></dd></dl></div></li><li class="indented4 " name="org.apache.spark.sql" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="sql" class="anchorToMember"></a><a id="sql:sql" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../../org/apache/spark/sql/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../../index.html" title="Allows the execution of relational queries, including those expressed in SQL using Spark."><span class="name">sql</span></a></span><p class="shortcomment cmt">Allows the execution of relational queries, including those expressed in SQL using Spark.</p><div class="fullcomment"><div class="comment cmt"><p>Allows the execution of relational queries, including those expressed in SQL using Spark.
</p></div><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../../index.html" name="org.apache.spark" id="org.apache.spark" class="extype">spark</a></dd></dl></div></li><li class="indented5 " name="org.apache.spark.sql.connector" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="connector" class="anchorToMember"></a><a id="connector:connector" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../../org/apache/spark/sql/connector/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../index.html" title=""><span class="name">connector</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../index.html" name="org.apache.spark.sql" id="org.apache.spark.sql" class="extype">sql</a></dd></dl></div></li><li class="indented6 " name="org.apache.spark.sql.connector.write" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="write" class="anchorToMember"></a><a id="write:write" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../../org/apache/spark/sql/connector/write/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../index.html" title=""><span class="name">write</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../index.html" name="org.apache.spark.sql.connector" id="org.apache.spark.sql.connector" class="extype">connector</a></dd></dl></div></li><li class="indented7 current" name="org.apache.spark.sql.connector.write.streaming" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="streaming" class="anchorToMember"></a><a id="streaming:streaming" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../../org/apache/spark/sql/connector/write/streaming/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><span class="name">streaming</span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../index.html" name="org.apache.spark.sql.connector.write" id="org.apache.spark.sql.connector.write" class="extype">write</a></dd></dl></div></li><li class="current-entities indented7"><span class="separator"></span> <a href="StreamingDataWriterFactory.html" title="A factory of DataWriter returned by StreamingWrite#createStreamingWriterFactory(PhysicalWriteInfo), which is responsible for creating and initializing the actual data writer at executor side." class="trait"></a><a href="StreamingDataWriterFactory.html" title="A factory of DataWriter returned by StreamingWrite#createStreamingWriterFactory(PhysicalWriteInfo), which is responsible for creating and initializing the actual data writer at executor side.">StreamingDataWriterFactory</a></li><li class="current-entities indented7"><span class="separator"></span> <a href="StreamingWrite.html" title="An interface that defines how to write the data to data source in streaming queries." class="trait"></a><a href="StreamingWrite.html" title="An interface that defines how to write the data to data source in streaming queries.">StreamingWrite</a></li></ul></div></div><div id="content"><body class="package value"><div id="definition"><div class="big-circle package">p</div><p id="owner"><a href="../../../../../../index.html" name="org" id="org" class="extype">org</a>.<a href="../../../../../index.html" name="org.apache" id="org.apache" class="extype">apache</a>.<a href="../../../../index.html" name="org.apache.spark" id="org.apache.spark" class="extype">spark</a>.<a href="../../../index.html" name="org.apache.spark.sql" id="org.apache.spark.sql" class="extype">sql</a>.<a href="../../index.html" name="org.apache.spark.sql.connector" id="org.apache.spark.sql.connector" class="extype">connector</a>.<a href="../index.html" name="org.apache.spark.sql.connector.write" id="org.apache.spark.sql.connector.write" class="extype">write</a></p><h1>streaming<span class="permalink"><a href="../../../../../../../org/apache/spark/sql/connector/write/streaming/index.html" title="Permalink"><i class="material-icons"></i></a></span></h1></div><h4 id="signature" class="signature"><span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><span class="name">streaming</span></span></h4><div id="comment" class="fullcommenttop"></div><div id="template"><div id="allMembers"><div id="types" class="types members"><h3>Type Members</h3><ol><li class="indented0 " name="org.apache.spark.sql.connector.write.streaming.StreamingDataWriterFactory" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="StreamingDataWriterFactoryextendsSerializable" class="anchorToMember"></a><a id="StreamingDataWriterFactory:StreamingDataWriterFactory" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../../org/apache/spark/sql/connector/write/streaming/StreamingDataWriterFactory.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="StreamingDataWriterFactory.html" title="A factory of DataWriter returned by StreamingWrite#createStreamingWriterFactory(PhysicalWriteInfo), which is responsible for creating and initializing the actual data writer at executor side."><span class="name">StreamingDataWriterFactory</span></a><span class="result"> extends <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/io/Serializable.html#java.io.Serializable" name="java.io.Serializable" id="java.io.Serializable" class="extype">Serializable</a></span></span><p class="shortcomment cmt">A factory of <code><a href="../DataWriter.html" name="org.apache.spark.sql.connector.write.DataWriter" id="org.apache.spark.sql.connector.write.DataWriter" class="extype">DataWriter</a></code> returned by
<code><span name="StreamingWrite#createStreamingWriterFactory(PhysicalWriteInfo)" class="extype">StreamingWrite#createStreamingWriterFactory(PhysicalWriteInfo)</span></code>, which is responsible for
creating and initializing the actual data writer at executor side.</p><div class="fullcomment"><div class="comment cmt"><p>A factory of <code><a href="../DataWriter.html" name="org.apache.spark.sql.connector.write.DataWriter" id="org.apache.spark.sql.connector.write.DataWriter" class="extype">DataWriter</a></code> returned by
<code><span name="StreamingWrite#createStreamingWriterFactory(PhysicalWriteInfo)" class="extype">StreamingWrite#createStreamingWriterFactory(PhysicalWriteInfo)</span></code>, which is responsible for
creating and initializing the actual data writer at executor side.</p><p>Note that, the writer factory will be serialized and sent to executors, then the data writer
will be created on executors and do the actual writing. So this interface must be
serializable and <code><a href="../DataWriter.html" name="org.apache.spark.sql.connector.write.DataWriter" id="org.apache.spark.sql.connector.write.DataWriter" class="extype">DataWriter</a></code> doesn't need to be.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.connector.write.streaming.StreamingWrite" group="Ungrouped" fullComment="yes" data-isabs="true" visbl="pub"><a id="StreamingWriteextendsObject" class="anchorToMember"></a><a id="StreamingWrite:StreamingWrite" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../../../org/apache/spark/sql/connector/write/streaming/StreamingWrite.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">trait</span></span> <span class="symbol"><a href="StreamingWrite.html" title="An interface that defines how to write the data to data source in streaming queries."><span class="name">StreamingWrite</span></a><span class="result"> extends <span name="scala.AnyRef" class="extype">AnyRef</span></span></span><p class="shortcomment cmt">An interface that defines how to write the data to data source in streaming queries.</p><div class="fullcomment"><div class="comment cmt"><p>An interface that defines how to write the data to data source in streaming queries.</p><p>The writing procedure is:</p><ul><li>Create a writer factory by <code><span name="#createStreamingWriterFactory(PhysicalWriteInfo)" class="extype">#createStreamingWriterFactory(PhysicalWriteInfo)</span></code>,
  serialize and send it to all the partitions of the input data(RDD).</li><li>For each epoch in each partition, create the data writer, and write the data of the
  epoch in the partition with this writer. If all the data are written successfully, call
  <code><span name="DataWriter#commit()" class="extype">DataWriter#commit()</span></code>. If exception happens during the writing, call
  <code><span name="DataWriter#abort()" class="extype">DataWriter#abort()</span></code>.</li><li>If writers in all partitions of one epoch are successfully committed, call
  <code><span name="#commit(long," class="extype">WriterCommitMessage[])</span></code>. If some writers are aborted, or the job failed
  with an unknown reason, call <code><span name="#abort(long," class="extype">WriterCommitMessage[])</span></code>.</li></ul><p>While Spark will retry failed writing tasks, Spark won't retry failed writing jobs. Users should
do it manually in their Spark applications if they want to retry.</p><p>Please refer to the documentation of commit/abort methods for detailed specifications.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>3.0.0</p></dd></dl></div></li></ol></div></div><div id="inheritedMembers"></div><div id="groupedMembers"><div name="Ungrouped" class="group"><h3>Ungrouped</h3></div></div></div><div id="tooltip"></div><div id="footer"></div></body></div></div></div></body></html>
