<!DOCTYPE html ><html><head><meta http-equiv="X-UA-Compatible" content="IE=edge"/><meta content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" name="viewport"/><title>Spark 4.0.0-preview2 ScalaDoc  - org.apache.spark.sql.streaming.DataStreamWriter</title><meta content="Spark 4.0.0 - preview2 ScalaDoc - org.apache.spark.sql.streaming.DataStreamWriter" name="description"/><meta content="Spark 4.0.0 preview2 ScalaDoc org.apache.spark.sql.streaming.DataStreamWriter" name="keywords"/><meta http-equiv="content-type" content="text/html; charset=UTF-8"/><link href="../../../../../lib/index.css" media="screen" type="text/css" rel="stylesheet"/><link href="../../../../../lib/template.css" media="screen" type="text/css" rel="stylesheet"/><link href="../../../../../lib/print.css" media="print" type="text/css" rel="stylesheet"/><link href="../../../../../lib/diagrams.css" media="screen" type="text/css" rel="stylesheet" id="diagrams-css"/><script type="text/javascript" src="../../../../../lib/jquery.min.js"></script><script type="text/javascript" src="../../../../../lib/index.js"></script><script type="text/javascript" src="../../../../../index.js"></script><script type="text/javascript" src="../../../../../lib/scheduler.js"></script><script type="text/javascript" src="../../../../../lib/template.js"></script><script type="text/javascript">/* this variable can be used by the JS to determine the path to the root document */
var toRoot = '../../../../../';</script></head><body><div id="search"><span id="doc-title">Spark 4.0.0-preview2 ScalaDoc<span id="doc-version"></span></span> <span class="close-results"><span class="left">&lt;</span> Back</span><div id="textfilter"><span class="input"><input autocapitalize="none" placeholder="Search" id="index-input" type="text" accesskey="/"/><i class="clear material-icons"></i><i id="search-icon" class="material-icons"></i></span></div></div><div id="search-results"><div id="search-progress"><div id="progress-fill"></div></div><div id="results-content"><div id="entity-results"></div><div id="member-results"></div></div></div><div id="content-scroll-container" style="-webkit-overflow-scrolling: touch;"><div id="content-container" style="-webkit-overflow-scrolling: touch;"><div id="subpackage-spacer"><div id="packages"><h1>Packages</h1><ul><li class="indented0 " name="_root_.root" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="_root_" class="anchorToMember"></a><a id="root:_root_" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../../../../index.html" title=""><span class="name">root</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../../../index.html" name="_root_" id="_root_" class="extype">root</a></dd></dl></div></li><li class="indented1 " name="_root_.org" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="org" class="anchorToMember"></a><a id="org:org" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../../../index.html" title=""><span class="name">org</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../../../index.html" name="_root_" id="_root_" class="extype">root</a></dd></dl></div></li><li class="indented2 " name="org.apache" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="apache" class="anchorToMember"></a><a id="apache:apache" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../../index.html" title=""><span class="name">apache</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../../index.html" name="org" id="org" class="extype">org</a></dd></dl></div></li><li class="indented3 " name="org.apache.spark" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="spark" class="anchorToMember"></a><a id="spark:spark" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../../index.html" title="Core Spark functionality."><span class="name">spark</span></a></span><p class="shortcomment cmt">Core Spark functionality.</p><div class="fullcomment"><div class="comment cmt"><p>Core Spark functionality. <a href="../../SparkContext.html" name="org.apache.spark.SparkContext" id="org.apache.spark.SparkContext" class="extype">org.apache.spark.SparkContext</a> serves as the main entry point to
Spark, while <a href="../../rdd/RDD.html" name="org.apache.spark.rdd.RDD" id="org.apache.spark.rdd.RDD" class="extype">org.apache.spark.rdd.RDD</a> is the data type representing a distributed collection,
and provides most parallel operations.</p><p>In addition, <a href="../../rdd/PairRDDFunctions.html" name="org.apache.spark.rdd.PairRDDFunctions" id="org.apache.spark.rdd.PairRDDFunctions" class="extype">org.apache.spark.rdd.PairRDDFunctions</a> contains operations available only on RDDs
of key-value pairs, such as <code>groupByKey</code> and <code>join</code>; <a href="../../rdd/DoubleRDDFunctions.html" name="org.apache.spark.rdd.DoubleRDDFunctions" id="org.apache.spark.rdd.DoubleRDDFunctions" class="extype">org.apache.spark.rdd.DoubleRDDFunctions</a>
contains operations available only on RDDs of Doubles; and
<a href="../../rdd/SequenceFileRDDFunctions.html" name="org.apache.spark.rdd.SequenceFileRDDFunctions" id="org.apache.spark.rdd.SequenceFileRDDFunctions" class="extype">org.apache.spark.rdd.SequenceFileRDDFunctions</a> contains operations available on RDDs that can
be saved as SequenceFiles. These operations are automatically available on any RDD of the right
type (e.g. RDD[(Int, Int)] through implicit conversions.</p><p>Java programmers should reference the <a href="../../api/java/index.html" name="org.apache.spark.api.java" id="org.apache.spark.api.java" class="extype">org.apache.spark.api.java</a> package
for Spark programming APIs in Java.</p><p>Classes and methods marked with <span class="experimental badge" style="float: none;">
Experimental</span> are user-facing features which have not been officially adopted by the
Spark project. These are subject to change or removal in minor releases.</p><p>Classes and methods marked with <span class="developer badge" style="float: none;">
Developer API</span> are intended for advanced users want to extend Spark through lower
level interfaces. These are subject to changes or removal in minor releases.
</p></div><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../../index.html" name="org.apache" id="org.apache" class="extype">apache</a></dd></dl></div></li><li class="indented4 " name="org.apache.spark.sql" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="sql" class="anchorToMember"></a><a id="sql:sql" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="../index.html" title="Allows the execution of relational queries, including those expressed in SQL using Spark."><span class="name">sql</span></a></span><p class="shortcomment cmt">Allows the execution of relational queries, including those expressed in SQL using Spark.</p><div class="fullcomment"><div class="comment cmt"><p>Allows the execution of relational queries, including those expressed in SQL using Spark.
</p></div><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../../index.html" name="org.apache.spark" id="org.apache.spark" class="extype">spark</a></dd></dl></div></li><li class="indented5 " name="org.apache.spark.sql.streaming" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="streaming" class="anchorToMember"></a><a id="streaming:streaming" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/index.html" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">package</span></span> <span class="symbol"><a href="index.html" title=""><span class="name">streaming</span></a></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd><a href="../index.html" name="org.apache.spark.sql" id="org.apache.spark.sql" class="extype">sql</a></dd></dl></div></li><li class="current-entities indented5"><span class="separator"></span> <a href="DataStreamReader.html" title="Interface used to load a streaming Dataset from external storage systems (e.g." class="class"></a><a href="DataStreamReader.html" title="Interface used to load a streaming Dataset from external storage systems (e.g.">DataStreamReader</a></li><li class="current-entities indented5"><a href="DataStreamWriter$.html" title="" class="object"></a> <a href="" title="Interface used to write a streaming Dataset to external storage systems (e.g." class="class"></a><a href="" title="Interface used to write a streaming Dataset to external storage systems (e.g.">DataStreamWriter</a></li><li class="current-entities indented5"><span class="separator"></span> <a href="GroupState.html" title=":: Experimental ::" class="trait"></a><a href="GroupState.html" title=":: Experimental ::">GroupState</a></li><li class="current-entities indented5"><span class="separator"></span> <a href="GroupStateTimeout.html" title="Represents the type of timeouts possible for the Dataset operations mapGroupsWithState and flatMapGroupsWithState." class="class"></a><a href="GroupStateTimeout.html" title="Represents the type of timeouts possible for the Dataset operations mapGroupsWithState and flatMapGroupsWithState.">GroupStateTimeout</a></li><li class="current-entities indented5"><span class="separator"></span> <a href="MapState.html" title="" class="trait"></a><a href="MapState.html" title="">MapState</a></li><li class="current-entities indented5"><span class="separator"></span> <a href="OutputMode.html" title="OutputMode describes what data will be written to a streaming sink when there is new data available in a streaming DataFrame/Dataset." class="class"></a><a href="OutputMode.html" title="OutputMode describes what data will be written to a streaming sink when there is new data available in a streaming DataFrame/Dataset.">OutputMode</a></li><li class="current-entities indented5"><span class="separator"></span> <a href="SinkProgress.html" title="Information about progress made for a sink in the execution of a StreamingQuery during a trigger." class="class"></a><a href="SinkProgress.html" title="Information about progress made for a sink in the execution of a StreamingQuery during a trigger.">SinkProgress</a></li><li class="current-entities indented5"><span class="separator"></span> <a href="SourceProgress.html" title="Information about progress made for a source in the execution of a StreamingQuery during a trigger." class="class"></a><a href="SourceProgress.html" title="Information about progress made for a source in the execution of a StreamingQuery during a trigger.">SourceProgress</a></li><li class="current-entities indented5"><span class="separator"></span> <a href="StateOperatorProgress.html" title="Information about updates made to stateful operators in a StreamingQuery during a trigger." class="class"></a><a href="StateOperatorProgress.html" title="Information about updates made to stateful operators in a StreamingQuery during a trigger.">StateOperatorProgress</a></li><li class="current-entities indented5"><span class="separator"></span> <a href="StreamingQuery.html" title="&lt;invalid inheritdoc annotation&gt;" class="trait"></a><a href="StreamingQuery.html" title="&lt;invalid inheritdoc annotation&gt;">StreamingQuery</a></li><li class="current-entities indented5"><span class="separator"></span> <a href="StreamingQueryException.html" title="Exception that stopped a StreamingQuery." class="class"></a><a href="StreamingQueryException.html" title="Exception that stopped a StreamingQuery.">StreamingQueryException</a></li><li class="current-entities indented5"><a href="StreamingQueryListener$.html" title="Companion object of StreamingQueryListener that defines the listener events." class="object"></a> <a href="StreamingQueryListener.html" title="Interface for listening to events related to StreamingQueries." class="class"></a><a href="StreamingQueryListener.html" title="Interface for listening to events related to StreamingQueries.">StreamingQueryListener</a></li><li class="current-entities indented5"><span class="separator"></span> <a href="StreamingQueryManager.html" title="A class to manage all the StreamingQuery active in a SparkSession." class="class"></a><a href="StreamingQueryManager.html" title="A class to manage all the StreamingQuery active in a SparkSession.">StreamingQueryManager</a></li><li class="current-entities indented5"><span class="separator"></span> <a href="StreamingQueryProgress.html" title="Information about progress made in the execution of a StreamingQuery during a trigger." class="class"></a><a href="StreamingQueryProgress.html" title="Information about progress made in the execution of a StreamingQuery during a trigger.">StreamingQueryProgress</a></li><li class="current-entities indented5"><span class="separator"></span> <a href="StreamingQueryStatus.html" title="Reports information about the instantaneous status of a streaming query." class="class"></a><a href="StreamingQueryStatus.html" title="Reports information about the instantaneous status of a streaming query.">StreamingQueryStatus</a></li><li class="current-entities indented5"><span class="separator"></span> <a href="TTLConfig.html" title="TTL Configuration for state variable." class="class"></a><a href="TTLConfig.html" title="TTL Configuration for state variable.">TTLConfig</a></li><li class="current-entities indented5"><a href="TestGroupState$.html" title="" class="object"></a> <a href="TestGroupState.html" title=":: Experimental ::" class="trait"></a><a href="TestGroupState.html" title=":: Experimental ::">TestGroupState</a></li><li class="current-entities indented5"><span class="separator"></span> <a href="TimeMode.html" title="Represents the time modes (used for specifying timers and ttl) possible for the Dataset operations transformWithState." class="class"></a><a href="TimeMode.html" title="Represents the time modes (used for specifying timers and ttl) possible for the Dataset operations transformWithState.">TimeMode</a></li><li class="current-entities indented5"><span class="separator"></span> <a href="Trigger.html" title="Policy used to indicate how often results should be produced by a StreamingQuery." class="class"></a><a href="Trigger.html" title="Policy used to indicate how often results should be produced by a StreamingQuery.">Trigger</a></li></ul></div></div><div id="content"><body class="class type"><div id="definition"><a href="DataStreamWriter$.html" title="See companion object"><div class="big-circle class-companion-object">c</div></a><p id="owner"><a href="../../../../index.html" name="org" id="org" class="extype">org</a>.<a href="../../../index.html" name="org.apache" id="org.apache" class="extype">apache</a>.<a href="../../index.html" name="org.apache.spark" id="org.apache.spark" class="extype">spark</a>.<a href="../index.html" name="org.apache.spark.sql" id="org.apache.spark.sql" class="extype">sql</a>.<a href="index.html" name="org.apache.spark.sql.streaming" id="org.apache.spark.sql.streaming" class="extype">streaming</a></p><h1><a href="DataStreamWriter$.html" title="See companion object">DataStreamWriter</a><span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html" title="Permalink"><i class="material-icons"></i></a></span></h1><h3><span class="morelinks"><div>Companion <a href="DataStreamWriter$.html" title="See companion object">object DataStreamWriter</a></div></span></h3></div><h4 id="signature" class="signature"><span class="modifier_kind"><span class="modifier">final </span> <span class="kind">class</span></span> <span class="symbol"><span class="name">DataStreamWriter</span><span class="tparams">[<span name="T">T</span>]</span><span class="result"> extends <span name="scala.AnyRef" class="extype">AnyRef</span></span></span></h4><div id="comment" class="fullcommenttop"><div class="comment cmt"><p>Interface used to write a streaming <code>Dataset</code> to external storage systems (e.g. file systems,
key-value stores, etc). Use <code>Dataset.writeStream</code> to access this.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Source</dt><dd><a href="https://github.com/apache/spark/tree/v4.0.0-preview2/sql/core/src/main/scala/org/apache/spark/sql/streaming/DataStreamWriter.scala" target="_blank">DataStreamWriter.scala</a></dd><dt>Since</dt><dd><p>2.0.0</p></dd></dl><div class="toggleContainer"><div class="toggle block"><span>Linear Supertypes</span><div class="superTypes hiddenContent"><span name="scala.AnyRef" class="extype">AnyRef</span>, <span name="scala.Any" class="extype">Any</span></div></div></div></div><div id="mbrsel"><div class="toggle"></div><div id="memberfilter"><i class="material-icons arrow"></i><span class="input"><input placeholder="Filter all members" id="mbrsel-input" type="text" accesskey="/"/></span><i class="clear material-icons"></i></div><div id="filterby"><div id="order"><span class="filtertype">Ordering</span><ol><li class="alpha in"><span>Alphabetic</span></li><li class="inherit out"><span>By Inheritance</span></li></ol></div><div class="ancestors"><span class="filtertype">Inherited<br/></span><ol id="linearization"><li class="in" name="org.apache.spark.sql.streaming.DataStreamWriter"><span>DataStreamWriter</span></li><li class="in" name="scala.AnyRef"><span>AnyRef</span></li><li class="in" name="scala.Any"><span>Any</span></li></ol></div><div class="ancestors"><span class="filtertype"></span><ol><li class="hideall out"><span>Hide All</span></li><li class="showall in"><span>Show All</span></li></ol></div><div id="visbl"><span class="filtertype">Visibility</span><ol><li class="public in"><span>Public</span></li><li class="protected out"><span>Protected</span></li></ol></div></div></div><div id="template"><div id="allMembers"><div class="values members"><h3>Value Members</h3><ol><li class="indented0 " name="scala.AnyRef#!=" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="!=(x$1:Any):Boolean" class="anchorToMember"></a><a id="!=(Any):Boolean" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#!=(x$1:Any):Boolean" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name" title="gt4s: $bang$eq">!=</span><span class="params">(<span name="arg0">arg0: <span name="scala.Any" class="extype">Any</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div></li><li class="indented0 " name="scala.AnyRef###" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="##:Int" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html###:Int" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name" title="gt4s: $hash$hash">##</span><span class="result">: <span name="scala.Int" class="extype">Int</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div></li><li class="indented0 " name="scala.AnyRef#==" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="==(x$1:Any):Boolean" class="anchorToMember"></a><a id="==(Any):Boolean" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#==(x$1:Any):Boolean" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name" title="gt4s: $eq$eq">==</span><span class="params">(<span name="arg0">arg0: <span name="scala.Any" class="extype">Any</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div></li><li class="indented0 " name="scala.Any#asInstanceOf" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="asInstanceOf[T0]:T0" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#asInstanceOf[T0]:T0" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">asInstanceOf</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="result">: <span name="scala.Any.asInstanceOf.T0" class="extype">T0</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>Any</dd></dl></div></li><li class="indented0 " name="scala.AnyRef#clone" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="prt"><a id="clone():Object" class="anchorToMember"></a><a id="clone():AnyRef" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#clone():Object" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">clone</span><span class="params">()</span><span class="result">: <span name="scala.AnyRef" class="extype">AnyRef</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Attributes</dt><dd>protected[<span name="java.lang" class="extype">lang</span>] </dd><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd><span class="name">@throws</span><span class="args">(<span><span class="defval">classOf[java.lang.CloneNotSupportedException]</span></span>)</span> <span class="name">@IntrinsicCandidate</span><span class="args">()</span> <span class="name">@native</span><span class="args">()</span> </dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.streaming.DataStreamWriter#clusterBy" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="clusterBy(colNames:String*):org.apache.spark.sql.streaming.DataStreamWriter[T]" class="anchorToMember"></a><a id="clusterBy(String*):DataStreamWriter[T]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#clusterBy(colNames:String*):org.apache.spark.sql.streaming.DataStreamWriter[T]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">clusterBy</span><span class="params">(<span name="colNames">colNames: <span name="scala.Predef.String" class="extype">String</span>*</span>)</span><span class="result">: <a href="" name="org.apache.spark.sql.streaming.DataStreamWriter" id="org.apache.spark.sql.streaming.DataStreamWriter" class="extype">DataStreamWriter</a>[<span name="org.apache.spark.sql.streaming.DataStreamWriter.T" class="extype">T</span>]</span></span><p class="shortcomment cmt">Clusters the output by the given columns.</p><div class="fullcomment"><div class="comment cmt"><p>Clusters the output by the given columns. If specified, the output is laid out such that
records with similar values on the clustering column are grouped together in the same file.</p><p>Clustering improves query efficiency by allowing queries with predicates on the clustering
columns to skip unnecessary data. Unlike partitioning, clustering can be used on very high
cardinality columns.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@varargs</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>4.0.0</p></dd></dl></div></li><li class="indented0 " name="scala.AnyRef#eq" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="eq(x$1:AnyRef):Boolean" class="anchorToMember"></a><a id="eq(AnyRef):Boolean" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#eq(x$1:AnyRef):Boolean" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">eq</span><span class="params">(<span name="arg0">arg0: <span name="scala.AnyRef" class="extype">AnyRef</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd></dl></div></li><li class="indented0 " name="scala.AnyRef#equals" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="equals(x$1:Object):Boolean" class="anchorToMember"></a><a id="equals(AnyRef):Boolean" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#equals(x$1:Object):Boolean" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">equals</span><span class="params">(<span name="arg0">arg0: <span name="scala.AnyRef" class="extype">AnyRef</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.streaming.DataStreamWriter#foreach" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="foreach(writer:org.apache.spark.sql.ForeachWriter[T]):org.apache.spark.sql.streaming.DataStreamWriter[T]" class="anchorToMember"></a><a id="foreach(ForeachWriter[T]):DataStreamWriter[T]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#foreach(writer:org.apache.spark.sql.ForeachWriter[T]):org.apache.spark.sql.streaming.DataStreamWriter[T]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">foreach</span><span class="params">(<span name="writer">writer: <a href="../ForeachWriter.html" name="org.apache.spark.sql.ForeachWriter" id="org.apache.spark.sql.ForeachWriter" class="extype">ForeachWriter</a>[<span name="org.apache.spark.sql.streaming.DataStreamWriter.T" class="extype">T</span>]</span>)</span><span class="result">: <a href="" name="org.apache.spark.sql.streaming.DataStreamWriter" id="org.apache.spark.sql.streaming.DataStreamWriter" class="extype">DataStreamWriter</a>[<span name="org.apache.spark.sql.streaming.DataStreamWriter.T" class="extype">T</span>]</span></span><p class="shortcomment cmt">Sets the output of the streaming query to be processed using the provided writer object.</p><div class="fullcomment"><div class="comment cmt"><p>Sets the output of the streaming query to be processed using the provided writer object.
object. See <a href="../ForeachWriter.html" name="org.apache.spark.sql.ForeachWriter" id="org.apache.spark.sql.ForeachWriter" class="extype">org.apache.spark.sql.ForeachWriter</a> for more details on the lifecycle and
semantics.</p></div><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.streaming.DataStreamWriter#foreachBatch" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="foreachBatch(function:org.apache.spark.api.java.function.VoidFunction2[org.apache.spark.sql.Dataset[T],Long]):org.apache.spark.sql.streaming.DataStreamWriter[T]" class="anchorToMember"></a><a id="foreachBatch(VoidFunction2[Dataset[T],Long]):DataStreamWriter[T]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#foreachBatch(function:org.apache.spark.api.java.function.VoidFunction2[org.apache.spark.sql.Dataset[T],Long]):org.apache.spark.sql.streaming.DataStreamWriter[T]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">foreachBatch</span><span class="params">(<span name="function">function: <a href="../../api/java/function/VoidFunction2.html" name="org.apache.spark.api.java.function.VoidFunction2" id="org.apache.spark.api.java.function.VoidFunction2" class="extype">VoidFunction2</a>[<a href="../Dataset.html" name="org.apache.spark.sql.Dataset" id="org.apache.spark.sql.Dataset" class="extype">Dataset</a>[<span name="org.apache.spark.sql.streaming.DataStreamWriter.T" class="extype">T</span>], <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Long.html#java.lang.Long" name="java.lang.Long" id="java.lang.Long" class="extype">Long</a>]</span>)</span><span class="result">: <a href="" name="org.apache.spark.sql.streaming.DataStreamWriter" id="org.apache.spark.sql.streaming.DataStreamWriter" class="extype">DataStreamWriter</a>[<span name="org.apache.spark.sql.streaming.DataStreamWriter.T" class="extype">T</span>]</span></span><p class="shortcomment cmt">:: Experimental ::</p><div class="fullcomment"><div class="comment cmt"><p>:: Experimental ::</p><p>(Java-specific) Sets the output of the streaming query to be processed using the provided
function. This is supported only in the micro-batch execution modes (that is, when the
trigger is not continuous). In every micro-batch, the provided function will be called in
every micro-batch with (i) the output rows as a Dataset and (ii) the batch identifier.
The batchId can be used to deduplicate and transactionally write the output
(that is, the provided Dataset) to external systems. The output Dataset is guaranteed
to be exactly the same for the same batchId (assuming all operations are deterministic
in the query).
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>2.4.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.streaming.DataStreamWriter#foreachBatch" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="foreachBatch(function:(org.apache.spark.sql.Dataset[T],Long)=&gt;Unit):org.apache.spark.sql.streaming.DataStreamWriter[T]" class="anchorToMember"></a><a id="foreachBatch((Dataset[T],Long)=&gt;Unit):DataStreamWriter[T]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#foreachBatch(function:(org.apache.spark.sql.Dataset[T],Long)=&gt;Unit):org.apache.spark.sql.streaming.DataStreamWriter[T]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">foreachBatch</span><span class="params">(<span name="function">function: (<a href="../Dataset.html" name="org.apache.spark.sql.Dataset" id="org.apache.spark.sql.Dataset" class="extype">Dataset</a>[<span name="org.apache.spark.sql.streaming.DataStreamWriter.T" class="extype">T</span>], <span name="scala.Long" class="extype">Long</span>) =&gt; <span name="scala.Unit" class="extype">Unit</span></span>)</span><span class="result">: <a href="" name="org.apache.spark.sql.streaming.DataStreamWriter" id="org.apache.spark.sql.streaming.DataStreamWriter" class="extype">DataStreamWriter</a>[<span name="org.apache.spark.sql.streaming.DataStreamWriter.T" class="extype">T</span>]</span></span><p class="shortcomment cmt">:: Experimental ::</p><div class="fullcomment"><div class="comment cmt"><p>:: Experimental ::</p><p>(Scala-specific) Sets the output of the streaming query to be processed using the provided
function. This is supported only in the micro-batch execution modes (that is, when the
trigger is not continuous). In every micro-batch, the provided function will be called in
every micro-batch with (i) the output rows as a Dataset and (ii) the batch identifier.
The batchId can be used to deduplicate and transactionally write the output
(that is, the provided Dataset) to external systems. The output Dataset is guaranteed
to be exactly the same for the same batchId (assuming all operations are deterministic
in the query).
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>2.4.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.streaming.DataStreamWriter#format" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="format(source:String):org.apache.spark.sql.streaming.DataStreamWriter[T]" class="anchorToMember"></a><a id="format(String):DataStreamWriter[T]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#format(source:String):org.apache.spark.sql.streaming.DataStreamWriter[T]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">format</span><span class="params">(<span name="source">source: <span name="scala.Predef.String" class="extype">String</span></span>)</span><span class="result">: <a href="" name="org.apache.spark.sql.streaming.DataStreamWriter" id="org.apache.spark.sql.streaming.DataStreamWriter" class="extype">DataStreamWriter</a>[<span name="org.apache.spark.sql.streaming.DataStreamWriter.T" class="extype">T</span>]</span></span><p class="shortcomment cmt">Specifies the underlying output data source.</p><div class="fullcomment"><div class="comment cmt"><p>Specifies the underlying output data source.
</p></div><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="scala.AnyRef#getClass" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="getClass():Class[_]" class="anchorToMember"></a><a id="getClass():Class[_&lt;:AnyRef]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#getClass():Class[_]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">getClass</span><span class="params">()</span><span class="result">: <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/Class.html#java.lang.Class" name="java.lang.Class" id="java.lang.Class" class="extype">Class</a>[_ &lt;: <span name="scala.AnyRef" class="extype">AnyRef</span>]</span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef → Any</dd><dt>Annotations</dt><dd><span class="name">@IntrinsicCandidate</span><span class="args">()</span> <span class="name">@native</span><span class="args">()</span> </dd></dl></div></li><li class="indented0 " name="scala.AnyRef#hashCode" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="hashCode():Int" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#hashCode():Int" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">hashCode</span><span class="params">()</span><span class="result">: <span name="scala.Int" class="extype">Int</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef → Any</dd><dt>Annotations</dt><dd><span class="name">@IntrinsicCandidate</span><span class="args">()</span> <span class="name">@native</span><span class="args">()</span> </dd></dl></div></li><li class="indented0 " name="scala.Any#isInstanceOf" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="isInstanceOf[T0]:Boolean" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#isInstanceOf[T0]:Boolean" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">isInstanceOf</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>Any</dd></dl></div></li><li class="indented0 " name="scala.AnyRef#ne" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="ne(x$1:AnyRef):Boolean" class="anchorToMember"></a><a id="ne(AnyRef):Boolean" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#ne(x$1:AnyRef):Boolean" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">ne</span><span class="params">(<span name="arg0">arg0: <span name="scala.AnyRef" class="extype">AnyRef</span></span>)</span><span class="result">: <span name="scala.Boolean" class="extype">Boolean</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd></dl></div></li><li class="indented0 " name="scala.AnyRef#notify" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="notify():Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#notify():Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">notify</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd><span class="name">@IntrinsicCandidate</span><span class="args">()</span> <span class="name">@native</span><span class="args">()</span> </dd></dl></div></li><li class="indented0 " name="scala.AnyRef#notifyAll" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="notifyAll():Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#notifyAll():Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">notifyAll</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd><span class="name">@IntrinsicCandidate</span><span class="args">()</span> <span class="name">@native</span><span class="args">()</span> </dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.streaming.DataStreamWriter#option" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="option(key:String,value:Double):org.apache.spark.sql.streaming.DataStreamWriter[T]" class="anchorToMember"></a><a id="option(String,Double):DataStreamWriter[T]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#option(key:String,value:Double):org.apache.spark.sql.streaming.DataStreamWriter[T]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">option</span><span class="params">(<span name="key">key: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="value">value: <span name="scala.Double" class="extype">Double</span></span>)</span><span class="result">: <a href="" name="org.apache.spark.sql.streaming.DataStreamWriter" id="org.apache.spark.sql.streaming.DataStreamWriter" class="extype">DataStreamWriter</a>[<span name="org.apache.spark.sql.streaming.DataStreamWriter.T" class="extype">T</span>]</span></span><p class="shortcomment cmt">Adds an output option for the underlying data source.</p><div class="fullcomment"><div class="comment cmt"><p>Adds an output option for the underlying data source.
</p></div><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.streaming.DataStreamWriter#option" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="option(key:String,value:Long):org.apache.spark.sql.streaming.DataStreamWriter[T]" class="anchorToMember"></a><a id="option(String,Long):DataStreamWriter[T]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#option(key:String,value:Long):org.apache.spark.sql.streaming.DataStreamWriter[T]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">option</span><span class="params">(<span name="key">key: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="value">value: <span name="scala.Long" class="extype">Long</span></span>)</span><span class="result">: <a href="" name="org.apache.spark.sql.streaming.DataStreamWriter" id="org.apache.spark.sql.streaming.DataStreamWriter" class="extype">DataStreamWriter</a>[<span name="org.apache.spark.sql.streaming.DataStreamWriter.T" class="extype">T</span>]</span></span><p class="shortcomment cmt">Adds an output option for the underlying data source.</p><div class="fullcomment"><div class="comment cmt"><p>Adds an output option for the underlying data source.
</p></div><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.streaming.DataStreamWriter#option" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="option(key:String,value:Boolean):org.apache.spark.sql.streaming.DataStreamWriter[T]" class="anchorToMember"></a><a id="option(String,Boolean):DataStreamWriter[T]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#option(key:String,value:Boolean):org.apache.spark.sql.streaming.DataStreamWriter[T]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">option</span><span class="params">(<span name="key">key: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="value">value: <span name="scala.Boolean" class="extype">Boolean</span></span>)</span><span class="result">: <a href="" name="org.apache.spark.sql.streaming.DataStreamWriter" id="org.apache.spark.sql.streaming.DataStreamWriter" class="extype">DataStreamWriter</a>[<span name="org.apache.spark.sql.streaming.DataStreamWriter.T" class="extype">T</span>]</span></span><p class="shortcomment cmt">Adds an output option for the underlying data source.</p><div class="fullcomment"><div class="comment cmt"><p>Adds an output option for the underlying data source.
</p></div><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.streaming.DataStreamWriter#option" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="option(key:String,value:String):org.apache.spark.sql.streaming.DataStreamWriter[T]" class="anchorToMember"></a><a id="option(String,String):DataStreamWriter[T]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#option(key:String,value:String):org.apache.spark.sql.streaming.DataStreamWriter[T]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">option</span><span class="params">(<span name="key">key: <span name="scala.Predef.String" class="extype">String</span></span>, <span name="value">value: <span name="scala.Predef.String" class="extype">String</span></span>)</span><span class="result">: <a href="" name="org.apache.spark.sql.streaming.DataStreamWriter" id="org.apache.spark.sql.streaming.DataStreamWriter" class="extype">DataStreamWriter</a>[<span name="org.apache.spark.sql.streaming.DataStreamWriter.T" class="extype">T</span>]</span></span><p class="shortcomment cmt">Adds an output option for the underlying data source.</p><div class="fullcomment"><div class="comment cmt"><p>Adds an output option for the underlying data source.
</p></div><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.streaming.DataStreamWriter#options" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="options(options:java.util.Map[String,String]):org.apache.spark.sql.streaming.DataStreamWriter[T]" class="anchorToMember"></a><a id="options(Map[String,String]):DataStreamWriter[T]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#options(options:java.util.Map[String,String]):org.apache.spark.sql.streaming.DataStreamWriter[T]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">options</span><span class="params">(<span name="options">options: <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/util/Map.html#java.util.Map" name="java.util.Map" id="java.util.Map" class="extype">Map</a>[<span name="scala.Predef.String" class="extype">String</span>, <span name="scala.Predef.String" class="extype">String</span>]</span>)</span><span class="result">: <a href="" name="org.apache.spark.sql.streaming.DataStreamWriter" id="org.apache.spark.sql.streaming.DataStreamWriter" class="extype">DataStreamWriter</a>[<span name="org.apache.spark.sql.streaming.DataStreamWriter.T" class="extype">T</span>]</span></span><p class="shortcomment cmt">Adds output options for the underlying data source.</p><div class="fullcomment"><div class="comment cmt"><p>Adds output options for the underlying data source.
</p></div><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.streaming.DataStreamWriter#options" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="options(options:scala.collection.Map[String,String]):org.apache.spark.sql.streaming.DataStreamWriter[T]" class="anchorToMember"></a><a id="options(Map[String,String]):DataStreamWriter[T]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#options(options:scala.collection.Map[String,String]):org.apache.spark.sql.streaming.DataStreamWriter[T]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">options</span><span class="params">(<span name="options">options: <span name="scala.collection.Map" class="extype">Map</span>[<span name="scala.Predef.String" class="extype">String</span>, <span name="scala.Predef.String" class="extype">String</span>]</span>)</span><span class="result">: <a href="" name="org.apache.spark.sql.streaming.DataStreamWriter" id="org.apache.spark.sql.streaming.DataStreamWriter" class="extype">DataStreamWriter</a>[<span name="org.apache.spark.sql.streaming.DataStreamWriter.T" class="extype">T</span>]</span></span><p class="shortcomment cmt">(Scala-specific) Adds output options for the underlying data source.</p><div class="fullcomment"><div class="comment cmt"><p>(Scala-specific) Adds output options for the underlying data source.
</p></div><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.streaming.DataStreamWriter#outputMode" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="outputMode(outputMode:String):org.apache.spark.sql.streaming.DataStreamWriter[T]" class="anchorToMember"></a><a id="outputMode(String):DataStreamWriter[T]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#outputMode(outputMode:String):org.apache.spark.sql.streaming.DataStreamWriter[T]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">outputMode</span><span class="params">(<span name="outputMode">outputMode: <span name="scala.Predef.String" class="extype">String</span></span>)</span><span class="result">: <a href="" name="org.apache.spark.sql.streaming.DataStreamWriter" id="org.apache.spark.sql.streaming.DataStreamWriter" class="extype">DataStreamWriter</a>[<span name="org.apache.spark.sql.streaming.DataStreamWriter.T" class="extype">T</span>]</span></span><p class="shortcomment cmt">Specifies how data of a streaming DataFrame/Dataset is written to a streaming sink.</p><div class="fullcomment"><div class="comment cmt"><p>Specifies how data of a streaming DataFrame/Dataset is written to a streaming sink.</p><ul><li> <code>append</code>: only the new rows in the streaming DataFrame/Dataset will be written to
the sink.</li><li> <code>complete</code>: all the rows in the streaming DataFrame/Dataset will be written to the sink
every time there are some updates.</li><li> <code>update</code>: only the rows that were updated in the streaming DataFrame/Dataset will
be written to the sink every time there are some updates. If the query doesn't
contain aggregations, it will be equivalent to <code>append</code> mode.</li></ul></div><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.streaming.DataStreamWriter#outputMode" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="outputMode(outputMode:org.apache.spark.sql.streaming.OutputMode):org.apache.spark.sql.streaming.DataStreamWriter[T]" class="anchorToMember"></a><a id="outputMode(OutputMode):DataStreamWriter[T]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#outputMode(outputMode:org.apache.spark.sql.streaming.OutputMode):org.apache.spark.sql.streaming.DataStreamWriter[T]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">outputMode</span><span class="params">(<span name="outputMode">outputMode: <a href="OutputMode.html" name="org.apache.spark.sql.streaming.OutputMode" id="org.apache.spark.sql.streaming.OutputMode" class="extype">OutputMode</a></span>)</span><span class="result">: <a href="" name="org.apache.spark.sql.streaming.DataStreamWriter" id="org.apache.spark.sql.streaming.DataStreamWriter" class="extype">DataStreamWriter</a>[<span name="org.apache.spark.sql.streaming.DataStreamWriter.T" class="extype">T</span>]</span></span><p class="shortcomment cmt">Specifies how data of a streaming DataFrame/Dataset is written to a streaming sink.</p><div class="fullcomment"><div class="comment cmt"><p>Specifies how data of a streaming DataFrame/Dataset is written to a streaming sink.</p><ul><li> <code>OutputMode.Append()</code>: only the new rows in the streaming DataFrame/Dataset will be
written to the sink.</li><li> <code>OutputMode.Complete()</code>: all the rows in the streaming DataFrame/Dataset will be written
to the sink every time there are some updates.</li><li> <code>OutputMode.Update()</code>: only the rows that were updated in the streaming
DataFrame/Dataset will be written to the sink every time there are some updates.
If the query doesn't contain aggregations, it will be equivalent to
<code>OutputMode.Append()</code> mode.</li></ul></div><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.streaming.DataStreamWriter#partitionBy" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="partitionBy(colNames:String*):org.apache.spark.sql.streaming.DataStreamWriter[T]" class="anchorToMember"></a><a id="partitionBy(String*):DataStreamWriter[T]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#partitionBy(colNames:String*):org.apache.spark.sql.streaming.DataStreamWriter[T]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">partitionBy</span><span class="params">(<span name="colNames">colNames: <span name="scala.Predef.String" class="extype">String</span>*</span>)</span><span class="result">: <a href="" name="org.apache.spark.sql.streaming.DataStreamWriter" id="org.apache.spark.sql.streaming.DataStreamWriter" class="extype">DataStreamWriter</a>[<span name="org.apache.spark.sql.streaming.DataStreamWriter.T" class="extype">T</span>]</span></span><p class="shortcomment cmt">Partitions the output by the given columns on the file system.</p><div class="fullcomment"><div class="comment cmt"><p>Partitions the output by the given columns on the file system. If specified, the output is
laid out on the file system similar to Hive's partitioning scheme. As an example, when we
partition a dataset by year and then month, the directory layout would look like:</p><ul><li> year=2016/month=01/</li><li> year=2016/month=02/</li></ul><p>Partitioning is one of the most widely used techniques to optimize physical data layout.
It provides a coarse-grained index for skipping unnecessary data reads when queries have
predicates on the partitioned columns. In order for partitioning to work well, the number
of distinct values in each column should typically be less than tens of thousands.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@varargs</span><span class="args">()</span> </dd><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.streaming.DataStreamWriter#queryName" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="queryName(queryName:String):org.apache.spark.sql.streaming.DataStreamWriter[T]" class="anchorToMember"></a><a id="queryName(String):DataStreamWriter[T]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#queryName(queryName:String):org.apache.spark.sql.streaming.DataStreamWriter[T]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">queryName</span><span class="params">(<span name="queryName">queryName: <span name="scala.Predef.String" class="extype">String</span></span>)</span><span class="result">: <a href="" name="org.apache.spark.sql.streaming.DataStreamWriter" id="org.apache.spark.sql.streaming.DataStreamWriter" class="extype">DataStreamWriter</a>[<span name="org.apache.spark.sql.streaming.DataStreamWriter.T" class="extype">T</span>]</span></span><p class="shortcomment cmt">Specifies the name of the <a href="StreamingQuery.html" name="org.apache.spark.sql.streaming.StreamingQuery" id="org.apache.spark.sql.streaming.StreamingQuery" class="extype">StreamingQuery</a> that can be started with <code>start()</code>.</p><div class="fullcomment"><div class="comment cmt"><p>Specifies the name of the <a href="StreamingQuery.html" name="org.apache.spark.sql.streaming.StreamingQuery" id="org.apache.spark.sql.streaming.StreamingQuery" class="extype">StreamingQuery</a> that can be started with <code>start()</code>.
This name must be unique among all the currently active queries in the associated SQLContext.
</p></div><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.streaming.DataStreamWriter#start" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="start():org.apache.spark.sql.streaming.StreamingQuery" class="anchorToMember"></a><a id="start():StreamingQuery" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#start():org.apache.spark.sql.streaming.StreamingQuery" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">start</span><span class="params">()</span><span class="result">: <a href="StreamingQuery.html" name="org.apache.spark.sql.streaming.StreamingQuery" id="org.apache.spark.sql.streaming.StreamingQuery" class="extype">StreamingQuery</a></span></span><p class="shortcomment cmt">Starts the execution of the streaming query, which will continually output results to the given
path as new data arrives.</p><div class="fullcomment"><div class="comment cmt"><p>Starts the execution of the streaming query, which will continually output results to the given
path as new data arrives. The returned <a href="StreamingQuery.html" name="org.apache.spark.sql.streaming.StreamingQuery" id="org.apache.spark.sql.streaming.StreamingQuery" class="extype">StreamingQuery</a> object can be used to interact with
the stream. Throws a <code>TimeoutException</code> if the following conditions are met:</p><ul><li>Another run of the same streaming query, that is a streaming query
   sharing the same checkpoint location, is already active on the same
   Spark Driver</li><li>The SQL configuration <code>spark.sql.streaming.stopActiveRunOnRestart</code>
   is enabled</li><li>The active run cannot be stopped within the timeout controlled by
   the SQL configuration <code>spark.sql.streaming.stopTimeout</code>
</li></ul></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@throws</span><span class="args">(<span><span class="defval">scala.this.throws.&lt;init&gt;$default$1[java.util.concurrent.TimeoutException]</span></span>)</span> </dd><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.streaming.DataStreamWriter#start" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="start(path:String):org.apache.spark.sql.streaming.StreamingQuery" class="anchorToMember"></a><a id="start(String):StreamingQuery" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#start(path:String):org.apache.spark.sql.streaming.StreamingQuery" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">start</span><span class="params">(<span name="path">path: <span name="scala.Predef.String" class="extype">String</span></span>)</span><span class="result">: <a href="StreamingQuery.html" name="org.apache.spark.sql.streaming.StreamingQuery" id="org.apache.spark.sql.streaming.StreamingQuery" class="extype">StreamingQuery</a></span></span><p class="shortcomment cmt">Starts the execution of the streaming query, which will continually output results to the given
path as new data arrives.</p><div class="fullcomment"><div class="comment cmt"><p>Starts the execution of the streaming query, which will continually output results to the given
path as new data arrives. The returned <a href="StreamingQuery.html" name="org.apache.spark.sql.streaming.StreamingQuery" id="org.apache.spark.sql.streaming.StreamingQuery" class="extype">StreamingQuery</a> object can be used to interact with
the stream.
</p></div><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="scala.AnyRef#synchronized" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="synchronized[T0](x$1:=&gt;T0):T0" class="anchorToMember"></a><a id="synchronized[T0](=&gt;T0):T0" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#synchronized[T0](x$1:=&gt;T0):T0" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">synchronized</span><span class="tparams">[<span name="T0">T0</span>]</span><span class="params">(<span name="arg0">arg0: =&gt; <span name="java.lang.AnyRef.synchronized.T0" class="extype">T0</span></span>)</span><span class="result">: <span name="java.lang.AnyRef.synchronized.T0" class="extype">T0</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd></dl></div></li><li class="indented0 " name="scala.AnyRef#toString" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="toString():String" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#toString():String" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">toString</span><span class="params">()</span><span class="result">: <a href="https://docs.oracle.com/en/java/javase/17/docs/api/java.base/java/lang/String.html#java.lang.String" name="java.lang.String" id="java.lang.String" class="extype">String</a></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef → Any</dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.streaming.DataStreamWriter#toTable" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="toTable(tableName:String):org.apache.spark.sql.streaming.StreamingQuery" class="anchorToMember"></a><a id="toTable(String):StreamingQuery" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#toTable(tableName:String):org.apache.spark.sql.streaming.StreamingQuery" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">toTable</span><span class="params">(<span name="tableName">tableName: <span name="scala.Predef.String" class="extype">String</span></span>)</span><span class="result">: <a href="StreamingQuery.html" name="org.apache.spark.sql.streaming.StreamingQuery" id="org.apache.spark.sql.streaming.StreamingQuery" class="extype">StreamingQuery</a></span></span><p class="shortcomment cmt">Starts the execution of the streaming query, which will continually output results to the given
table as new data arrives.</p><div class="fullcomment"><div class="comment cmt"><p>Starts the execution of the streaming query, which will continually output results to the given
table as new data arrives. The returned <a href="StreamingQuery.html" name="org.apache.spark.sql.streaming.StreamingQuery" id="org.apache.spark.sql.streaming.StreamingQuery" class="extype">StreamingQuery</a> object can be used to interact with
the stream.</p><p>For v1 table, partitioning columns provided by <code>partitionBy</code> will be respected no matter the
table exists or not. A new table will be created if the table not exists.</p><p>For v2 table, <code>partitionBy</code> will be ignored if the table already exists. <code>partitionBy</code> will be
respected only if the v2 table does not exist. Besides, the v2 table created by this API lacks
some functionalities (e.g., customized properties, options, and serde info). If you need them,
please create the v2 table manually before the execution to avoid creating a table with
incomplete information.
</p></div><dl class="attributes block"><dt>Annotations</dt><dd><span class="name">@Evolving</span><span class="args">()</span> <span class="name">@throws</span><span class="args">(<span><span class="defval">scala.this.throws.&lt;init&gt;$default$1[java.util.concurrent.TimeoutException]</span></span>)</span> </dd><dt>Since</dt><dd><p>3.1.0</p></dd></dl></div></li><li class="indented0 " name="org.apache.spark.sql.streaming.DataStreamWriter#trigger" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="trigger(trigger:org.apache.spark.sql.streaming.Trigger):org.apache.spark.sql.streaming.DataStreamWriter[T]" class="anchorToMember"></a><a id="trigger(Trigger):DataStreamWriter[T]" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#trigger(trigger:org.apache.spark.sql.streaming.Trigger):org.apache.spark.sql.streaming.DataStreamWriter[T]" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name">trigger</span><span class="params">(<span name="trigger">trigger: <a href="Trigger.html" name="org.apache.spark.sql.streaming.Trigger" id="org.apache.spark.sql.streaming.Trigger" class="extype">Trigger</a></span>)</span><span class="result">: <a href="" name="org.apache.spark.sql.streaming.DataStreamWriter" id="org.apache.spark.sql.streaming.DataStreamWriter" class="extype">DataStreamWriter</a>[<span name="org.apache.spark.sql.streaming.DataStreamWriter.T" class="extype">T</span>]</span></span><p class="shortcomment cmt">Set the trigger for the stream query.</p><div class="fullcomment"><div class="comment cmt"><p>Set the trigger for the stream query. The default value is <code>ProcessingTime(0)</code> and it will run
the query as fast as possible.</p><p>Scala Example:</p><pre>df.writeStream.trigger(ProcessingTime(<span class="lit">"10 seconds"</span>))

<span class="kw">import</span> scala.concurrent.duration._
df.writeStream.trigger(ProcessingTime(<span class="num">10.</span>seconds))</pre><p>Java Example:</p><pre>df.writeStream().trigger(ProcessingTime.create(<span class="lit">"10 seconds"</span>))

<span class="kw">import</span> java.util.concurrent.TimeUnit
df.writeStream().trigger(ProcessingTime.create(<span class="num">10</span>, TimeUnit.SECONDS))</pre></div><dl class="attributes block"><dt>Since</dt><dd><p>2.0.0</p></dd></dl></div></li><li class="indented0 " name="scala.AnyRef#wait" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="wait(x$1:Long,x$2:Int):Unit" class="anchorToMember"></a><a id="wait(Long,Int):Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#wait(x$1:Long,x$2:Int):Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">wait</span><span class="params">(<span name="arg0">arg0: <span name="scala.Long" class="extype">Long</span></span>, <span name="arg1">arg1: <span name="scala.Int" class="extype">Int</span></span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd><span class="name">@throws</span><span class="args">(<span><span class="defval">classOf[java.lang.InterruptedException]</span></span>)</span> </dd></dl></div></li><li class="indented0 " name="scala.AnyRef#wait" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="wait(x$1:Long):Unit" class="anchorToMember"></a><a id="wait(Long):Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#wait(x$1:Long):Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">wait</span><span class="params">(<span name="arg0">arg0: <span name="scala.Long" class="extype">Long</span></span>)</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd><span class="name">@throws</span><span class="args">(<span><span class="defval">classOf[java.lang.InterruptedException]</span></span>)</span> <span class="name">@native</span><span class="args">()</span> </dd></dl></div></li><li class="indented0 " name="scala.AnyRef#wait" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="pub"><a id="wait():Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#wait():Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier">final </span> <span class="kind">def</span></span> <span class="symbol"><span class="name">wait</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd><span class="name">@throws</span><span class="args">(<span><span class="defval">classOf[java.lang.InterruptedException]</span></span>)</span> </dd></dl></div></li></ol></div><div class="values members"><h3>Deprecated Value Members</h3><ol><li class="indented0 " name="scala.AnyRef#finalize" group="Ungrouped" fullComment="yes" data-isabs="false" visbl="prt"><a id="finalize():Unit" class="anchorToMember"></a> <span class="permalink"><a href="../../../../../org/apache/spark/sql/streaming/DataStreamWriter.html#finalize():Unit" title="Permalink"><i class="material-icons"></i></a></span> <span class="modifier_kind"><span class="modifier"></span> <span class="kind">def</span></span> <span class="symbol"><span class="name deprecated" title="Deprecated: (Since version 9)">finalize</span><span class="params">()</span><span class="result">: <span name="scala.Unit" class="extype">Unit</span></span></span><div class="fullcomment"><dl class="attributes block"><dt>Attributes</dt><dd>protected[<span name="java.lang" class="extype">lang</span>] </dd><dt>Definition Classes</dt><dd>AnyRef</dd><dt>Annotations</dt><dd><span class="name">@throws</span><span class="args">(<span><span class="symbol">classOf[java.lang.Throwable]</span></span>)</span> <span class="name">@Deprecated</span> </dd><dt>Deprecated</dt><dd class="cmt"><p><i>(Since version 9)</i></p></dd></dl></div></li></ol></div></div><div id="inheritedMembers"><div name="scala.AnyRef" class="parent"><h3>Inherited from <span name="scala.AnyRef" class="extype">AnyRef</span></h3></div><div name="scala.Any" class="parent"><h3>Inherited from <span name="scala.Any" class="extype">Any</span></h3></div></div><div id="groupedMembers"><div name="Ungrouped" class="group"><h3>Ungrouped</h3></div></div></div><div id="tooltip"></div><div id="footer"></div></body></div></div></div></body></html>
