



<!DOCTYPE html>
<html class="no-js">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">

        <title>State Data Source Integration Guide - Spark 4.0.0-preview2 Documentation</title>
        

        


        <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/css/bootstrap.min.css" rel="stylesheet"
        integrity="sha384-EVSTQN3/azprG1Anm3QDgpJLIm9Nao0Yz1ztcQTwFspd3yD65VohhpuuCOmLASjC" crossorigin="anonymous">
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=DM+Sans:ital,wght@0,400;0,500;0,700;1,400;1,500;1,700&Courier+Prime:wght@400;700&display=swap" rel="stylesheet">
        <link href="../css/custom.css" rel="stylesheet">
        <script src="/js/vendor/modernizr-2.6.1-respond-1.1.0.min.js"></script>

        <link rel="stylesheet" href="../css/pygments-default.css">
        <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css" />
        <link rel="stylesheet" href="../css/docsearch.css">

        
        <!-- Matomo -->
        <script>
            var _paq = window._paq = window._paq || [];
            /* tracker methods like "setCustomDimension" should be called before "trackPageView" */
            _paq.push(["disableCookies"]);
            _paq.push(['trackPageView']);
            _paq.push(['enableLinkTracking']);
            (function() {
              var u="https://analytics.apache.org/";
              _paq.push(['setTrackerUrl', u+'matomo.php']);
              _paq.push(['setSiteId', '40']);
              var d=document, g=d.createElement('script'), s=d.getElementsByTagName('script')[0];
              g.async=true; g.src=u+'matomo.js'; s.parentNode.insertBefore(g,s);
            })();
        </script>
        <!-- End Matomo Code -->
        

    </head>
    <body class="global">
        <!-- This code is taken from http://twitter.github.com/bootstrap/examples/hero.html -->
        <nav class="navbar navbar-expand-lg navbar-dark p-0 px-4 fixed-top" style="background: #1d6890;" id="topbar">
            <div class="navbar-brand"><a href="../index.html">
                <img src="https://spark.apache.org/images/spark-logo-rev.svg" width="141" height="72"/></a><span class="version">4.0.0-preview2</span>
            </div>
            <button class="navbar-toggler" type="button" data-toggle="collapse"
                    data-target="#navbarCollapse" aria-controls="navbarCollapse"
                    aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarCollapse">
                <ul class="navbar-nav me-auto">
                    <li class="nav-item"><a href="../index.html" class="nav-link">Overview</a></li>

                    <li class="nav-item dropdown">
                        <a href="#" class="nav-link dropdown-toggle" id="navbarQuickStart" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Programming Guides</a>
                        <div class="dropdown-menu" aria-labelledby="navbarQuickStart">
                            <a class="dropdown-item" href="../quick-start.html">Quick Start</a>
                            <a class="dropdown-item" href="../rdd-programming-guide.html">RDDs, Accumulators, Broadcasts Vars</a>
                            <a class="dropdown-item" href="../sql-programming-guide.html">SQL, DataFrames, and Datasets</a>
                            <a class="dropdown-item" href="../streaming/index.html">Structured Streaming</a>
                            <a class="dropdown-item" href="../streaming-programming-guide.html">Spark Streaming (DStreams)</a>
                            <a class="dropdown-item" href="../ml-guide.html">MLlib (Machine Learning)</a>
                            <a class="dropdown-item" href="../graphx-programming-guide.html">GraphX (Graph Processing)</a>
                            <a class="dropdown-item" href="../sparkr.html">SparkR (R on Spark)</a>
                            <a class="dropdown-item" href="../api/python/getting_started/index.html">PySpark (Python on Spark)</a>
                        </div>
                    </li>

                    <li class="nav-item dropdown">
                        <a href="#" class="nav-link dropdown-toggle" id="navbarAPIDocs" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">API Docs</a>
                        <div class="dropdown-menu" aria-labelledby="navbarAPIDocs">
                            <a class="dropdown-item" href="../api/python/index.html">Python</a>
                            <a class="dropdown-item" href="../api/scala/org/apache/spark/index.html">Scala</a>
                            <a class="dropdown-item" href="../api/java/index.html">Java</a>
                            <a class="dropdown-item" href="../api/R/index.html">R</a>
                            <a class="dropdown-item" href="../api/sql/index.html">SQL, Built-in Functions</a>
                        </div>
                    </li>

                    <li class="nav-item dropdown">
                        <a href="#" class="nav-link dropdown-toggle" id="navbarDeploying" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Deploying</a>
                        <div class="dropdown-menu" aria-labelledby="navbarDeploying">
                            <a class="dropdown-item" href="../cluster-overview.html">Overview</a>
                            <a class="dropdown-item" href="../submitting-applications.html">Submitting Applications</a>
                            <div class="dropdown-divider"></div>
                            <a class="dropdown-item" href="../spark-standalone.html">Spark Standalone</a>
                            <a class="dropdown-item" href="../running-on-yarn.html">YARN</a>
                            <a class="dropdown-item" href="../running-on-kubernetes.html">Kubernetes</a>
                        </div>
                    </li>

                    <li class="nav-item dropdown">
                        <a href="#" class="nav-link dropdown-toggle" id="navbarMore" role="button" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">More</a>
                        <div class="dropdown-menu" aria-labelledby="navbarMore">
                            <a class="dropdown-item" href="../configuration.html">Configuration</a>
                            <a class="dropdown-item" href="../monitoring.html">Monitoring</a>
                            <a class="dropdown-item" href="../tuning.html">Tuning Guide</a>
                            <a class="dropdown-item" href="../job-scheduling.html">Job Scheduling</a>
                            <a class="dropdown-item" href="../security.html">Security</a>
                            <a class="dropdown-item" href="../hardware-provisioning.html">Hardware Provisioning</a>
                            <a class="dropdown-item" href="../migration-guide.html">Migration Guide</a>
                            <div class="dropdown-divider"></div>
                            <a class="dropdown-item" href="../building-spark.html">Building Spark</a>
                            <a class="dropdown-item" href="https://spark.apache.org/contributing.html">Contributing to Spark</a>
                            <a class="dropdown-item" href="https://spark.apache.org/third-party-projects.html">Third Party Projects</a>
                        </div>
                    </li>

                    <li class="nav-item">
                        <input type="text" id="docsearch-input" placeholder="Search the docsâ€¦">
                    </li>
                </ul>
                <!--<span class="navbar-text navbar-right"><span class="version-text">v4.0.0-preview2</span></span>-->
            </div>
        </nav>

        

        <div class="container">
            
                
                    
<div class="left-menu-wrapper">
    <div class="left-menu">
        <h3><a href="../streaming/index.html">Structured Streaming Programming Guide</a></h3>
        
<ul>

    <li>
        <a href="../streaming/index.html">
            
                Overview
            
        </a>
    </li>
    
    

    <li>
        <a href="../streaming/getting-started.html">
            
                Getting Started
            
        </a>
    </li>
    
    

    <li>
        <a href="../streaming/apis-on-dataframes-and-datasets.html">
            
                APIs on DataFrames and Datasets
            
        </a>
    </li>
    
    

    <li>
        <a href="../streaming/performance-tips.html">
            
                Performance Tips
            
        </a>
    </li>
    
    

    <li>
        <a href="../streaming/additional-information.html">
            
                Additional Information
            
        </a>
    </li>
    
    

</ul>

    </div>
</div>

                
                <input id="nav-trigger" class="nav-trigger" checked type="checkbox">
                <label for="nav-trigger"></label>
                <div class="content-with-sidebar mr-3" id="content">
                    
                        <h1 class="title">State Data Source Integration Guide</h1>
                    

                    <p>State data source Guide in Structured Streaming (Experimental)</p>

<h2 id="overview">Overview</h2>

<p>State data source provides functionality to manipulate the state from the checkpoint.</p>

<p>As of Spark 4.0, state data source provides the read functionality with a batch query. Additional functionalities including write is on the future roadmap.</p>

<p>NOTE: this data source is currently marked as experimental - source options and the behavior (output) might be subject to change.</p>

<h2 id="reading-state-key-values-from-the-checkpoint">Reading state key-values from the checkpoint</h2>

<p>State data source enables reading key-value pairs from the state store in the checkpoint, via running a separate batch query.
Users can leverage the functionality to cover two major use cases described below:</p>

<ul>
  <li>Construct a test checking both output and the state. It is non-trivial to deduce the key-value of the state from the output, and having visibility of the state would be a huge win on testing.</li>
  <li>Investigate an incident against stateful streaming query. If users observe the incorrect output and want to track how it came up, having visibility of the state would be required.</li>
</ul>

<p>Users can read an instance of state store, which is matched to a single stateful operator in most cases. This means, users can expect that they can read the entire key-value pairs in the state for a single stateful operator.</p>

<p>Note that there could be an exception, e.g. stream-stream join, which leverages multiple state store instances internally. The data source abstracts the internal representation away from users and
provides a user-friendly approach to read the state. See the section for stream-stream join for more details.</p>

<h3 id="creating-a-state-store-for-batch-queries-all-defaults">Creating a state store for batch queries (all defaults)</h3>

<div class="codetabs">

<div data-lang="python">

    <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span> \
<span class="p">.</span><span class="n">read</span> \
<span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="s">"statestore"</span><span class="p">)</span> \
<span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">"&lt;checkpointLocation&gt;"</span><span class="p">)</span></code></pre></figure>

  </div>

<div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">df</span> <span class="k">=</span> <span class="nv">spark</span>
<span class="o">.</span><span class="py">read</span>
<span class="o">.</span><span class="py">format</span><span class="o">(</span><span class="s">"statestore"</span><span class="o">)</span>
<span class="o">.</span><span class="py">load</span><span class="o">(</span><span class="s">"&lt;checkpointLocation&gt;"</span><span class="o">)</span></code></pre></figure>

  </div>

<div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">Dataset</span><span class="o">&lt;</span><span class="nc">Row</span><span class="o">&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span>
<span class="o">.</span><span class="na">read</span><span class="o">()</span>
<span class="o">.</span><span class="na">format</span><span class="o">(</span><span class="s">"statestore"</span><span class="o">)</span>
<span class="o">.</span><span class="na">load</span><span class="o">(</span><span class="s">"&lt;checkpointLocation&gt;"</span><span class="o">);</span></code></pre></figure>

  </div>

</div>

<p>Each row in the source has the following schema:</p>

<table>
<thead><tr><th>Column</th><th>Type</th><th>Note</th></tr></thead>
<tr>
  <td>key</td>
  <td>struct (depends on the type for state key)</td>
  <td></td>
</tr>
<tr>
  <td>value</td>
  <td>struct (depends on the type for state value)</td>
  <td></td>
</tr>
<tr>
  <td>partition_id</td>
  <td>int</td>
  <td></td>
</tr>
</table>

<p>The nested columns for key and value heavily depend on the input schema of the stateful operator as well as the type of operator.
Users are encouraged to query about the schema via df.schema() / df.printSchema() first to understand the type of output.</p>

<p>The following options must be set for the source.</p>

<table>
<thead><tr><th>Option</th><th>Value</th><th>Meaning</th></tr></thead>
<tr>
  <td>path</td>
  <td>string</td>
  <td>Specify the root directory of the checkpoint location. You can either specify the path via option("path", `path`) or load(`path`).</td>
</tr>
</table>

<p>The following configurations are optional:</p>

<table>
<thead><tr><th>Option</th><th>Value</th><th>Default</th><th>Meaning</th></tr></thead>
<tr>
  <td>batchId</td>
  <td>numeric value</td>
  <td>latest committed batch</td>
  <td>Represents the target batch to read from. This option is used when users want to perform time-travel. The batch should be committed but not yet cleaned up.</td>
</tr>
<tr>
  <td>operatorId</td>
  <td>numeric value</td>
  <td>0</td>
  <td>Represents the target operator to read from. This option is used when the query is using multiple stateful operators.</td>
</tr>
<tr>
  <td>storeName</td>
  <td>string</td>
  <td>DEFAULT</td>
  <td>Represents the target state store name to read from. This option is used when the stateful operator uses multiple state store instances. It is not required except stream-stream join.</td>
</tr>
<tr>
  <td>joinSide</td>
  <td>string ("left" or "right")</td>
  <td>(none)</td>
  <td>Represents the target side to read from. This option is used when users want to read the state from stream-stream join.</td>
</tr>
<tr>
  <td>snapshotStartBatchId</td>
  <td>numeric value</td>
  <td></td>
  <td>If specified, force to read the snapshot at this batch ID, then changelogs will be replayed until 'batchId' or its default. Note that snapshot batch ID starts with 0 and equals to snapshot version ID minus 1. This option must be used together with 'snapshotPartitionId'.</td>
</tr>
<tr>
  <td>snapshotPartitionId</td>
  <td>numeric value</td>
  <td></td>
  <td>If specified, only this specific partition will be read. Note that partition ID starts with 0. This option must be used together with 'snapshotStartBatchId'.</td>
</tr>
<tr>
  <td>readChangeFeed</td>
  <td>boolean</td>
  <td>false</td>
  <td>If set to true, will read the change of state over microbatches. The output table schema will also differ. Details can be found in section <a href="#reading-state-changes-over-microbatches">"Reading state changes over microbatches"</a>. Option 'changeStartBatchId' must be specified with this option. Option 'batchId', 'joinSide', 'snapshotStartBatchId' and 'snapshotPartitionId' cannot be used together with this option.</td>
</tr>
<tr>
  <td>changeStartBatchId</td>
  <td>numeric value</td>
  <td></td>
  <td>Represents the first batch to read in the read change feed mode. This option requires 'readChangeFeed' to be set to true.</td>
</tr>
<tr>
  <td>changeEndBatchId</td>
  <td>numeric value</td>
  <td>latest commited batchId</td>
  <td>Represents the last batch to read in the read change feed mode. This option requires 'readChangeFeed' to be set to true.</td>
</tr>
</table>

<h3 id="reading-state-for-stream-stream-join">Reading state for stream-stream join</h3>

<p>Structured Streaming implements the stream-stream join feature via leveraging multiple instances of state store internally.
These instances logically compose buffers to store the input rows for left and right.</p>

<p>Since it is more obvious to users to reason about, the data source provides the option &#8216;joinSide&#8217; to read the buffered input for specific side of the join.
To enable the functionality to read the internal state store instance directly, we also allow specifying the option &#8216;storeName&#8217;, with restriction that &#8216;storeName&#8217; and &#8216;joinSide&#8217; cannot be specified together.</p>

<h3 id="reading-state-changes-over-microbatches">Reading state changes over microbatches</h3>

<p>If we want to understand the change of state store over microbatches instead of the whole state store at a particular microbatch, &#8216;readChangeFeed&#8217; is the option to use.
For example, this is the code to read the change of state from batch 2 to the latest committed batch.</p>

<div class="codetabs">

<div data-lang="python">

    <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span> \
<span class="p">.</span><span class="n">read</span> \
<span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="s">"statestore"</span><span class="p">)</span> \
<span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">"readChangeFeed"</span><span class="p">,</span> <span class="n">true</span><span class="p">)</span> \
<span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">"changeStartBatchId"</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span> \
<span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">"&lt;checkpointLocation&gt;"</span><span class="p">)</span></code></pre></figure>

  </div>

<div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">df</span> <span class="k">=</span> <span class="nv">spark</span>
<span class="o">.</span><span class="py">read</span>
<span class="o">.</span><span class="py">format</span><span class="o">(</span><span class="s">"statestore"</span><span class="o">)</span>
<span class="o">.</span><span class="py">option</span><span class="o">(</span><span class="s">"readChangeFeed"</span><span class="o">,</span> <span class="kc">true</span><span class="o">)</span>
<span class="o">.</span><span class="py">option</span><span class="o">(</span><span class="s">"changeStartBatchId"</span><span class="o">,</span> <span class="mi">2</span><span class="o">)</span>
<span class="o">.</span><span class="py">load</span><span class="o">(</span><span class="s">"&lt;checkpointLocation&gt;"</span><span class="o">)</span></code></pre></figure>

  </div>

<div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">Dataset</span><span class="o">&lt;</span><span class="nc">Row</span><span class="o">&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span>
<span class="o">.</span><span class="na">read</span><span class="o">()</span>
<span class="o">.</span><span class="na">format</span><span class="o">(</span><span class="s">"statestore"</span><span class="o">)</span>
<span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="s">"readChangeFeed"</span><span class="o">,</span> <span class="kc">true</span><span class="o">)</span>
<span class="o">.</span><span class="na">option</span><span class="o">(</span><span class="s">"changeStartBatchId"</span><span class="o">,</span> <span class="mi">2</span><span class="o">)</span>
<span class="o">.</span><span class="na">load</span><span class="o">(</span><span class="s">"&lt;checkpointLocation&gt;"</span><span class="o">);</span></code></pre></figure>

  </div>

</div>

<p>The output schema will also be different from the normal output.</p>

<table>
<thead><tr><th>Column</th><th>Type</th><th>Note</th></tr></thead>
<tr>
  <td>batch_id</td>
  <td>long</td>
  <td></td>
</tr>
<tr>
  <td>change_type</td>
  <td>string</td>
  <td>There are two possible values: 'update' and 'delete'. Update represents either inserting a non-existing key-value pair or updating an existing key with new value. The 'value' field will be null for delete records.</td>
</tr>
<tr>
  <td>key</td>
  <td>struct (depends on the type for state key)</td>
  <td></td>
</tr>
<tr>
  <td>value</td>
  <td>struct (depends on the type for state value)</td>
  <td></td>
</tr>
<tr>
  <td>partition_id</td>
  <td>int</td>
  <td></td>
</tr>
</table>

<h2 id="state-metadata-source">State Metadata Source</h2>

<p>Before querying the state from existing checkpoint via state data source, users would like to understand the information for the checkpoint, especially about state operator. This includes which operators and state store instances are available in the checkpoint, available range of batch IDs, etc.</p>

<p>Structured Streaming provides a data source named &#8220;State metadata source&#8221; to provide the state-related metadata information from the checkpoint.</p>

<p>Note: The metadata is constructed when the streaming query is running with Spark 4.0+. The existing checkpoint which has been running with lower Spark version does not have the metadata and will be unable to query/use with this metadata source. It is required to run the streaming query pointing the existing checkpoint in Spark 4.0+ to construct the metadata before querying.
Users can optionally provide the batchId to get the operator metadata at a point in time.</p>

<h3 id="creating-a-state-metadata-store-for-batch-queries">Creating a State metadata store for Batch Queries</h3>

<div class="codetabs">

<div data-lang="python">

    <figure class="highlight"><pre><code class="language-python" data-lang="python"><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span> \
<span class="p">.</span><span class="n">read</span> \
<span class="p">.</span><span class="nb">format</span><span class="p">(</span><span class="s">"state-metadata"</span><span class="p">)</span> \
<span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">"&lt;checkpointLocation&gt;"</span><span class="p">)</span></code></pre></figure>

  </div>

<div data-lang="scala">

    <figure class="highlight"><pre><code class="language-scala" data-lang="scala"><span class="k">val</span> <span class="nv">df</span> <span class="k">=</span> <span class="nv">spark</span>
<span class="o">.</span><span class="py">read</span>
<span class="o">.</span><span class="py">format</span><span class="o">(</span><span class="s">"state-metadata"</span><span class="o">)</span>
<span class="o">.</span><span class="py">load</span><span class="o">(</span><span class="s">"&lt;checkpointLocation&gt;"</span><span class="o">)</span></code></pre></figure>

  </div>

<div data-lang="java">

    <figure class="highlight"><pre><code class="language-java" data-lang="java"><span class="nc">Dataset</span><span class="o">&lt;</span><span class="nc">Row</span><span class="o">&gt;</span> <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span>
<span class="o">.</span><span class="na">read</span><span class="o">()</span>
<span class="o">.</span><span class="na">format</span><span class="o">(</span><span class="s">"state-metadata"</span><span class="o">)</span>
<span class="o">.</span><span class="na">load</span><span class="o">(</span><span class="s">"&lt;checkpointLocation&gt;"</span><span class="o">);</span></code></pre></figure>

  </div>

</div>

<p>The following options must be set for the source:</p>

<table>
<thead><tr><th>Option</th><th>Value</th><th>Meaning</th></tr></thead>
<tr>
  <td>path</td>
  <td>string</td>
  <td>Specify the root directory of the checkpoint location. You can either specify the path via option("path", `path`) or load(`path`).</td>
</tr>
</table>

<p>The following configurations are optional:</p>

<table>
<thead><tr><th>Option</th><th>Value</th><th>Default</th><th>Meaning</th></tr></thead>
<tr>
  <td>batchId</td>
  <td>numeric value</td>
  <td>Last committed batch if available, else 0</td>
  <td>Optional batchId used to retrieve operator metadata at that batch.</td>
</tr>
</table>

<p>Each row in the source has the following schema:</p>

<table>
<thead><tr><th>Column</th><th>Type</th><th>Note</th></tr></thead>
<tr>
  <td>operatorId</td>
  <td>int</td>
  <td></td>
</tr>
<tr>
  <td>operatorName</td>
  <td>string</td>
  <td></td>
</tr>
<tr>
  <td>stateStoreName</td>
  <td>int</td>
  <td></td>
</tr>
<tr>
  <td>numPartitions</td>
  <td>int</td>
  <td></td>
</tr>
<tr>
  <td>minBatchId</td>
  <td>int</td>
  <td>The minimum batch ID available for querying state. The value could be invalid if the streaming query taking the checkpoint is running, as cleanup would run.</td>
</tr>
<tr>
  <td>maxBatchId</td>
  <td>int</td>
  <td>The maximum batch ID available for querying state. The value could be invalid if the streaming query taking the checkpoint is running, as the query will commit further batches.</td>
</tr>
<tr>
  <td>operatorProperties</td>
  <td>string</td>
  <td>List of properties used by the operator encoded as JSON. Output generated here is operator dependent.</td>
</tr>
<tr>
  <td>_numColsPrefixKey</td>
  <td>int</td>
  <td>metadata column (hidden unless specified with SELECT)</td>
</tr>
</table>

<p>One of the major use cases of this data source is to identify the operatorId to query if the query has multiple stateful operators, e.g. stream-stream join followed by deduplication.
The column &#8216;operatorName&#8217; helps users to identify the operatorId for given operator.</p>

<p>Additionally, if users want to query about an internal state store instance for a stateful operator (e.g. stream-stream join), the column &#8216;stateStoreName&#8217; would be useful to determine the target.</p>


                </div>
            
             <!-- /container -->
        </div>

        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.0.2/dist/js/bootstrap.bundle.min.js"
        integrity="sha384-MrcW6ZMFYlzcLA8Nl+NtUVF0sA7MsXsP1UyJoMp4YLEuNSfAP+JcXn/tWtIaxVXM"
        crossorigin="anonymous"></script>
        <script src="https://code.jquery.com/jquery.js"></script>

        <script src="/js/vendor/anchor.min.js"></script>
        <script src="/js/main.js"></script>

        <script type="text/javascript" src="https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.js"></script>
        <script type="text/javascript">
            // DocSearch is entirely free and automated. DocSearch is built in two parts:
            // 1. a crawler which we run on our own infrastructure every 24 hours. It follows every link
            //    in your website and extract content from every page it traverses. It then pushes this
            //    content to an Algolia index.
            // 2. a JavaScript snippet to be inserted in your website that will bind this Algolia index
            //    to your search input and display its results in a dropdown UI. If you want to find more
            //    details on how works DocSearch, check the docs of DocSearch.
            docsearch({
    apiKey: 'd62f962a82bc9abb53471cb7b89da35e',
    appId: 'RAI69RXRSK',
    indexName: 'apache_spark',
    inputSelector: '#docsearch-input',
    enhancedSearchInput: true,
    algoliaOptions: {
      'facetFilters': ["version:4.0.0-preview2"]
    },
    debug: false // Set debug to true if you want to inspect the dropdown
});

        </script>

        <!-- MathJax Section -->
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({
                TeX: { equationNumbers: { autoNumber: "AMS" } }
            });
        </script>
        <script>
            // Note that we load MathJax this way to work with local file (file://), HTTP and HTTPS.
            // We could use "//cdn.mathjax...", but that won't support "file://".
            (function(d, script) {
                script = d.createElement('script');
                script.type = 'text/javascript';
                script.async = true;
                script.onload = function(){
                    MathJax.Hub.Config({
                        tex2jax: {
                            inlineMath: [ ["$", "$"], ["\\\\(","\\\\)"] ],
                            displayMath: [ ["$$","$$"], ["\\[", "\\]"] ],
                            processEscapes: true,
                            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre']
                        }
                    });
                };
                script.src = ('https:' == document.location.protocol ? 'https://' : 'http://') +
                    'cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js' +
                    '?config=TeX-AMS-MML_HTMLorMML';
                d.getElementsByTagName('head')[0].appendChild(script);
            }(document));
        </script>
    </body>
</html>
